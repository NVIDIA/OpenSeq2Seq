

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Using existing models &mdash; OpenSeq2Seq 0.2 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Internal structure" href="internal-structure.html" />
    <link rel="prev" title="In-depth tutorials" href="../in-depth-tutorials.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> OpenSeq2Seq
          

          
            
            <img src="../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation-instructions.html">Installation instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting-started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models-and-recipes.html">Models and recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distr-training.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mixed-precision.html">Mixed precision training</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../in-depth-tutorials.html">In-depth tutorials</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Using existing models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#how-to-run-models">How to run models</a></li>
<li class="toctree-l3"><a class="reference internal" href="#config-parameters">Config parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="#what-is-being-logged">What is being logged</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="internal-structure.html">Internal structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../extending.html">Adding new models</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api-docs/modules.html">API documentation</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">OpenSeq2Seq</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../in-depth-tutorials.html">In-depth tutorials</a> &raquo;</li>
        
      <li>Using existing models</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/in-depth-tutorials/using-existing-models.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="using-existing-models">
<h1>Using existing models<a class="headerlink" href="#using-existing-models" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial we will describe everything you can do with OpenSeq2Seq without
writing any new code. We will cover the following topics: how to run one of
the implemented models (for training, evaluation or inference), what parameters
can be specified in the config file/command line and what are the different
kinds of output that OpenSeq2Seq generates for you.</p>
<div class="section" id="how-to-run-models">
<h2>How to run models<a class="headerlink" href="#how-to-run-models" title="Permalink to this headline">¶</a></h2>
<p>There are two scripts that can be used to run the models: <code class="docutils literal notranslate"><span class="pre">run.py</span></code> and
<code class="docutils literal notranslate"><span class="pre">start_experiment.sh</span></code>. The latter one is just a convenient bash
wrapper around <code class="docutils literal notranslate"><span class="pre">run.py</span></code> that adds additional functionality, so we will
describe it in the end. Since <code class="docutils literal notranslate"><span class="pre">run.py</span></code> is a fairly simple Python script,
you can probably understand
how to use it by running <code class="docutils literal notranslate"><span class="pre">run.py</span> <span class="pre">--help</span></code> which will display all available
command line parameters and their short description. If that does not contain
enough details, continue reading this section. Otherwise, just skip to the
description of <code class="docutils literal notranslate"><span class="pre">start_experiment.sh</span></code> script (last paragraph of this section).</p>
<p>There are 2 main parameters of <code class="docutils literal notranslate"><span class="pre">run.py</span></code> that will be
used most often: <code class="docutils literal notranslate"><span class="pre">--config_file</span></code> and <code class="docutils literal notranslate"><span class="pre">--mode</span></code>. The first one is a required
parameter with path to the python configuration file (described in the <a class="reference internal" href="#config-params"><span class="std std-ref">next
section</span></a>). <code class="docutils literal notranslate"><span class="pre">--mode</span></code> parameter can be one of the “train”,
“eval”, “train_eval” or “infer”. This will do what it says: run the model in
the corresponding mode (with “train_eval” executing training with periodic
evaluation). The other parameters of the <code class="docutils literal notranslate"><span class="pre">run.py</span></code> script are the following:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">--continue_learning</span></code> — specify this when you want to continue learning
from existing checkpoint. This parameter is only checked when <code class="docutils literal notranslate"><span class="pre">--mode</span></code> is
“train” or “train_eval”.</li>
<li><code class="docutils literal notranslate"><span class="pre">--infer_output_file</span></code> — this specifies the path to output of the inference.
This parameter is only checked when <code class="docutils literal notranslate"><span class="pre">--mode</span></code> is “infer”.</li>
<li><code class="docutils literal notranslate"><span class="pre">--no_dir_check</span></code> — this parameter disables log directory checking.
By default, <code class="docutils literal notranslate"><span class="pre">run.py</span></code> will be checking that the log
directory (specified in the python config) is valid. Specifically, it will
check that it exists when <code class="docutils literal notranslate"><span class="pre">--mode</span></code> equals “eval” or “infer”
(or when <code class="docutils literal notranslate"><span class="pre">--continue_learning</span></code> is specified for training). If training is
performed, but <code class="docutils literal notranslate"><span class="pre">--continue_learning</span></code> is not specified, the script will check
that log directory is empty or does not exist, otherwise finishing with
exception. Finally, whenever necessary it will check that the log directory
contains a valid TensorFlow checkpoint of the saved model.</li>
<li><code class="docutils literal notranslate"><span class="pre">--benchmark</span></code> — specifying this parameter will automatically prepare config
for time benchmarking: disable all logging and evaluation. This parameter is
only useful for training benchmarking, since in other cases no config
preparation is needed. Moreover, specifying it will force the model to run
in the “train” mode.</li>
<li><code class="docutils literal notranslate"><span class="pre">--bench_steps</span></code> — number of steps to run the model for benchmarking. For
now this can only be used in conjunction with <code class="docutils literal notranslate"><span class="pre">--benchmark</span></code> parameter and
thus only works in the training benchmarking.</li>
<li><code class="docutils literal notranslate"><span class="pre">--bench_start</span></code> — first step to start counting time for benchmarking. This
parameter works in all modes whether or not <code class="docutils literal notranslate"><span class="pre">--benchmark</span></code> parameter was
specified.</li>
<li><code class="docutils literal notranslate"><span class="pre">--debug</span></code> — this enables TensorFlow debugging. To use it first run
<code class="docutils literal notranslate"><span class="pre">tensorboard</span> <span class="pre">--logdir=.</span> <span class="pre">--debugger_port=6067</span></code> and while tensorboard is
running execute <code class="docutils literal notranslate"><span class="pre">run.py</span></code> with <code class="docutils literal notranslate"><span class="pre">--debug</span></code> attribute. After that tensorboard
should have debugging tab.</li>
</ul>
<p>In order to make it more convenient to run multiple experiments we provide
<code class="docutils literal notranslate"><span class="pre">start_experiment.sh</span></code> script that is a wrapper around <code class="docutils literal notranslate"><span class="pre">run.py</span></code> script which
does the following things. First, it will make sure that the complete output of
<code class="docutils literal notranslate"><span class="pre">run.py</span></code> is saved inside the log directory (in the “output_&lt;time stamp&gt;.log
file, where &lt;time stamp&gt; is a string with current date and time to make sure
that everything is saved if you run this script multiple times).
Second, it will log the current git commit and git diff in the
“gitinfo_&lt;time stamp&gt;.log” file to make it possible to completely reproduce the
experiment. Finally, it will save the current experiment configuration in the
“config_&lt;time stamp&gt;.py” file. To run <code class="docutils literal notranslate"><span class="pre">start_experiment.sh</span></code> you will need to
define the following environment variables: <code class="docutils literal notranslate"><span class="pre">LOGDIR</span></code> (path to the desired log
directory), <code class="docutils literal notranslate"><span class="pre">CONFIG_FILE</span></code> (path to the Python configuration file), <code class="docutils literal notranslate"><span class="pre">MODE</span></code>
(mode to execute <code class="docutils literal notranslate"><span class="pre">run.py</span></code> in) and <code class="docutils literal notranslate"><span class="pre">CONTINUE_LEARNING</span></code> (whether to specify
<code class="docutils literal notranslate"><span class="pre">--continue_learning</span></code> flag for <code class="docutils literal notranslate"><span class="pre">run.py</span></code>, could be 1 or 0). For example to
train DeepSpeech2-like model on the toy speech data you can run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">LOGDIR</span><span class="o">=</span><span class="n">experiments</span><span class="o">/</span><span class="n">librispeech</span> <span class="n">CONFIG_FILE</span><span class="o">=</span><span class="n">example_configs</span><span class="o">/</span><span class="n">speech2text</span><span class="o">/</span><span class="n">ds2_toy_data_config</span><span class="o">.</span><span class="n">py</span> <span class="n">MODE</span><span class="o">=</span><span class="n">train_eval</span> <span class="n">CONTINUE_LEARNING</span><span class="o">=</span><span class="mi">0</span> <span class="o">./</span><span class="n">start_experiment</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
</div>
<div class="section" id="config-parameters">
<h2>Config parameters<a class="headerlink" href="#config-parameters" title="Permalink to this headline">¶</a></h2>
<p>The experiment parameters are completely defined in one Python configuration
file. This file must define <code class="docutils literal notranslate"><span class="pre">base_params</span></code> dictionary and <code class="docutils literal notranslate"><span class="pre">base_model</span></code> class.
<code class="docutils literal notranslate"><span class="pre">base_model</span></code> should be any class derived from
<a class="reference internal" href="../api-docs/models.html#models.model.Model" title="models.model.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code></a>. Currently it can only be
<a class="reference internal" href="../api-docs/models.html#models.speech2text.Speech2Text" title="models.speech2text.Speech2Text"><code class="xref py py-class docutils literal notranslate"><span class="pre">Speech2Text</span></code></a> or
<a class="reference internal" href="../api-docs/models.html#models.text2text.BasicText2TextWithAttention" title="models.text2text.BasicText2TextWithAttention"><code class="xref py py-class docutils literal notranslate"><span class="pre">BasicText2TextWithAttention</span></code></a>.
Note that this parameter is not a string, but an actual Python class, so you
will need to add corresponding imports in the configuration file. In addition
to <code class="docutils literal notranslate"><span class="pre">base_params</span></code> and <code class="docutils literal notranslate"><span class="pre">base_model</span></code> you can define
<code class="docutils literal notranslate"><span class="pre">train_params</span></code>, <code class="docutils literal notranslate"><span class="pre">eval_params</span></code> and <code class="docutils literal notranslate"><span class="pre">infer_params</span></code> dictionaries that will
overwrite corresponding parts of <code class="docutils literal notranslate"><span class="pre">base_params</span></code> when the corresponding mode
is used. For example of configuration file look in the <code class="docutils literal notranslate"><span class="pre">example_configs</span></code>
directory. The complete list of all possible configuration parameters is
defined in the documentation in various places. A good place to look first is
the <a class="reference internal" href="#models.model.Model.__init__" title="models.model.Model.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Model.__init__()</span></code></a> method
(config parameters section), which defines most of the <em>first level</em> parameters:</p>
<dl class="method">
<dt id="models.model.Model.__init__">
<code class="descclassname">Model.</code><code class="descname">__init__</code><span class="sig-paren">(</span><em>params</em>, <em>mode='train'</em>, <em>hvd=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/model.html#Model.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.model.Model.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Model constructor.
The TensorFlow graph should not be created here, but rather in the
<a class="reference internal" href="../api-docs/models.html#models.model.Model.compile" title="models.model.Model.compile"><code class="xref py py-meth docutils literal notranslate"><span class="pre">self.compile()</span></code></a> method.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>params</strong> (<em>dict</em>) – parameters describing the model.
All supported parameters are listed in <a class="reference internal" href="../api-docs/models.html#models.model.Model.get_required_params" title="models.model.Model.get_required_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_required_params()</span></code></a>,
<a class="reference internal" href="../api-docs/models.html#models.model.Model.get_optional_params" title="models.model.Model.get_optional_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_optional_params()</span></code></a> functions.</li>
<li><strong>mode</strong> (<em>string</em><em>, </em><em>optional</em>) – “train”, “eval” or “infer”.
If mode is “train” all parts of the graph will be built
(model, loss, optimizer).
If mode is “eval”, only model and loss will be built.
If mode is “infer”, only model will be built.</li>
<li><strong>hvd</strong> (<em>optional</em>) – if Horovod is used, this should be
<code class="docutils literal notranslate"><span class="pre">horovod.tensorflow</span></code> module.
If Horovod is not used, it should be None.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Config parameters:</p>
<blockquote>
<div><ul class="simple">
<li><strong>random_seed</strong> (int) — random seed to use.</li>
<li><strong>use_horovod</strong> (bool) — whether to use Horovod for distributed
execution.</li>
<li><strong>num_gpus</strong> (int) — number of GPUs to use. This parameter cannot be
used if <code class="docutils literal notranslate"><span class="pre">gpu_ids</span></code> is specified. When <code class="docutils literal notranslate"><span class="pre">use_horovod</span></code> is True
this parameter is ignored.</li>
<li><strong>gpu_ids</strong> (list of ints) — GPU ids to use. This parameter cannot be
used if <code class="docutils literal notranslate"><span class="pre">num_gpus</span></code> is specified. When <code class="docutils literal notranslate"><span class="pre">use_horovod</span></code> is True
this parameter is ignored.</li>
<li><strong>batch_size_per_gpu</strong> (int) — batch size to use for each GPU.</li>
<li><strong>num_epochs</strong> (int) — number of epochs to run training for.
This parameter cannot be used if <code class="docutils literal notranslate"><span class="pre">max_steps</span></code> is specified.</li>
<li><strong>max_steps</strong> (int) — number of steps to run training for.
This parameter cannot be used if <code class="docutils literal notranslate"><span class="pre">num_epochs</span></code> is specified.</li>
<li><strong>save_summaries_steps</strong> (int or None) — how often to save summaries.
Setting it to None disables summaries saving.</li>
<li><strong>print_loss_steps</strong> (int or None) — how often to print loss during
training. Setting it to None disables loss printing.</li>
<li><strong>print_samples_steps</strong> (int or None) — how often to print training
samples (input sequences, correct answers and model predictions).
Setting it to None disables samples printing.</li>
<li><strong>save_checkpoint_steps</strong> (int or None) — how often to save model
checkpoints. Setting it to None disables checkpoint saving.</li>
<li><strong>eval_steps</strong> (int) — how often to run evaluation during training.
This parameter is only checked if <code class="docutils literal notranslate"><span class="pre">--mode</span></code> argument of <code class="docutils literal notranslate"><span class="pre">run.py</span></code> is
“train_eval”. If no evaluation is needed you should use “train” mode.</li>
<li><strong>logdir</strong> (string) — path to the log directory where all checkpoints
and summaries will be saved.</li>
<li><strong>data_layer</strong> (any class derived from
<a class="reference internal" href="../api-docs/data.html#data.data_layer.DataLayer" title="data.data_layer.DataLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLayer</span></code></a>) — data layer class
to use.</li>
<li><strong>data_layer_params</strong> (dict) — dictionary with data layer
configuration.
For complete list of possible parameters see the corresponding
class docs.</li>
<li><strong>learning_rate</strong> (float) — initial learning rate for training.</li>
<li><strong>optimizer</strong> (string or TensorFlow optimizer class) — optimizer to
use for training. Could be either “Adam”, “Adagrad”, “Ftrl”, “Momentum”,
“RMSProp”, “SGD” or any valid TensorFlow optimizer class.</li>
<li><strong>optimizer_params</strong> (dict) — dictionary that will be passed to
optimizer <code class="docutils literal notranslate"><span class="pre">__init__</span></code> method.</li>
<li><strong>initializer</strong> — any valid TensorFlow initializer.</li>
<li><strong>initializer_params</strong> (dict) — dictionary that will be passed to
initializer <code class="docutils literal notranslate"><span class="pre">__init__</span></code> method.</li>
<li><strong>regularizer</strong> — and valid TensorFlow regularizer.</li>
<li><strong>regularizer_params</strong> (dict) — dictionary that will be passed to
regularizer <code class="docutils literal notranslate"><span class="pre">__init__</span></code> method.</li>
<li><strong>dtype</strong> — model dtype. Could be either <code class="docutils literal notranslate"><span class="pre">tf.float16</span></code>,
<code class="docutils literal notranslate"><span class="pre">tf.float32</span></code> or “mixed”. For details see
<a class="reference internal" href="../mixed-precision.html#mixed-precision"><span class="std std-ref">mixed precision training</span></a> section in docs.</li>
<li><strong>lr_policy</strong> — any valid learning rate policy function. For examples,
see <a class="reference internal" href="../api-docs/optimizers.html#module-optimizers.lr_policies" title="optimizers.lr_policies"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">optimizers.lr_policies</span></code></a> module.</li>
<li><strong>lr_policy_params</strong> (dict) — dictionary containing lr_policy
parameters.</li>
<li><strong>max_grad_norm</strong> (float) — maximum value of gradient norm. Clipping
will be performed if some gradients exceed this value (this is checked
for each variable independently).</li>
<li><strong>larc_mode</strong> — specify this to use LARC or LARS optimization
algorithms. Could be either “scale” (LARS) or “clip” (LARC).
You also need to specify <code class="docutils literal notranslate"><span class="pre">larc_nu</span></code> to enable LARC or LARS. Note that
it works in addition to any other optimization algorithm since we treat
it as adaptive gradient clipping and learning rate adjustment.</li>
<li><strong>larc_nu</strong> (float) — LARC or LARS scaling parameter.</li>
<li><strong>loss_scale</strong> (float) — static loss scale to use. For details see
<a class="reference internal" href="../mixed-precision.html#mixed-precision"><span class="std std-ref">mixed precision training</span></a> section in docs.</li>
<li><strong>automatic_loss_scaling</strong> — automatic loss scaling mode. Could be
either None, “Backoff” or “Logmax”. For details see
<a class="reference internal" href="../mixed-precision.html#mixed-precision"><span class="std std-ref">mixed precision training</span></a> section in docs.</li>
<li><strong>summaries</strong> (list) — which summaries to log. Could contain
“learning_rate”, “gradients”, “gradient_norm”, “global_gradient_norm”,
“variables”, “variable_norm”.</li>
</ul>
</div></blockquote>
</dd></dl>

<p>Note that some of the parameters are also config dictionaries for corresponding
classes. To see list of their configuration options, you should proceed to the
corresponding class docs. For example, to see all supported data layer parameters,
look into the docs for <a class="reference internal" href="../api-docs/data.html#data.data_layer.DataLayer" title="data.data_layer.DataLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">data.data_layer.DataLayer</span></code></a>. Sometimes, derived classes
might define their additional parameters, in that case you should be looking
into both, parent class and its child. For example, look into
<a class="reference internal" href="../api-docs/models.html#models.seq2seq.Seq2Seq" title="models.seq2seq.Seq2Seq"><code class="xref py py-class docutils literal notranslate"><span class="pre">models.seq2seq.Seq2Seq</span></code></a>, which defines sequence-to-sequence specific
parameters (i.e. encoder, decoder and loss). You can also have a look at
<a class="reference internal" href="../api-docs/encoders.html#encoders.encoder.Encoder" title="encoders.encoder.Encoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">encoders.encoder.Encoder</span></code></a> (which defines some parameters shared across
all encoders) and <a class="reference internal" href="../api-docs/encoders.html#encoders.ds2_encoder.DeepSpeech2Encoder" title="encoders.ds2_encoder.DeepSpeech2Encoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">encoders.ds2_encoder.DeepSpeech2Encoder</span></code></a> (which
additionally defines a set of DeepSpeech-2 specific parameters).</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">For convenience all <em>first level</em> parameters can be overwritten by
command line arguments. For example, try to add <code class="docutils literal notranslate"><span class="pre">--logdir</span></code> argument
to your <code class="docutils literal notranslate"><span class="pre">run.py</span></code> execution.</p>
</div>
</div>
<div class="section" id="what-is-being-logged">
<h2>What is being logged<a class="headerlink" href="#what-is-being-logged" title="Permalink to this headline">¶</a></h2>
<p>This section is going to be completed soon.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="internal-structure.html" class="btn btn-neutral float-right" title="Internal structure" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../in-depth-tutorials.html" class="btn btn-neutral" title="In-depth tutorials" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, NVIDIA.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.2',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  <script type="text/javascript">
      jQuery(function () {
          
          SphinxRtdTheme.Navigation.enableSticky();
          
      });
  </script>  
  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #64d81c;
    }
    .wy-side-nav-search > div.version {
      color: #ffffff;
    }
    .wy-side-nav-search > img {
      max-width: 150px;
    }
    .wy-side-nav-search > a {
      font-size: 23px;
    }
  </style>


</body>
</html>