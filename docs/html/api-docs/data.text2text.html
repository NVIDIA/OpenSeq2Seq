

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>text2text &mdash; OpenSeq2Seq 0.2 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  
  
  

  

  
  
    

  

  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/theme_override.css" type="text/css" />
  <link rel="stylesheet" href="../_static/theme_override.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="text2speech" href="data.text2speech.html" />
    <link rel="prev" title="speech2text" href="data.speech2text.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> OpenSeq2Seq
          

          
            
            <img src="../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../machine-translation.html">Machine Translation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../speech-recognition.html">Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../speech-synthesis.html">Speech Synthesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distr-training.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mixed-precision.html">Mixed precision training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../in-depth-tutorials.html">In-depth tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../interactive-infer-demos.html">Interactive Infer Mode</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">API documentation</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="models.html">models</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="data.html">data</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="data.image2label.html">image2label</a></li>
<li class="toctree-l3"><a class="reference internal" href="data.speech2text.html">speech2text</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">text2text</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#module-data.text2text.t2t">t2t</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id1">text2text</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-data.text2text.tokenizer">tokenizer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="data.text2speech.html">text2speech</a></li>
<li class="toctree-l3"><a class="reference internal" href="data.html#module-data.data_layer">data_layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="data.html#module-data.utils">utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="encoders.html">encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="decoders.html">decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="losses.html">losses</a></li>
<li class="toctree-l2"><a class="reference internal" href="optimizers.html">optimizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="parts.html">parts</a></li>
<li class="toctree-l2"><a class="reference internal" href="utils.html">utils</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">OpenSeq2Seq</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="modules.html">API documentation</a> &raquo;</li>
        
          <li><a href="data.html">data</a> &raquo;</li>
        
      <li>text2text</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/api-docs/data.text2text.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-data.text2text">
<span id="text2text"></span><h1>text2text<a class="headerlink" href="#module-data.text2text" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-data.text2text.t2t">
<span id="t2t"></span><h2>t2t<a class="headerlink" href="#module-data.text2text.t2t" title="Permalink to this headline">¶</a></h2>
<p>Input pipeline for the transformer model to read, filter, and batch examples.</p>
<p>Two things to note in the pipeline:</p>
<ol class="arabic">
<li><p class="first">Batching scheme</p>
<dl class="docutils">
<dt>The examples encoded in the TFRecord files contain data in the format:</dt>
<dd><dl class="first last docutils">
<dt>{“inputs”: [variable length array of integers],</dt>
<dd><p class="first last">“targets”: [variable length array of integers]}</p>
</dd>
</dl>
</dd>
</dl>
<p>Where integers in the arrays refer to tokens in the English and German vocab
file (named <cite>vocab.ende.32768</cite>).</p>
<p>Prior to batching, elements in the dataset are grouped by length (max between
“inputs” and “targets” length). Each group is then batched such that:</p>
<blockquote>
<div><p>group_batch_size * length &lt;= batch_size.</p>
</div></blockquote>
<p>Another way to view batch_size is the maximum number of tokens in each batch.</p>
<dl class="docutils">
<dt>Once batched, each element in the dataset will have the shape:</dt>
<dd><dl class="first last docutils">
<dt>{“inputs”: [group_batch_size, padded_input_length],</dt>
<dd><p class="first last">“targets”: [group_batch_size, padded_target_length]}</p>
</dd>
</dl>
</dd>
</dl>
<p>Lengths are padded to the longest “inputs” or “targets” sequence in the batch
(padded_input_length and padded_target_length can be different).</p>
<p>This batching scheme decreases the fraction of padding tokens per training
batch, thus improving the training speed significantly.</p>
</li>
<li><p class="first">Shuffling</p>
<p>While training, the dataset is shuffled in two places in the code. The first
is the list of training files. Second, while reading records using
<cite>parallel_interleave</cite>, the <cite>sloppy</cite> argument is used to generate randomness
in the order of the examples.</p>
</li>
<li><p class="first">Modified slightly to fit OpenSeq2Seq needs</p>
</li>
</ol>
<dl class="function">
<dt id="data.text2text.t2t._batch_examples">
<code class="descclassname">data.text2text.t2t.</code><code class="descname">_batch_examples</code><span class="sig-paren">(</span><em>dataset</em>, <em>batch_size</em>, <em>max_length</em>, <em>pad_2_eight=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/t2t.html#_batch_examples"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.t2t._batch_examples" title="Permalink to this definition">¶</a></dt>
<dd><p>Group examples by similar lengths, and return batched dataset.</p>
<p>Each batch of similar-length examples are padded to the same length, and may
have different number of elements in each batch, such that:</p>
<blockquote>
<div>group_batch_size * padded_length &lt;= batch_size.</div></blockquote>
<p>This decreases the number of padding tokens per batch, which improves the
training speed.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> – Dataset of unbatched examples.</li>
<li><strong>batch_size</strong> – Max number of tokens per batch of examples.</li>
<li><strong>max_length</strong> – Max number of tokens in an example input or target sequence.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">Dataset of batched examples with similar lengths.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="data.text2text.t2t._create_min_max_boundaries">
<code class="descclassname">data.text2text.t2t.</code><code class="descname">_create_min_max_boundaries</code><span class="sig-paren">(</span><em>max_length</em>, <em>min_boundary=8</em>, <em>boundary_scale=1.1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/t2t.html#_create_min_max_boundaries"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.t2t._create_min_max_boundaries" title="Permalink to this definition">¶</a></dt>
<dd><p>Create min and max boundary lists up to max_length.</p>
<p>For example, when max_length=24, min_boundary=4 and boundary_scale=2, the
returned values will be:</p>
<blockquote>
<div>buckets_min = [0, 4, 8, 16, 24]
buckets_max = [4, 8, 16, 24, 25]</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>max_length</strong> – The maximum length of example in dataset.</li>
<li><strong>min_boundary</strong> – Minimum length in boundary.</li>
<li><strong>boundary_scale</strong> – Amount to scale consecutive boundaries in the list.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">min and max boundary lists</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="data.text2text.t2t._filter_max_length">
<code class="descclassname">data.text2text.t2t.</code><code class="descname">_filter_max_length</code><span class="sig-paren">(</span><em>example</em>, <em>max_length=256</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/t2t.html#_filter_max_length"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.t2t._filter_max_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Indicates whether the example’s length is lower than the maximum length.</p>
</dd></dl>

<dl class="function">
<dt id="data.text2text.t2t._get_example_length">
<code class="descclassname">data.text2text.t2t.</code><code class="descname">_get_example_length</code><span class="sig-paren">(</span><em>example</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/t2t.html#_get_example_length"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.t2t._get_example_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the maximum length between the example inputs and targets.</p>
</dd></dl>

<dl class="function">
<dt id="data.text2text.t2t._load_records">
<code class="descclassname">data.text2text.t2t.</code><code class="descname">_load_records</code><span class="sig-paren">(</span><em>filename</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/t2t.html#_load_records"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.t2t._load_records" title="Permalink to this definition">¶</a></dt>
<dd><p>Read file and return a dataset of tf.Examples.</p>
</dd></dl>

<dl class="function">
<dt id="data.text2text.t2t._parse_example">
<code class="descclassname">data.text2text.t2t.</code><code class="descname">_parse_example</code><span class="sig-paren">(</span><em>serialized_example</em>, <em>pad_2_eight=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/t2t.html#_parse_example"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.t2t._parse_example" title="Permalink to this definition">¶</a></dt>
<dd><p>Return inputs and targets Tensors from a serialized tf.Example.</p>
</dd></dl>

<dl class="function">
<dt id="data.text2text.t2t._read_and_batch_from_files">
<code class="descclassname">data.text2text.t2t.</code><code class="descname">_read_and_batch_from_files</code><span class="sig-paren">(</span><em>file_pattern</em>, <em>batch_size</em>, <em>max_length</em>, <em>num_cpu_cores</em>, <em>shuffle</em>, <em>repeat</em>, <em>num_workers</em>, <em>worker_id</em>, <em>batch_in_tokens</em>, <em>pad2eight=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/t2t.html#_read_and_batch_from_files"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.t2t._read_and_batch_from_files" title="Permalink to this definition">¶</a></dt>
<dd><p>Create dataset where each item is a dict of “inputs” and “targets”.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>file_pattern</strong> – String used to match the input TFRecord files.</li>
<li><strong>batch_size</strong> – Maximum number of tokens per batch of examples</li>
<li><strong>max_length</strong> – Maximum number of tokens per example</li>
<li><strong>num_cpu_cores</strong> – Number of cpu cores for parallel input processing.</li>
<li><strong>shuffle</strong> – If true, randomizes order of elements.</li>
<li><strong>repeat</strong> – Number of times to repeat the dataset. If None, the dataset is
repeated forever.</li>
<li><strong>num_workers</strong> – Number of workers or number of Horovod workers</li>
<li><strong>worker_id</strong> – Worker id or Horovod rank</li>
<li><strong>batch_in_tokens</strong> – whether to batch_size means amounts in tokens or sentence</li>
<li><strong>batching in tokens is more efficient as it reduces PADs. batching in</strong> (<em>pairs.</em>) – </li>
<li><strong>should be used in inference mode since order of</strong> (<em>sentences</em>) – </li>
<li><strong>is important</strong> (<em>sentences</em>) – </li>
<li><strong>pad2eight</strong> – if True, it will pad both dimensions to be divisible by 8</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">tf.data.Dataset object containing examples loaded from the files.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="id1">
<h2>text2text<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-data.text2text.text2text"></span><dl class="class">
<dt id="data.text2text.text2text.ParallelTextDataLayer">
<em class="property">class </em><code class="descclassname">data.text2text.text2text.</code><code class="descname">ParallelTextDataLayer</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>num_workers=1</em>, <em>worker_id=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/text2text.html#ParallelTextDataLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.text2text.ParallelTextDataLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">open_seq2seq.data.data_layer.DataLayer</span></code></p>
<dl class="method">
<dt id="data.text2text.text2text.ParallelTextDataLayer.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/text2text.html#ParallelTextDataLayer.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.text2text.ParallelTextDataLayer.build_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Here all TensorFlow graph construction should happen.</p>
</dd></dl>

<dl class="method">
<dt id="data.text2text.text2text.ParallelTextDataLayer.create_feed_dict">
<code class="descname">create_feed_dict</code><span class="sig-paren">(</span><em>model_in</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/text2text.html#ParallelTextDataLayer.create_feed_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.text2text.ParallelTextDataLayer.create_feed_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates the feed dict for interactive infer</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>model_in</strong> (<em>str</em>) – the string to be translated. Should be in bpe format.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Dictionary with values for the placeholders.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">feed_dict (dict)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="data.text2text.text2text.ParallelTextDataLayer.create_interactive_placeholders">
<code class="descname">create_interactive_placeholders</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/text2text.html#ParallelTextDataLayer.create_interactive_placeholders"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.text2text.ParallelTextDataLayer.create_interactive_placeholders" title="Permalink to this definition">¶</a></dt>
<dd><p>A function that must be defined for data layers that support interactive
infer. This function is intended to create placeholders that will be passed
to self._input_tensors that will be passed to the model.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="data.text2text.text2text.ParallelTextDataLayer.get_optional_params">
<em class="property">static </em><code class="descname">get_optional_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/text2text.html#ParallelTextDataLayer.get_optional_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.text2text.ParallelTextDataLayer.get_optional_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of optional parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>can</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="data.text2text.text2text.ParallelTextDataLayer.get_required_params">
<em class="property">static </em><code class="descname">get_required_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/text2text.html#ParallelTextDataLayer.get_required_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.text2text.ParallelTextDataLayer.get_required_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of required parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>have to</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="data.text2text.text2text.ParallelTextDataLayer.get_size_in_samples">
<code class="descname">get_size_in_samples</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/text2text.html#ParallelTextDataLayer.get_size_in_samples"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.text2text.ParallelTextDataLayer.get_size_in_samples" title="Permalink to this definition">¶</a></dt>
<dd><p>Should return the dataset size in samples.
That is, the number of objects in the dataset. This method is used to
calculate a valid epoch size. If this method is not defined, you will need
to make sure that your dataset for evaluation is created only for
one epoch. You will also not be able to use <code class="docutils literal notranslate"><span class="pre">num_epochs</span></code> parameter in the
base config.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">dataset size in samples.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">int</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="data.text2text.text2text.ParallelTextDataLayer.input_tensors">
<code class="descname">input_tensors</code><a class="headerlink" href="#data.text2text.text2text.ParallelTextDataLayer.input_tensors" title="Permalink to this definition">¶</a></dt>
<dd><p>Dictionary containing input tensors.
This dictionary has to define the following keys: <cite>source_tensors</cite>,
which should contain all tensors describing the input object (i.e. tensors
that are passed to the encoder, e.g. input sequence and input length). And
when <code class="docutils literal notranslate"><span class="pre">self.params['mode']</span> <span class="pre">!=</span> <span class="pre">&quot;infer&quot;</span></code> data layer should also define
<cite>target_tensors</cite> which is the list of all tensors related to the
corresponding target object (i.e. tensors taht are passed to the decoder and
loss, e.g. target sequence and target length). Note that all tensors have
to be created inside <a class="reference internal" href="#data.text2text.text2text.ParallelTextDataLayer.build_graph" title="data.text2text.text2text.ParallelTextDataLayer.build_graph"><code class="xref py py-meth docutils literal notranslate"><span class="pre">self.build_graph()</span></code></a> method.</p>
</dd></dl>

<dl class="attribute">
<dt id="data.text2text.text2text.ParallelTextDataLayer.iterator">
<code class="descname">iterator</code><a class="headerlink" href="#data.text2text.text2text.ParallelTextDataLayer.iterator" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> iterator.
Should be created by <a class="reference internal" href="#data.text2text.text2text.ParallelTextDataLayer.build_graph" title="data.text2text.text2text.ParallelTextDataLayer.build_graph"><code class="xref py py-meth docutils literal notranslate"><span class="pre">self.build_graph()</span></code></a>.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="data.text2text.text2text.SpecialTextTokens">
<em class="property">class </em><code class="descclassname">data.text2text.text2text.</code><code class="descname">SpecialTextTokens</code><a class="reference internal" href="../_modules/data/text2text/text2text.html#SpecialTextTokens"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.text2text.SpecialTextTokens" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">enum.Enum</span></code></p>
<p>An enumeration.</p>
<dl class="attribute">
<dt id="data.text2text.text2text.SpecialTextTokens.END_OF_CHOICE">
<code class="descname">END_OF_CHOICE</code><em class="property"> = -100</em><a class="headerlink" href="#data.text2text.text2text.SpecialTextTokens.END_OF_CHOICE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="data.text2text.text2text.SpecialTextTokens.EOS_ID">
<code class="descname">EOS_ID</code><em class="property"> = 1</em><a class="headerlink" href="#data.text2text.text2text.SpecialTextTokens.EOS_ID" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="data.text2text.text2text.SpecialTextTokens.OUT_OF_BUCKET">
<code class="descname">OUT_OF_BUCKET</code><em class="property"> = 1234567890</em><a class="headerlink" href="#data.text2text.text2text.SpecialTextTokens.OUT_OF_BUCKET" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="data.text2text.text2text.SpecialTextTokens.PAD_ID">
<code class="descname">PAD_ID</code><em class="property"> = 0</em><a class="headerlink" href="#data.text2text.text2text.SpecialTextTokens.PAD_ID" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="data.text2text.text2text.SpecialTextTokens.S_ID">
<code class="descname">S_ID</code><em class="property"> = 2</em><a class="headerlink" href="#data.text2text.text2text.SpecialTextTokens.S_ID" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="data.text2text.text2text.SpecialTextTokens.UNK_ID">
<code class="descname">UNK_ID</code><em class="property"> = 3</em><a class="headerlink" href="#data.text2text.text2text.SpecialTextTokens.UNK_ID" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="data.text2text.text2text.TransformerDataLayer">
<em class="property">class </em><code class="descclassname">data.text2text.text2text.</code><code class="descname">TransformerDataLayer</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>num_workers=1</em>, <em>worker_id=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/text2text.html#TransformerDataLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.text2text.TransformerDataLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">open_seq2seq.data.data_layer.DataLayer</span></code></p>
<p>Wraps Transformers data pipeline into the form for OpenSeq2Seq</p>
<dl class="method">
<dt id="data.text2text.text2text.TransformerDataLayer.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/text2text.html#TransformerDataLayer.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.text2text.TransformerDataLayer.build_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Here all TensorFlow graph construction should happen.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="data.text2text.text2text.TransformerDataLayer.get_optional_params">
<em class="property">static </em><code class="descname">get_optional_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/text2text.html#TransformerDataLayer.get_optional_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.text2text.TransformerDataLayer.get_optional_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of optional parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>can</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="data.text2text.text2text.TransformerDataLayer.get_required_params">
<em class="property">static </em><code class="descname">get_required_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/text2text.html#TransformerDataLayer.get_required_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.text2text.TransformerDataLayer.get_required_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of required parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>have to</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="data.text2text.text2text.TransformerDataLayer.input_tensors">
<code class="descname">input_tensors</code><a class="headerlink" href="#data.text2text.text2text.TransformerDataLayer.input_tensors" title="Permalink to this definition">¶</a></dt>
<dd><p>Dictionary containing input tensors.
This dictionary has to define the following keys: <cite>source_tensors</cite>,
which should contain all tensors describing the input object (i.e. tensors
that are passed to the encoder, e.g. input sequence and input length). And
when <code class="docutils literal notranslate"><span class="pre">self.params['mode']</span> <span class="pre">!=</span> <span class="pre">&quot;infer&quot;</span></code> data layer should also define
<cite>target_tensors</cite> which is the list of all tensors related to the
corresponding target object (i.e. tensors taht are passed to the decoder and
loss, e.g. target sequence and target length). Note that all tensors have
to be created inside <a class="reference internal" href="#data.text2text.text2text.TransformerDataLayer.build_graph" title="data.text2text.text2text.TransformerDataLayer.build_graph"><code class="xref py py-meth docutils literal notranslate"><span class="pre">self.build_graph()</span></code></a> method.</p>
</dd></dl>

<dl class="attribute">
<dt id="data.text2text.text2text.TransformerDataLayer.iterator">
<code class="descname">iterator</code><a class="headerlink" href="#data.text2text.text2text.TransformerDataLayer.iterator" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> iterator.
Should be created by <a class="reference internal" href="#data.text2text.text2text.TransformerDataLayer.build_graph" title="data.text2text.text2text.TransformerDataLayer.build_graph"><code class="xref py py-meth docutils literal notranslate"><span class="pre">self.build_graph()</span></code></a>.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-data.text2text.tokenizer">
<span id="tokenizer"></span><h2>tokenizer<a class="headerlink" href="#module-data.text2text.tokenizer" title="Permalink to this headline">¶</a></h2>
<p>Defines Subtokenizer class to encode and decode strings.</p>
<dl class="class">
<dt id="data.text2text.tokenizer.Subtokenizer">
<em class="property">class </em><code class="descclassname">data.text2text.tokenizer.</code><code class="descname">Subtokenizer</code><span class="sig-paren">(</span><em>vocab_file</em>, <em>reserved_tokens=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#Subtokenizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer.Subtokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Encodes and decodes strings to/from integer IDs.</p>
<dl class="method">
<dt id="data.text2text.tokenizer.Subtokenizer.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>vocab_file</em>, <em>reserved_tokens=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#Subtokenizer.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer.Subtokenizer.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initializes class, creating a vocab file if data_files is provided.</p>
</dd></dl>

<dl class="method">
<dt id="data.text2text.tokenizer.Subtokenizer._subtoken_ids_to_tokens">
<code class="descname">_subtoken_ids_to_tokens</code><span class="sig-paren">(</span><em>subtokens</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#Subtokenizer._subtoken_ids_to_tokens"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer.Subtokenizer._subtoken_ids_to_tokens" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert list of int subtoken ids to a list of string tokens.</p>
</dd></dl>

<dl class="method">
<dt id="data.text2text.tokenizer.Subtokenizer._token_to_subtoken_ids">
<code class="descname">_token_to_subtoken_ids</code><span class="sig-paren">(</span><em>token</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#Subtokenizer._token_to_subtoken_ids"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer.Subtokenizer._token_to_subtoken_ids" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode a single token into a list of subtoken ids.</p>
</dd></dl>

<dl class="method">
<dt id="data.text2text.tokenizer.Subtokenizer.decode">
<code class="descname">decode</code><span class="sig-paren">(</span><em>subtokens</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#Subtokenizer.decode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer.Subtokenizer.decode" title="Permalink to this definition">¶</a></dt>
<dd><p>Converts list of int subtokens ids into a string.</p>
</dd></dl>

<dl class="method">
<dt id="data.text2text.tokenizer.Subtokenizer.encode">
<code class="descname">encode</code><span class="sig-paren">(</span><em>raw_string</em>, <em>add_eos=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#Subtokenizer.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer.Subtokenizer.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encodes a string into a list of int subtoken ids.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="data.text2text.tokenizer.Subtokenizer.init_from_files">
<em class="property">static </em><code class="descname">init_from_files</code><span class="sig-paren">(</span><em>vocab_file</em>, <em>files</em>, <em>target_vocab_size</em>, <em>threshold</em>, <em>min_count=None</em>, <em>file_byte_limit=1000000.0</em>, <em>reserved_tokens=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#Subtokenizer.init_from_files"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer.Subtokenizer.init_from_files" title="Permalink to this definition">¶</a></dt>
<dd><p>Create subtoken vocabulary based on files, and save vocab to file.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>vocab_file</strong> – String name of vocab file to store subtoken vocabulary.</li>
<li><strong>files</strong> – List of file paths that will be used to generate vocabulary.</li>
<li><strong>target_vocab_size</strong> – target vocabulary size to generate.</li>
<li><strong>threshold</strong> – int threshold of vocabulary size to accept.</li>
<li><strong>min_count</strong> – int minimum count to use for generating the vocabulary. The min
count is the minimum number of times a subtoken should appear in the
files before it is added to the vocabulary. If set to none, this value
is found using binary search.</li>
<li><strong>file_byte_limit</strong> – (Default 1e6) Maximum number of bytes of sample text that
will be drawn from the files.</li>
<li><strong>reserved_tokens</strong> – List of string tokens that are guaranteed to be at the
beginning of the subtoken vocabulary list.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">Subtokenizer object</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="data.text2text.tokenizer._count_and_gen_subtokens">
<code class="descclassname">data.text2text.tokenizer.</code><code class="descname">_count_and_gen_subtokens</code><span class="sig-paren">(</span><em>token_counts</em>, <em>alphabet</em>, <em>subtoken_dict</em>, <em>max_subtoken_length</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#_count_and_gen_subtokens"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer._count_and_gen_subtokens" title="Permalink to this definition">¶</a></dt>
<dd><p>Count number of times subtokens appear, and generate new subtokens.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>token_counts</strong> – dict mapping tokens to the number of times they appear in the
original files.</li>
<li><strong>alphabet</strong> – list of allowed characters. Used to escape the tokens, which
guarantees that all tokens can be split into subtokens.</li>
<li><strong>subtoken_dict</strong> – dict mapping subtokens to ids.</li>
<li><strong>max_subtoken_length</strong> – maximum length of subtoken in subtoken_dict.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A defaultdict mapping subtokens to the number of times they appear in the
tokens. The dict may contain new subtokens.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="data.text2text.tokenizer._count_tokens">
<code class="descclassname">data.text2text.tokenizer.</code><code class="descname">_count_tokens</code><span class="sig-paren">(</span><em>files</em>, <em>file_byte_limit=1000000.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#_count_tokens"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer._count_tokens" title="Permalink to this definition">¶</a></dt>
<dd><p>Return token counts of words in the files.</p>
<p>Samples file_byte_limit bytes from each file, and counts the words that appear
in the samples. The samples are semi-evenly distributed across the file.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>files</strong> – List of filepaths</li>
<li><strong>file_byte_limit</strong> – Max number of bytes that will be read from each file.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">Dictionary mapping tokens to the number of times they appear in the sampled
lines from the files.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="data.text2text.tokenizer._escape_token">
<code class="descclassname">data.text2text.tokenizer.</code><code class="descname">_escape_token</code><span class="sig-paren">(</span><em>token</em>, <em>alphabet</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#_escape_token"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer._escape_token" title="Permalink to this definition">¶</a></dt>
<dd><p>Replace characters that aren’t in the alphabet and append “_” to token.</p>
<dl class="docutils">
<dt>Apply three transformations to the token:</dt>
<dd><ol class="first last arabic simple">
<li>Replace underline character “_” with “u”, and backslash “” with “&quot;.</li>
<li>Replace characters outside of the alphabet with “###;”, where ### is the
character’s Unicode code point.</li>
<li>Appends “_” to mark the end of a token.</li>
</ol>
</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>token</strong> – unicode string to be escaped</li>
<li><strong>alphabet</strong> – list of all known characters</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">escaped string</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="data.text2text.tokenizer._filter_and_bucket_subtokens">
<code class="descclassname">data.text2text.tokenizer.</code><code class="descname">_filter_and_bucket_subtokens</code><span class="sig-paren">(</span><em>subtoken_counts</em>, <em>min_count</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#_filter_and_bucket_subtokens"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer._filter_and_bucket_subtokens" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a bucketed list of subtokens that are filtered by count.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>subtoken_counts</strong> – defaultdict mapping subtokens to their counts</li>
<li><strong>min_count</strong> – int count used to filter subtokens</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">List of subtoken sets, where subtokens in set i have the same length=i.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="data.text2text.tokenizer._gen_new_subtoken_list">
<code class="descclassname">data.text2text.tokenizer.</code><code class="descname">_gen_new_subtoken_list</code><span class="sig-paren">(</span><em>subtoken_counts</em>, <em>min_count</em>, <em>alphabet</em>, <em>reserved_tokens=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#_gen_new_subtoken_list"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer._gen_new_subtoken_list" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate candidate subtokens ordered by count, and new max subtoken length.</p>
<p>Add subtokens to the candiate list in order of length (longest subtokens
first). When a subtoken is added, the counts of each of its prefixes are
decreased. Prefixes that don’t appear much outside the subtoken are not added
to the candidate list.</p>
<dl class="docutils">
<dt>For example:</dt>
<dd>subtoken being added to candidate list: ‘translate’
subtoken_counts: {‘translate’:10, ‘t’:40, ‘tr’:16, ‘tra’:12, …}
min_count: 5</dd>
<dt>When ‘translate’ is added, subtoken_counts is updated to:</dt>
<dd>{‘translate’:0, ‘t’:30, ‘tr’:6, ‘tra’: 2, …}</dd>
</dl>
<p>The subtoken ‘tra’ will not be added to the candidate list, because it appears
twice (less than min_count) outside of ‘translate’.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>subtoken_counts</strong> – defaultdict mapping str subtokens to int counts</li>
<li><strong>min_count</strong> – int minumum count requirement for subtokens</li>
<li><strong>alphabet</strong> – set of characters. Each character is added to the subtoken list to
guarantee that all tokens can be encoded.</li>
<li><strong>reserved_tokens</strong> – list of tokens that will be added to the beginning of the
returned subtoken list.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">List of candidate subtokens in decreasing count order, and maximum subtoken
length</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="data.text2text.tokenizer._generate_alphabet_dict">
<code class="descclassname">data.text2text.tokenizer.</code><code class="descname">_generate_alphabet_dict</code><span class="sig-paren">(</span><em>iterable</em>, <em>reserved_tokens=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#_generate_alphabet_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer._generate_alphabet_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Create set of characters that appear in any element in the iterable.</p>
</dd></dl>

<dl class="function">
<dt id="data.text2text.tokenizer._generate_subtokens">
<code class="descclassname">data.text2text.tokenizer.</code><code class="descname">_generate_subtokens</code><span class="sig-paren">(</span><em>token_counts</em>, <em>alphabet</em>, <em>min_count</em>, <em>num_iterations=4</em>, <em>reserved_tokens=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#_generate_subtokens"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer._generate_subtokens" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a list of subtokens in decreasing order of frequency.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>token_counts</strong> – dict mapping str tokens -&gt; int count</li>
<li><strong>alphabet</strong> – set of characters</li>
<li><strong>min_count</strong> – int minimum number of times a subtoken must appear before it is
added to the vocabulary.</li>
<li><strong>num_iterations</strong> – int number of iterations to generate new tokens.</li>
<li><strong>reserved_tokens</strong> – list of tokens that will be added to the beginning to the
returned subtoken list.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">Sorted list of subtokens (most frequent first)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="data.text2text.tokenizer._generate_subtokens_with_target_vocab_size">
<code class="descclassname">data.text2text.tokenizer.</code><code class="descname">_generate_subtokens_with_target_vocab_size</code><span class="sig-paren">(</span><em>token_counts</em>, <em>alphabet</em>, <em>target_size</em>, <em>threshold</em>, <em>min_count=None</em>, <em>reserved_tokens=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#_generate_subtokens_with_target_vocab_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer._generate_subtokens_with_target_vocab_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate subtoken vocabulary close to the target size.</p>
</dd></dl>

<dl class="function">
<dt id="data.text2text.tokenizer._list_to_index_dict">
<code class="descclassname">data.text2text.tokenizer.</code><code class="descname">_list_to_index_dict</code><span class="sig-paren">(</span><em>lst</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#_list_to_index_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer._list_to_index_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Create dictionary mapping list items to their indices in the list.</p>
</dd></dl>

<dl class="function">
<dt id="data.text2text.tokenizer._load_vocab_file">
<code class="descclassname">data.text2text.tokenizer.</code><code class="descname">_load_vocab_file</code><span class="sig-paren">(</span><em>vocab_file</em>, <em>reserved_tokens=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#_load_vocab_file"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer._load_vocab_file" title="Permalink to this definition">¶</a></dt>
<dd><p>Load vocabulary while ensuring reserved tokens are at the top.</p>
</dd></dl>

<dl class="function">
<dt id="data.text2text.tokenizer._native_to_unicode">
<code class="descclassname">data.text2text.tokenizer.</code><code class="descname">_native_to_unicode</code><span class="sig-paren">(</span><em>s</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#_native_to_unicode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer._native_to_unicode" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert string to unicode (required in Python 2).</p>
</dd></dl>

<dl class="function">
<dt id="data.text2text.tokenizer._save_vocab_file">
<code class="descclassname">data.text2text.tokenizer.</code><code class="descname">_save_vocab_file</code><span class="sig-paren">(</span><em>vocab_file</em>, <em>subtoken_list</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#_save_vocab_file"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer._save_vocab_file" title="Permalink to this definition">¶</a></dt>
<dd><p>Save subtokens to file.</p>
</dd></dl>

<dl class="function">
<dt id="data.text2text.tokenizer._split_string_to_tokens">
<code class="descclassname">data.text2text.tokenizer.</code><code class="descname">_split_string_to_tokens</code><span class="sig-paren">(</span><em>text</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#_split_string_to_tokens"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer._split_string_to_tokens" title="Permalink to this definition">¶</a></dt>
<dd><p>Splits text to a list of string tokens.</p>
</dd></dl>

<dl class="function">
<dt id="data.text2text.tokenizer._split_token_to_subtokens">
<code class="descclassname">data.text2text.tokenizer.</code><code class="descname">_split_token_to_subtokens</code><span class="sig-paren">(</span><em>token</em>, <em>subtoken_dict</em>, <em>max_subtoken_length</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#_split_token_to_subtokens"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer._split_token_to_subtokens" title="Permalink to this definition">¶</a></dt>
<dd><p>Splits a token into subtokens defined in the subtoken dict.</p>
</dd></dl>

<dl class="function">
<dt id="data.text2text.tokenizer._unicode_to_native">
<code class="descclassname">data.text2text.tokenizer.</code><code class="descname">_unicode_to_native</code><span class="sig-paren">(</span><em>s</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#_unicode_to_native"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer._unicode_to_native" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert string from unicode to native format (required in Python 2).</p>
</dd></dl>

<dl class="function">
<dt id="data.text2text.tokenizer.join_tokens_to_string">
<code class="descclassname">data.text2text.tokenizer.</code><code class="descname">join_tokens_to_string</code><span class="sig-paren">(</span><em>tokens</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#join_tokens_to_string"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer.join_tokens_to_string" title="Permalink to this definition">¶</a></dt>
<dd><p>Join a list of string tokens into a single string.</p>
</dd></dl>

<dl class="function">
<dt id="data.text2text.tokenizer.unescape_token">
<code class="descclassname">data.text2text.tokenizer.</code><code class="descname">unescape_token</code><span class="sig-paren">(</span><em>token</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/text2text/tokenizer.html#unescape_token"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.text2text.tokenizer.unescape_token" title="Permalink to this definition">¶</a></dt>
<dd><p>Replaces escaped characters in the token with their unescaped versions.</p>
<dl class="docutils">
<dt>Applies inverse transformations as _escape_token():</dt>
<dd><ol class="first last arabic simple">
<li>Replace “u” with “_”, and “&quot; with “”.</li>
<li>Replace “###;” with the unicode character the ### refers to.</li>
</ol>
</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>token</strong> – escaped string</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">unescaped string</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="data.text2speech.html" class="btn btn-neutral float-right" title="text2speech" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="data.speech2text.html" class="btn btn-neutral" title="speech2text" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, NVIDIA.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.2',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  <script type="text/javascript">
      jQuery(function () {
          
          SphinxRtdTheme.Navigation.enableSticky();
          
      });
  </script>  
  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #64d81c;
    }
    .wy-side-nav-search > div.version {
      color: #ffffff;
    }
    .wy-side-nav-search > img {
      max-width: 150px;
    }
    .wy-side-nav-search > a {
      font-size: 23px;
    }
  </style>


</body>
</html>