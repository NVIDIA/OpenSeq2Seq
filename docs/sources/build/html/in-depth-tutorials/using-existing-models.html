

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Using existing models &mdash; OpenSeq2Seq 0.2 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Internal structure" href="internal-structure.html" />
    <link rel="prev" title="In-depth tutorials" href="../in-depth-tutorials.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> OpenSeq2Seq
          

          
            
            <img src="../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation-instructions.html">Installation instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting-started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models-and-recipes.html">Models and recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distr-training.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mixed-precision.html">Mixed precision training</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../in-depth-tutorials.html">In-depth tutorials</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Using existing models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#how-to-run-models">How to run models</a></li>
<li class="toctree-l3"><a class="reference internal" href="#config-parameters">Config parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="#what-is-being-logged">What is being logged</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="internal-structure.html">Internal structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../extending.html">Adding new models</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api-docs/modules.html">API documentation</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">OpenSeq2Seq</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../in-depth-tutorials.html">In-depth tutorials</a> &raquo;</li>
        
      <li>Using existing models</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/in-depth-tutorials/using-existing-models.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="using-existing-models">
<h1>Using existing models<a class="headerlink" href="#using-existing-models" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial we will describe everything you can do with OpenSeq2Seq without
writing any new code. We will cover the following topics: how to run one of
the implemented models (for training, evaluation or inference), what parameters
can be specified in the config file/command line and what are the different
kinds of output that OpenSeq2Seq generates for you.</p>
<div class="section" id="how-to-run-models">
<h2>How to run models<a class="headerlink" href="#how-to-run-models" title="Permalink to this headline">¶</a></h2>
<p>There are two scripts that can be used to run the models: <code class="docutils literal"><span class="pre">run.py</span></code> and
<code class="docutils literal"><span class="pre">start_experiment.sh</span></code>. The latter one is just a convenient bash
wrapper around <code class="docutils literal"><span class="pre">run.py</span></code> that adds additional functionality, so we will
describe it in the end. Since <code class="docutils literal"><span class="pre">run.py</span></code> is a fairly simple Python script,
you can probably understand
how to use it by running <code class="docutils literal"><span class="pre">run.py</span> <span class="pre">--help</span></code> which will display all available
command line parameters and their short description. If that does not contain
enough details, continue reading this section. Otherwise, just skip to the
description of <code class="docutils literal"><span class="pre">start_experiment.sh</span></code> script (last paragraph of this section).</p>
<p>There are 2 main parameters of <code class="docutils literal"><span class="pre">run.py</span></code> that will be
used most often: <code class="docutils literal"><span class="pre">--config_file</span></code> and <code class="docutils literal"><span class="pre">--mode</span></code>. The first one is a required
parameter with path to the python configuration file (described in the <a class="reference internal" href="#config-params"><span class="std std-ref">next
section</span></a>). <code class="docutils literal"><span class="pre">--mode</span></code> parameter can be one of the “train”,
“eval”, “train_eval” or “infer”. This will do what it says: run the model in
the corresponding mode (with “train_eval” executing training with periodic
evaluation). The other parameters of the <code class="docutils literal"><span class="pre">run.py</span></code> script are the following:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">--continue_learning</span></code> — specify this when you want to continue learning
from existing checkpoint. This parameter is only checked when <code class="docutils literal"><span class="pre">--mode</span></code> is
“train” or “train_eval”.</li>
<li><code class="docutils literal"><span class="pre">--infer_output_file</span></code> — this specifies the path to output of the inference.
This parameter is only checked when <code class="docutils literal"><span class="pre">--mode</span></code> is “infer”.</li>
<li><code class="docutils literal"><span class="pre">--no_dir_check</span></code> — this parameter disables log directory checking.
By default, <code class="docutils literal"><span class="pre">run.py</span></code> will be checking that the log
directory (specified in the python config) is valid. Specifically, it will
check that it exists when <code class="docutils literal"><span class="pre">--mode</span></code> equals “eval” or “infer”
(or when <code class="docutils literal"><span class="pre">--continue_learning</span></code> is specified for training). If training is
performed, but <code class="docutils literal"><span class="pre">--continue_learning</span></code> is not specified, the script will check
that log directory is empty or does not exist, otherwise finishing with
exception. Finally, whenever necessary it will check that the log directory
contains a valid TensorFlow checkpoint of the saved model.</li>
<li><code class="docutils literal"><span class="pre">--benchmark</span></code> — specifying this parameter will automatically prepare config
for time benchmarking: disable all logging and evaluation. This parameter is
only useful for training benchmarking, since in other cases no config
preparation is needed. Moreover, specifying it will force the model to run
in the “train” mode.</li>
<li><code class="docutils literal"><span class="pre">--bench_steps</span></code> — number of steps to run the model for benchmarking. For
now this can only be used in conjunction with <code class="docutils literal"><span class="pre">--benchmark</span></code> parameter and
thus only works in the training benchmarking.</li>
<li><code class="docutils literal"><span class="pre">--bench_start</span></code> — first step to start counting time for benchmarking. This
parameter works in all modes whether or not <code class="docutils literal"><span class="pre">--benchmark</span></code> parameter was
specified.</li>
<li><code class="docutils literal"><span class="pre">--debug</span></code> — this enables TensorFlow debugging. To use it first run
<code class="docutils literal"><span class="pre">tensorboard</span> <span class="pre">--logdir=.</span> <span class="pre">--debugger_port=6067</span></code> and while tensorboard is
running execute <code class="docutils literal"><span class="pre">run.py</span></code> with <code class="docutils literal"><span class="pre">--debug</span></code> attribute. After that tensorboard
should have debugging tab.</li>
</ul>
<p>In order to make it more convenient to run multiple experiments we provide
<code class="docutils literal"><span class="pre">start_experiment.sh</span></code> script that is a wrapper around <code class="docutils literal"><span class="pre">run.py</span></code> script which
does the following things. First, it will make sure that the complete output of
<code class="docutils literal"><span class="pre">run.py</span></code> is saved inside the log directory (in the “output_&lt;time stamp&gt;.log
file, where &lt;time stamp&gt; is a string with current date and time to make sure
that everything is saved if you run this script multiple times).
Second, it will log the current git commit and git diff in the
“gitinfo_&lt;time stamp&gt;.log” file to make it possible to completely reproduce the
experiment. Finally, it will save the current experiment configuration in the
“config_&lt;time stamp&gt;.py” file. To run <code class="docutils literal"><span class="pre">start_experiment.sh</span></code> you will need to
define the following environment variables: <code class="docutils literal"><span class="pre">LOGDIR</span></code> (path to the desired log
directory), <code class="docutils literal"><span class="pre">CONFIG_FILE</span></code> (path to the Python configuration file), <code class="docutils literal"><span class="pre">MODE</span></code>
(mode to execute <code class="docutils literal"><span class="pre">run.py</span></code> in) and <code class="docutils literal"><span class="pre">CONTINUE_LEARNING</span></code> (whether to specify
<code class="docutils literal"><span class="pre">--continue_learning</span></code> flag for <code class="docutils literal"><span class="pre">run.py</span></code>, could be 1 or 0). For example to
train DeepSpeech2-like model on the toy speech data you can run:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">LOGDIR</span><span class="o">=</span><span class="n">experiments</span><span class="o">/</span><span class="n">librispeech</span> <span class="n">CONFIG_FILE</span><span class="o">=</span><span class="n">example_configs</span><span class="o">/</span><span class="n">speech2text</span><span class="o">/</span><span class="n">ds2_toy_data_config</span><span class="o">.</span><span class="n">py</span> <span class="n">MODE</span><span class="o">=</span><span class="n">train_eval</span> <span class="n">CONTINUE_LEARNING</span><span class="o">=</span><span class="mi">0</span> <span class="o">./</span><span class="n">start_experiment</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
</div>
<div class="section" id="config-parameters">
<h2>Config parameters<a class="headerlink" href="#config-parameters" title="Permalink to this headline">¶</a></h2>
<p>The experiment parameters are completely defined in one Python configuration
file. This file must define <code class="docutils literal"><span class="pre">base_params</span></code> dictionary and can define additional
<code class="docutils literal"><span class="pre">train_params</span></code>, <code class="docutils literal"><span class="pre">eval_params</span></code> and <code class="docutils literal"><span class="pre">infer_params</span></code> dictionaries that will
overwrite corresponding parts of <code class="docutils literal"><span class="pre">base_params</span></code> when the corresponding mode
is used. For example of configuration file look in the <code class="docutils literal"><span class="pre">example_configs</span></code>
directory. The complete list of all possible configuration parameters is
located in the documentation of
<a class="reference internal" href="#utils.model_builders.create_encoder_decoder_loss_model" title="utils.model_builders.create_encoder_decoder_loss_model"><code class="xref py py-func docutils literal"><span class="pre">create_encoder_decoder_loss_model</span></code></a> function (config
parameters section):</p>
<dl class="function">
<dt id="utils.model_builders.create_encoder_decoder_loss_model">
<code class="descclassname">utils.model_builders.</code><code class="descname">create_encoder_decoder_loss_model</code><span class="sig-paren">(</span><em>config</em>, <em>mode</em>, <em>hvd</em>, <em>reuse=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/utils/model_builders.html#create_encoder_decoder_loss_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#utils.model_builders.create_encoder_decoder_loss_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a model specified in the configuration file.
This function takes in Python config and creates all parts of the model:
data layer, encoder, decoder and loss. They are all then combined in one
model instance which is returned.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>config</strong> (<em>dict</em>) – dictionary containing run parameters. For complete list of
possible values see “Config parameters” section.</li>
<li><strong>mode</strong> (<em>str</em>) – mode to create the model in. Could be “train”, “eval” or “infer”.</li>
<li><strong>hvd</strong> – if Horovod is used, this should be <code class="docutils literal"><span class="pre">horovod.tensorflow</span></code> module.
If Horovod is not used it should be None.</li>
<li><strong>reuse</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to reuse variables in the model. Useful
for creating evaluation model during training.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">instance of <code class="docutils literal"><span class="pre">base_model</span></code> class specified in the config.</p>
</td>
</tr>
</tbody>
</table>
<p>Config parameters:</p>
<ul class="simple">
<li><strong>random_seed</strong> (int) — random seed to use.</li>
<li><strong>use_horovod</strong> (bool) — whether to use Horovod for distributed execution.</li>
<li><strong>num_gpus</strong> (int) — number of GPUs to use. When <code class="docutils literal"><span class="pre">use_horovod</span></code> is True
this parameter is ignored.</li>
<li><strong>batch_size_per_gpu</strong> (int) — batch size to use for each GPU.</li>
<li><strong>num_epochs</strong> (int) — number of epochs to run training for.
This parameter cannot be used if <code class="docutils literal"><span class="pre">max_steps</span></code> is specified.</li>
<li><strong>max_steps</strong> (int) — number of steps to run training for.
This parameter cannot be used if <code class="docutils literal"><span class="pre">num_epochs</span></code> is specified.</li>
<li><strong>save_summaries_steps</strong> (int or None) — how often to save summaries.
Setting it to None disables summaries saving.</li>
<li><strong>print_loss_steps</strong> (int or None) — how often to print loss during
training. Setting it to None disables loss printing.</li>
<li><strong>print_sample_steps</strong> (int or None) — how often to print training samples
(input sequences, correct answers and model predictions).
Setting it to None disables samples printing.</li>
<li><strong>save_checkpoint_steps</strong> (int or None) — how often to save model
checkpoints. Setting it to None disables checkpoint saving.</li>
<li><strong>eval_steps</strong> (int) — how often to run evaluation during training.
This parameter is only checked if <code class="docutils literal"><span class="pre">--mode</span></code> argument of <code class="docutils literal"><span class="pre">run.py</span></code> is
“train_eval”. If no evaluation is needed you should use “train” mode.</li>
<li><strong>logdir</strong> (string) — path to the log directory where all checkpoints and
summaries will be saved.</li>
<li><strong>base_model</strong> (any class derived from
<a class="reference internal" href="../api-docs/models.html#models.model.Model" title="models.model.Model"><code class="xref py py-class docutils literal"><span class="pre">Model</span></code></a>) — base model class to use.
Currently can only be <a class="reference internal" href="../api-docs/models.html#models.speech2text.Speech2Text" title="models.speech2text.Speech2Text"><code class="xref py py-class docutils literal"><span class="pre">Speech2Text</span></code></a>
or
<a class="reference internal" href="../api-docs/models.html#models.text2text.BasicText2TextWithAttention" title="models.text2text.BasicText2TextWithAttention"><code class="xref py py-class docutils literal"><span class="pre">BasicText2TextWithAttention</span></code></a>.
Note that this parameter is not a string, but an actual Python class, so you
will need to add corresponding imports in the configuration file.</li>
<li><strong>model_params</strong> (dict) — dictionary with model configuration. For
complete list of possible parameters see the corresponding class docs.</li>
<li><strong>data_layer</strong> (any class derived from
<a class="reference internal" href="../api-docs/data.html#data.data_layer.DataLayer" title="data.data_layer.DataLayer"><code class="xref py py-class docutils literal"><span class="pre">DataLayer</span></code></a>) — data layer class to use.</li>
<li><strong>data_layer_params</strong> (dict) — dictionary with data layer configuration.
For complete list of possible parameters see the corresponding class docs.</li>
<li><strong>encoder</strong> (any class derived from
<a class="reference internal" href="../api-docs/encoders.html#encoders.encoder.Encoder" title="encoders.encoder.Encoder"><code class="xref py py-class docutils literal"><span class="pre">Encoder</span></code></a>) — encoder class to use.</li>
<li><strong>encoder_params</strong> (dict) — dictionary with encoder configuration. For
complete list of possible parameters see the corresponding class docs.</li>
<li><strong>decoder</strong> (any class derived from
<a class="reference internal" href="../api-docs/decoders.html#decoders.decoder.Decoder" title="decoders.decoder.Decoder"><code class="xref py py-class docutils literal"><span class="pre">Decoder</span></code></a>) — decoder class to use.</li>
<li><strong>decoder_params</strong> (dict) — dictionary with decoder configuration. For
complete list of possible parameters see the corresponding class docs.</li>
<li><strong>loss</strong> (any class derived from
<a class="reference internal" href="../api-docs/losses.html#losses.loss.Loss" title="losses.loss.Loss"><code class="xref py py-class docutils literal"><span class="pre">Loss</span></code></a>) — loss class to use.</li>
<li><strong>loss_params</strong> (dict) — dictionary with loss configuration. For
complete list of possible parameters see the corresponding class docs.</li>
</ul>
</dd></dl>

<p>Note that some of the parameters are also config dictionaries for corresponding
classes. To see list of their configuration options, you should proceed to the
corresponding class docs. For example, to see all supported model parameters,
look into the docs for <a class="reference internal" href="../api-docs/models.html#models.model.Model" title="models.model.Model"><code class="xref py py-class docutils literal"><span class="pre">models.model.Model</span></code></a>. Sometimes, derived classes
might define their additional parameters, in that case you should be looking
into both, parent class and its child. As an example, see
<a class="reference internal" href="../api-docs/encoders.html#encoders.encoder.Encoder" title="encoders.encoder.Encoder"><code class="xref py py-class docutils literal"><span class="pre">encoders.encoder.Encoder</span></code></a> (which defines some parameters shared across
all encoders) and <a class="reference internal" href="../api-docs/encoders.html#encoders.ds2_encoder.DeepSpeech2Encoder" title="encoders.ds2_encoder.DeepSpeech2Encoder"><code class="xref py py-class docutils literal"><span class="pre">encoders.ds2_encoder.DeepSpeech2Encoder</span></code></a> (which
additionally defines a set of DeepSpeech-2 specific parameters).</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">For convenience all <em>first level</em> parameters can be overwritten by
command line arguments. For example, try to add <code class="docutils literal"><span class="pre">--logdir</span></code> argument
to your <code class="docutils literal"><span class="pre">run.py</span></code> execution.</p>
</div>
</div>
<div class="section" id="what-is-being-logged">
<h2>What is being logged<a class="headerlink" href="#what-is-being-logged" title="Permalink to this headline">¶</a></h2>
<p>This section is going to be completed soon.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="internal-structure.html" class="btn btn-neutral float-right" title="Internal structure" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../in-depth-tutorials.html" class="btn btn-neutral" title="In-depth tutorials" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, NVIDIA.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.2',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  <script type="text/javascript">
      jQuery(function () {
          
          SphinxRtdTheme.Navigation.enableSticky();
          
      });
  </script>  
  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #64d81c;
    }
    .wy-side-nav-search > div.version {
      color: #ffffff;
    }
    .wy-side-nav-search > img {
      max-width: 150px;
    }
    .wy-side-nav-search > a {
      font-size: 23px;
    }
  </style>


</body>
</html>