

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>models &mdash; OpenSeq2Seq 0.2 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="data" href="data.html" />
    <link rel="prev" title="API documentation" href="modules.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> OpenSeq2Seq
          

          
            
            <img src="../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation-instructions.html">Installation instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting-started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models-and-recipes.html">Models and recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distr-training.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mixed-precision.html">Mixed precision training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../in-depth-tutorials.html">In-depth tutorials</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">API documentation</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-models.model">model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-models.seq2seq">seq2seq</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-models.speech2text">speech2text</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-models.text2text">text2text</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="data.html">data</a></li>
<li class="toctree-l2"><a class="reference internal" href="encoders.html">encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="decoders.html">decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="losses.html">losses</a></li>
<li class="toctree-l2"><a class="reference internal" href="optimizers.html">optimizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="parts.html">parts</a></li>
<li class="toctree-l2"><a class="reference internal" href="utils.html">utils</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">OpenSeq2Seq</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="modules.html">API documentation</a> &raquo;</li>
        
      <li>models</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/api-docs/models.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-models">
<span id="models"></span><h1>models<a class="headerlink" href="#module-models" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-models.model">
<span id="model"></span><h2>model<a class="headerlink" href="#module-models.model" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="models.model.Model">
<em class="property">class </em><code class="descclassname">models.model.</code><code class="descname">Model</code><span class="sig-paren">(</span><em>params</em>, <em>data_layer</em>, <em>global_step=None</em>, <em>force_var_reuse=False</em>, <em>mode='train'</em>, <em>gpu_ids=None</em>, <em>hvd=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/model.html#Model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.model.Model" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Abstract class that any model should inherit from.
It automatically enables multi-GPU (or Horovod) computation,
has mixed precision support, logs training summaries, etc.</p>
<dl class="method">
<dt id="models.model.Model.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>params</em>, <em>data_layer</em>, <em>global_step=None</em>, <em>force_var_reuse=False</em>, <em>mode='train'</em>, <em>gpu_ids=None</em>, <em>hvd=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/model.html#Model.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.model.Model.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Model constructor. The TensorFlow graph is created here.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>params</strong> (<em>dict</em>) – parameters describing the model.
All supported parameters are listed in <a class="reference internal" href="#models.model.Model.get_required_params" title="models.model.Model.get_required_params"><code class="xref py py-meth docutils literal"><span class="pre">get_required_params()</span></code></a>,
<a class="reference internal" href="#models.model.Model.get_optional_params" title="models.model.Model.get_optional_params"><code class="xref py py-meth docutils literal"><span class="pre">get_optional_params()</span></code></a> functions.</li>
<li><strong>data_layer</strong> (<a class="reference internal" href="data.html#data.data_layer.DataLayer" title="data.data_layer.DataLayer"><em>DataLayer</em></a>) – The <code class="xref py py-class docutils literal"><span class="pre">DataLayer</span></code> instance to take data from.</li>
<li><strong>global_step</strong> (<em>optional</em>) – TensorFlow global step or None</li>
<li><strong>force_var_reuse</strong> (<em>bool</em><em>, </em><em>optional</em>) – if true, all variables will be re-used.
Useful for creating evaluation model alongside the training model or
for multi-GPU training.</li>
<li><strong>mode</strong> (<em>string</em><em>, </em><em>optional</em>) – “train”, “eval” or “infer”.
If mode is “train” all parts of the graph will be built
(model, loss, optimizer).
If mode is “eval”, only model and loss will be built.
If mode is “infer”, only model will be built.</li>
<li><strong>gpu_ids</strong> (<em>list</em><em>, </em><em>optional</em>) – a list of gpu ids to run the model on.
For distributed training using Horovod this parameter is ignored.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Config parameters:</p>
<ul class="simple">
<li><strong>learning_rate</strong> (float) — initial learning rate for training.</li>
<li><strong>optimizer</strong> (string or TensorFlow optimizer class) — optimizer to
use for training. Could be either “Adam”, “Adagrad”, “Ftrl”, “Momentum”,
“RMSProp”, “SGD” or any valid TensorFlow optimizer class.</li>
<li><strong>optimizer_params</strong> (dict) — dictionary that will be passed to
optimizer <code class="docutils literal"><span class="pre">__init__</span></code> method.</li>
<li><strong>initializer</strong> — any valid TensorFlow initializer.</li>
<li><strong>initializer_params</strong> (dict) — dictionary that will be passed to
initializer <code class="docutils literal"><span class="pre">__init__</span></code> method.</li>
<li><strong>regularizer</strong> — and valid TensorFlow regularizer.</li>
<li><strong>regularizer_params</strong> (dict) — dictionary that will be passed to
regularizer <code class="docutils literal"><span class="pre">__init__</span></code> method.</li>
<li><strong>dtype</strong> — model dtype. Could be either <code class="docutils literal"><span class="pre">tf.float16</span></code>, <code class="docutils literal"><span class="pre">tf.float32</span></code>
or “mixed”. For details see
<a class="reference internal" href="../mixed-precision.html#mixed-precision"><span class="std std-ref">mixed precision training</span></a> section in docs.</li>
<li><strong>lr_policy</strong> — any valid learning rate policy function. For examples,
see <a class="reference internal" href="optimizers.html#module-optimizers.lr_policies" title="optimizers.lr_policies"><code class="xref any py py-mod docutils literal"><span class="pre">optimizers.lr_policies</span></code></a> module.</li>
<li><strong>lr_policy_params</strong> (dict) — dictionary containing lr_policy
parameters.</li>
<li><strong>max_grad_norm</strong> (float) — maximum value of gradient norm. Clipping
will be performed if some gradients exceed this value (this is checked
for each variable independently).</li>
<li><strong>larc_mode</strong> — specify this to use LARC or LARS optimization
algorithms. Could be either “scale” (LARS) or “clip” (LARC).
You also need to specify <code class="docutils literal"><span class="pre">larc_nu</span></code> to enable LARC or LARS. Note that
it works in addition to any other optimization algorithm since we treat
it as adaptive gradient clipping and learning rate adjustment.</li>
<li><strong>larc_nu</strong> (float) — LARC or LARS scaling parameter.</li>
<li><strong>loss_scale</strong> (float) — static loss scale to use. For details see
<a class="reference internal" href="../mixed-precision.html#mixed-precision"><span class="std std-ref">mixed precision training</span></a> section in docs.</li>
<li><strong>autimatic_loss_scaling</strong> — automatic loss scaling mode. Could be
either None, “Backoff” or “Logmax”. For details see
<a class="reference internal" href="../mixed-precision.html#mixed-precision"><span class="std std-ref">mixed precision training</span></a> section in docs.</li>
<li><strong>summaries</strong> (list) — which summaries to log. Could contain
“learning_rate”, “gradients”, “gradient_norm”, “global_gradient_norm”,
“variables”, “variable_norm”.</li>
</ul>
</dd></dl>

<dl class="method">
<dt id="models.model.Model._build_forward_pass_graph">
<code class="descname">_build_forward_pass_graph</code><span class="sig-paren">(</span><em>input_tensors</em>, <em>gpu_id=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/model.html#Model._build_forward_pass_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.model.Model._build_forward_pass_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Abstract method. Should create the graph of the forward pass of the model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input_tensors</strong> (<em>list</em>) – list of all input tensors
required to build the model.</li>
<li><strong>gpu_id</strong> (<em>int</em><em>, </em><em>optional</em>) – id of the GPU where the current copy of the model
is constructed. For Horovod this is always zero.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><p>tuple containing loss tensor and samples tensor.</p>
<p>Loss tensor will be automatically provided to the optimizer and
corresponding <code class="xref py py-attr docutils literal"><span class="pre">train_op</span></code> will be created.</p>
<p>Samples tensors are stored in the <code class="xref py py-attr docutils literal"><span class="pre">_outputs</span></code> attribute and can be
accessed by calling <a class="reference internal" href="#models.model.Model.get_output_tensors" title="models.model.Model.get_output_tensors"><code class="xref py py-meth docutils literal"><span class="pre">get_output_tensors()</span></code></a> function. For example,
this happens inside <a class="reference internal" href="utils.html#utils.hooks.RunEvaluationHook" title="utils.hooks.RunEvaluationHook"><code class="xref py py-class docutils literal"><span class="pre">utils.hooks.RunEvaluationHook</span></code></a>
to fetch output values for evaluation.</p>
<p>Both loss and samples can be None when corresponding part of the graph
is not built.</p>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">tuple</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="models.model.Model.data_layer">
<code class="descname">data_layer</code><a class="headerlink" href="#models.model.Model.data_layer" title="Permalink to this definition">¶</a></dt>
<dd><p>Model data layer.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="models.model.Model.get_optional_params">
<em class="property">static </em><code class="descname">get_optional_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/model.html#Model.get_optional_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.model.Model.get_optional_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of optional parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>can</strong> be
included into the <code class="docutils literal"><span class="pre">params</span></code> parameter of the
class <a class="reference internal" href="#models.model.Model.__init__" title="models.model.Model.__init__"><code class="xref py py-meth docutils literal"><span class="pre">__init__()</span></code></a> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="models.model.Model.get_output_tensors">
<code class="descname">get_output_tensors</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/model.html#Model.get_output_tensors"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.model.Model.get_output_tensors" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns output tensors generated by <code class="xref py py-meth docutils literal"><span class="pre">_build_forward_pass_graph.()</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">list with output tensors.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">list</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="models.model.Model.get_required_params">
<em class="property">static </em><code class="descname">get_required_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/model.html#Model.get_required_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.model.Model.get_required_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of required parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>have to</strong> be
included into the <code class="docutils literal"><span class="pre">params</span></code> parameter of the
class <a class="reference internal" href="#models.model.Model.__init__" title="models.model.Model.__init__"><code class="xref py py-meth docutils literal"><span class="pre">__init__()</span></code></a> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="models.model.Model.get_tf_dtype">
<code class="descname">get_tf_dtype</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/model.html#Model.get_tf_dtype"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.model.Model.get_tf_dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns actual TesnorFlow dtype that will be used as variables dtype.</p>
</dd></dl>

<dl class="method">
<dt id="models.model.Model.infer">
<code class="descname">infer</code><span class="sig-paren">(</span><em>inputs_per_batch</em>, <em>outputs_per_batch</em>, <em>output_file</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/model.html#Model.infer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.model.Model.infer" title="Permalink to this definition">¶</a></dt>
<dd><p>This function should be implemented if the model support inference mode.
For example for speech-to-text and text-to-text models, this function will
log the corresponding input-output pair to the output_file.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>inputs_per_batch</strong> (<em>list</em>) – list with evaluation of
<a class="reference internal" href="data.html#data.data_layer.DataLayer.get_input_tensors" title="data.data_layer.DataLayer.get_input_tensors"><code class="xref py py-meth docutils literal"><span class="pre">self.data_layer.get_input_tensors()</span></code></a>
for each batch in evaluation dataset.</li>
<li><strong>outputs_per_batch</strong> (<em>list</em>) – list with evaluation of
<a class="reference internal" href="#models.model.Model.get_output_tensors" title="models.model.Model.get_output_tensors"><code class="xref py py-meth docutils literal"><span class="pre">self.get_output_tensors()</span></code></a>
for each batch in evaluation dataset.</li>
<li><strong>output_file</strong> (<em>str</em>) – name of the output file that inference results should
be saved to.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="models.model.Model.last_step">
<code class="descname">last_step</code><a class="headerlink" href="#models.model.Model.last_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of steps the training should be run for.</p>
</dd></dl>

<dl class="method">
<dt id="models.model.Model.maybe_evaluate">
<code class="descname">maybe_evaluate</code><span class="sig-paren">(</span><em>inputs_per_batch</em>, <em>outputs_per_batch</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/model.html#Model.maybe_evaluate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.model.Model.maybe_evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>This function can be used to calculate evaluation metrics.
For example, for speech-to-text models this function can calculate
word-error-rate on the validation data. For text-to-text models, this
function can compute BLEU score. Look at the corresponding derived classes
for examples of this. This function will be called every
<code class="docutils literal"><span class="pre">eval_steps</span></code> (config parameter) iterations and
input/output values will be populated automatically by calling <code class="docutils literal"><span class="pre">sess.run</span></code>
on corresponding tensors for each batch (using evaluation model). Note that
this function is not abstract and does not have to be implemented in
derived classes. But if evaluation functionality is required,
overwriting this function can be a useful way to add it.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inputs_per_batch</strong> (<em>list</em>) – list with evaluation of
<a class="reference internal" href="data.html#data.data_layer.DataLayer.get_input_tensors" title="data.data_layer.DataLayer.get_input_tensors"><code class="xref py py-meth docutils literal"><span class="pre">self.data_layer.get_input_tensors()</span></code></a>
for each batch in evaluation dataset.</li>
<li><strong>outputs_per_batch</strong> (<em>list</em>) – list with evaluation of
<a class="reference internal" href="#models.model.Model.get_output_tensors" title="models.model.Model.get_output_tensors"><code class="xref py py-meth docutils literal"><span class="pre">self.get_output_tensors()</span></code></a>
for each batch in evaluation dataset.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">dictionary with values that need to be logged to TensorBoard (can be empty).</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">dict</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="models.model.Model.maybe_print_logs">
<code class="descname">maybe_print_logs</code><span class="sig-paren">(</span><em>input_values</em>, <em>output_values</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/model.html#Model.maybe_print_logs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.model.Model.maybe_print_logs" title="Permalink to this definition">¶</a></dt>
<dd><p>This function can be used to print logs that help to visualize training.
For example, you can print sample input sequences and their corresponding
predictions. This function will be called every <code class="docutils literal"><span class="pre">print_samples_steps</span></code>
(config parameter) iterations and input/output values will be populated
automatically by calling <code class="docutils literal"><span class="pre">sess.run</span></code> on corresponding tensors. Note that
this function is not abstract and does not have to be implemented in
derived classes. But if additional printing functionality is required,
overwriting this function can be a useful way to add it.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input_values</strong> – evaluation of <a class="reference internal" href="data.html#data.data_layer.DataLayer.get_input_tensors" title="data.data_layer.DataLayer.get_input_tensors"><code class="xref py py-meth docutils literal"><span class="pre">self.data_layer.get_input_tensors()</span></code></a>.</li>
<li><strong>output_values</strong> – evaluation of <a class="reference internal" href="#models.model.Model.get_output_tensors" title="models.model.Model.get_output_tensors"><code class="xref py py-meth docutils literal"><span class="pre">self.get_output_tensors()</span></code></a>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">dictionary with values that need to be logged to TensorBoard (can be empty).</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">dict</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="models.model.Model.mode">
<code class="descname">mode</code><a class="headerlink" href="#models.model.Model.mode" title="Permalink to this definition">¶</a></dt>
<dd><p>Mode the model is executed in (“train”, “eval” or “infer”).</p>
</dd></dl>

<dl class="attribute">
<dt id="models.model.Model.num_gpus">
<code class="descname">num_gpus</code><a class="headerlink" href="#models.model.Model.num_gpus" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of GPUs the model will be run on.
For Horovod this is always 1 and actual number of GPUs is controlled by
mpi parameters.</p>
</dd></dl>

<dl class="attribute">
<dt id="models.model.Model.on_horovod">
<code class="descname">on_horovod</code><a class="headerlink" href="#models.model.Model.on_horovod" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether the model is run on Horovod or not.</p>
</dd></dl>

<dl class="attribute">
<dt id="models.model.Model.params">
<code class="descname">params</code><a class="headerlink" href="#models.model.Model.params" title="Permalink to this definition">¶</a></dt>
<dd><p>Parameters used to construct the model (dictionary).</p>
</dd></dl>

<dl class="attribute">
<dt id="models.model.Model.step_size">
<code class="descname">step_size</code><a class="headerlink" href="#models.model.Model.step_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of samples the model processes per step.
This parameter is only populated if <code class="docutils literal"><span class="pre">num_epochs</span></code> was specified in the
config. It is used in training hooks to correctly print epoch number.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-models.seq2seq">
<span id="seq2seq"></span><h2>seq2seq<a class="headerlink" href="#module-models.seq2seq" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="models.seq2seq.Seq2Seq">
<em class="property">class </em><code class="descclassname">models.seq2seq.</code><code class="descname">Seq2Seq</code><span class="sig-paren">(</span><em>params</em>, <em>data_layer</em>, <em>encoder</em>, <em>decoder</em>, <em>loss</em>, <em>global_step=None</em>, <em>force_var_reuse=False</em>, <em>mode=None</em>, <em>gpu_ids=None</em>, <em>hvd=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/seq2seq.html#Seq2Seq"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.seq2seq.Seq2Seq" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">open_seq2seq.models.model.Model</span></code></p>
<p>Standard Sequence-to-Sequence class with one encoder and one decoder.
“encoder-decoder-loss” models should inherit from this</p>
<dl class="method">
<dt id="models.seq2seq.Seq2Seq.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>params</em>, <em>data_layer</em>, <em>encoder</em>, <em>decoder</em>, <em>loss</em>, <em>global_step=None</em>, <em>force_var_reuse=False</em>, <em>mode=None</em>, <em>gpu_ids=None</em>, <em>hvd=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/seq2seq.html#Seq2Seq.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.seq2seq.Seq2Seq.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor
:param params: Python dictionary - parameters describing seq2seq model
:param data_layer: Instance of DataLayer
:param encoder: Instance of Encoder
:param decoder: Instance of Decoder
:param loss: Instance of Loss
:param global_step: TF variable - global step
:param force_var_reuse: Boolean - if true, all vars will be re-used
:param mode: string, currently “train” or “infer”
:param gpu_ids: a list of gpu ids, None, or “horovod” string</p>
<blockquote>
<div>for distributed training using Horovod</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="models.seq2seq.Seq2Seq._build_forward_pass_graph">
<code class="descname">_build_forward_pass_graph</code><span class="sig-paren">(</span><em>input_tensors</em>, <em>gpu_id=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/seq2seq.html#Seq2Seq._build_forward_pass_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.seq2seq.Seq2Seq._build_forward_pass_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds forward pass
:param input_tensors: List of Tensors, currently assumes the following:
[source_sequence, src_length, target_sequence, tgt_length]
:param gpu_id: gpu_id where this pass is being built
:return: loss or nothing</p>
</dd></dl>

<dl class="attribute">
<dt id="models.seq2seq.Seq2Seq.decoder">
<code class="descname">decoder</code><a class="headerlink" href="#models.seq2seq.Seq2Seq.decoder" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="models.seq2seq.Seq2Seq.encoder">
<code class="descname">encoder</code><a class="headerlink" href="#models.seq2seq.Seq2Seq.encoder" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="models.seq2seq.Seq2Seq.loss_computator">
<code class="descname">loss_computator</code><a class="headerlink" href="#models.seq2seq.Seq2Seq.loss_computator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-models.speech2text">
<span id="speech2text"></span><h2>speech2text<a class="headerlink" href="#module-models.speech2text" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="models.speech2text.Speech2Text">
<em class="property">class </em><code class="descclassname">models.speech2text.</code><code class="descname">Speech2Text</code><span class="sig-paren">(</span><em>params</em>, <em>data_layer</em>, <em>encoder</em>, <em>decoder</em>, <em>loss</em>, <em>global_step=None</em>, <em>force_var_reuse=False</em>, <em>mode=None</em>, <em>gpu_ids=None</em>, <em>hvd=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/speech2text.html#Speech2Text"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.speech2text.Speech2Text" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#models.seq2seq.Seq2Seq" title="models.seq2seq.Seq2Seq"><code class="xref py py-class docutils literal"><span class="pre">models.seq2seq.Seq2Seq</span></code></a></p>
<dl class="method">
<dt id="models.speech2text.Speech2Text.infer">
<code class="descname">infer</code><span class="sig-paren">(</span><em>inputs_per_batch</em>, <em>outputs_per_batch</em>, <em>output_file</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/speech2text.html#Speech2Text.infer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.speech2text.Speech2Text.infer" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="models.speech2text.Speech2Text.maybe_evaluate">
<code class="descname">maybe_evaluate</code><span class="sig-paren">(</span><em>inputs_per_batch</em>, <em>outputs_per_batch</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/speech2text.html#Speech2Text.maybe_evaluate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.speech2text.Speech2Text.maybe_evaluate" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="models.speech2text.Speech2Text.maybe_print_logs">
<code class="descname">maybe_print_logs</code><span class="sig-paren">(</span><em>input_values</em>, <em>output_values</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/speech2text.html#Speech2Text.maybe_print_logs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.speech2text.Speech2Text.maybe_print_logs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="models.speech2text.levenshtein">
<code class="descclassname">models.speech2text.</code><code class="descname">levenshtein</code><span class="sig-paren">(</span><em>a</em>, <em>b</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/speech2text.html#levenshtein"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.speech2text.levenshtein" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the Levenshtein distance between a and b.</p>
</dd></dl>

<dl class="function">
<dt id="models.speech2text.sparse_tensor_value_to_texts">
<code class="descclassname">models.speech2text.</code><code class="descname">sparse_tensor_value_to_texts</code><span class="sig-paren">(</span><em>value</em>, <em>alphabet</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/speech2text.html#sparse_tensor_value_to_texts"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.speech2text.sparse_tensor_value_to_texts" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a <code class="xref py py-class docutils literal"><span class="pre">tf.SparseTensor</span></code> <code class="docutils literal"><span class="pre">value</span></code>, return an array of
Python strings representing its values.</p>
</dd></dl>

<dl class="function">
<dt id="models.speech2text.sparse_tuple_to_texts">
<code class="descclassname">models.speech2text.</code><code class="descname">sparse_tuple_to_texts</code><span class="sig-paren">(</span><em>tup</em>, <em>alphabet</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/speech2text.html#sparse_tuple_to_texts"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.speech2text.sparse_tuple_to_texts" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-models.text2text">
<span id="text2text"></span><h2>text2text<a class="headerlink" href="#module-models.text2text" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="models.text2text.BasicText2TextWithAttention">
<em class="property">class </em><code class="descclassname">models.text2text.</code><code class="descname">BasicText2TextWithAttention</code><span class="sig-paren">(</span><em>params</em>, <em>data_layer</em>, <em>encoder</em>, <em>decoder</em>, <em>loss</em>, <em>global_step=None</em>, <em>force_var_reuse=False</em>, <em>mode=None</em>, <em>gpu_ids=None</em>, <em>hvd=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/text2text.html#BasicText2TextWithAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.text2text.BasicText2TextWithAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#models.seq2seq.Seq2Seq" title="models.seq2seq.Seq2Seq"><code class="xref py py-class docutils literal"><span class="pre">models.seq2seq.Seq2Seq</span></code></a></p>
<p>An example class implementing classical text-to-text model.</p>
<dl class="method">
<dt id="models.text2text.BasicText2TextWithAttention.infer">
<code class="descname">infer</code><span class="sig-paren">(</span><em>inputs_per_batch</em>, <em>outputs_per_batch</em>, <em>output_file</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/text2text.html#BasicText2TextWithAttention.infer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.text2text.BasicText2TextWithAttention.infer" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="models.text2text.BasicText2TextWithAttention.maybe_evaluate">
<code class="descname">maybe_evaluate</code><span class="sig-paren">(</span><em>inputs_per_batch</em>, <em>outputs_per_batch</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/text2text.html#BasicText2TextWithAttention.maybe_evaluate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.text2text.BasicText2TextWithAttention.maybe_evaluate" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="models.text2text.BasicText2TextWithAttention.maybe_print_logs">
<code class="descname">maybe_print_logs</code><span class="sig-paren">(</span><em>input_values</em>, <em>output_values</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/text2text.html#BasicText2TextWithAttention.maybe_print_logs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.text2text.BasicText2TextWithAttention.maybe_print_logs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="models.text2text.calculate_bleu">
<code class="descclassname">models.text2text.</code><code class="descname">calculate_bleu</code><span class="sig-paren">(</span><em>preds</em>, <em>targets</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/text2text.html#calculate_bleu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.text2text.calculate_bleu" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>preds</strong> – list of lists</li>
<li><strong>targets</strong> – list of lists</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">bleu score - float32</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="models.text2text.transform_for_bleu">
<code class="descclassname">models.text2text.</code><code class="descname">transform_for_bleu</code><span class="sig-paren">(</span><em>row</em>, <em>vocab</em>, <em>ignore_special=False</em>, <em>delim=' '</em>, <em>bpe_used=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/models/text2text.html#transform_for_bleu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#models.text2text.transform_for_bleu" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="data.html" class="btn btn-neutral float-right" title="data" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="modules.html" class="btn btn-neutral" title="API documentation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, NVIDIA.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.2',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  <script type="text/javascript">
      jQuery(function () {
          
          SphinxRtdTheme.Navigation.enableSticky();
          
      });
  </script>  
  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #64d81c;
    }
    .wy-side-nav-search > div.version {
      color: #ffffff;
    }
    .wy-side-nav-search > img {
      max-width: 150px;
    }
    .wy-side-nav-search > a {
      font-size: 23px;
    }
  </style>


</body>
</html>