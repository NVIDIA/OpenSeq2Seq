

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>image2label &mdash; OpenSeq2Seq 0.2 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  
  
  

  

  
  
    

  

  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/theme_override.css" type="text/css" />
  <link rel="stylesheet" href="../_static/theme_override.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="speech2text" href="data.speech2text.html" />
    <link rel="prev" title="data" href="data.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> OpenSeq2Seq
          

          
            
            <img src="../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../machine-translation.html">Machine Translation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../speech-recognition.html">Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../speech-synthesis.html">Speech Synthesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distr-training.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mixed-precision.html">Mixed precision training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../in-depth-tutorials.html">In-depth tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../interactive-infer-demos.html">Interactive Infer Mode</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">API documentation</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="models.html">models</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="data.html">data</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">image2label</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">image2label</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-data.image2label.imagenet_preprocessing">imagenet_preprocessing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="data.speech2text.html">speech2text</a></li>
<li class="toctree-l3"><a class="reference internal" href="data.text2text.html">text2text</a></li>
<li class="toctree-l3"><a class="reference internal" href="data.text2speech.html">text2speech</a></li>
<li class="toctree-l3"><a class="reference internal" href="data.html#module-data.data_layer">data_layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="data.html#module-data.utils">utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="encoders.html">encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="decoders.html">decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="losses.html">losses</a></li>
<li class="toctree-l2"><a class="reference internal" href="optimizers.html">optimizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="parts.html">parts</a></li>
<li class="toctree-l2"><a class="reference internal" href="utils.html">utils</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">OpenSeq2Seq</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="modules.html">API documentation</a> &raquo;</li>
        
          <li><a href="data.html">data</a> &raquo;</li>
        
      <li>image2label</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/api-docs/data.image2label.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-data.image2label">
<span id="image2label"></span><h1>image2label<a class="headerlink" href="#module-data.image2label" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id1">
<h2>image2label<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-data.image2label.image2label"></span><dl class="class">
<dt id="data.image2label.image2label.CifarDataLayer">
<em class="property">class </em><code class="descclassname">data.image2label.image2label.</code><code class="descname">CifarDataLayer</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>num_workers</em>, <em>worker_id</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/image2label.html#CifarDataLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.image2label.CifarDataLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">open_seq2seq.data.data_layer.DataLayer</span></code></p>
<dl class="method">
<dt id="data.image2label.image2label.CifarDataLayer.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/image2label.html#CifarDataLayer.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.image2label.CifarDataLayer.build_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Here all TensorFlow graph construction should happen.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="data.image2label.image2label.CifarDataLayer.get_optional_params">
<em class="property">static </em><code class="descname">get_optional_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/image2label.html#CifarDataLayer.get_optional_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.image2label.CifarDataLayer.get_optional_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of optional parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>can</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="data.image2label.image2label.CifarDataLayer.get_required_params">
<em class="property">static </em><code class="descname">get_required_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/image2label.html#CifarDataLayer.get_required_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.image2label.CifarDataLayer.get_required_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of required parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>have to</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="data.image2label.image2label.CifarDataLayer.get_size_in_samples">
<code class="descname">get_size_in_samples</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/image2label.html#CifarDataLayer.get_size_in_samples"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.image2label.CifarDataLayer.get_size_in_samples" title="Permalink to this definition">¶</a></dt>
<dd><p>Should return the dataset size in samples.
That is, the number of objects in the dataset. This method is used to
calculate a valid epoch size. If this method is not defined, you will need
to make sure that your dataset for evaluation is created only for
one epoch. You will also not be able to use <code class="docutils literal notranslate"><span class="pre">num_epochs</span></code> parameter in the
base config.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">dataset size in samples.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">int</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="data.image2label.image2label.CifarDataLayer.input_tensors">
<code class="descname">input_tensors</code><a class="headerlink" href="#data.image2label.image2label.CifarDataLayer.input_tensors" title="Permalink to this definition">¶</a></dt>
<dd><p>Dictionary containing input tensors.
This dictionary has to define the following keys: <cite>source_tensors</cite>,
which should contain all tensors describing the input object (i.e. tensors
that are passed to the encoder, e.g. input sequence and input length). And
when <code class="docutils literal notranslate"><span class="pre">self.params['mode']</span> <span class="pre">!=</span> <span class="pre">&quot;infer&quot;</span></code> data layer should also define
<cite>target_tensors</cite> which is the list of all tensors related to the
corresponding target object (i.e. tensors taht are passed to the decoder and
loss, e.g. target sequence and target length). Note that all tensors have
to be created inside <a class="reference internal" href="#data.image2label.image2label.CifarDataLayer.build_graph" title="data.image2label.image2label.CifarDataLayer.build_graph"><code class="xref py py-meth docutils literal notranslate"><span class="pre">self.build_graph()</span></code></a> method.</p>
</dd></dl>

<dl class="attribute">
<dt id="data.image2label.image2label.CifarDataLayer.iterator">
<code class="descname">iterator</code><a class="headerlink" href="#data.image2label.image2label.CifarDataLayer.iterator" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> iterator.
Should be created by <a class="reference internal" href="#data.image2label.image2label.CifarDataLayer.build_graph" title="data.image2label.image2label.CifarDataLayer.build_graph"><code class="xref py py-meth docutils literal notranslate"><span class="pre">self.build_graph()</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="data.image2label.image2label.CifarDataLayer.parse_record">
<code class="descname">parse_record</code><span class="sig-paren">(</span><em>raw_record</em>, <em>is_training</em>, <em>num_classes=10</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/image2label.html#CifarDataLayer.parse_record"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.image2label.CifarDataLayer.parse_record" title="Permalink to this definition">¶</a></dt>
<dd><p>Parse CIFAR-10 image and label from a raw record.</p>
</dd></dl>

<dl class="method">
<dt id="data.image2label.image2label.CifarDataLayer.preprocess_image">
<code class="descname">preprocess_image</code><span class="sig-paren">(</span><em>image</em>, <em>is_training</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/image2label.html#CifarDataLayer.preprocess_image"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.image2label.CifarDataLayer.preprocess_image" title="Permalink to this definition">¶</a></dt>
<dd><p>Preprocess a single image of layout [height, width, depth].</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="data.image2label.image2label.ImagenetDataLayer">
<em class="property">class </em><code class="descclassname">data.image2label.image2label.</code><code class="descname">ImagenetDataLayer</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>num_workers</em>, <em>worker_id</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/image2label.html#ImagenetDataLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.image2label.ImagenetDataLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">open_seq2seq.data.data_layer.DataLayer</span></code></p>
<dl class="method">
<dt id="data.image2label.image2label.ImagenetDataLayer.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/image2label.html#ImagenetDataLayer.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.image2label.ImagenetDataLayer.build_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Here all TensorFlow graph construction should happen.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="data.image2label.image2label.ImagenetDataLayer.get_optional_params">
<em class="property">static </em><code class="descname">get_optional_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/image2label.html#ImagenetDataLayer.get_optional_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.image2label.ImagenetDataLayer.get_optional_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of optional parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>can</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="data.image2label.image2label.ImagenetDataLayer.get_required_params">
<em class="property">static </em><code class="descname">get_required_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/image2label.html#ImagenetDataLayer.get_required_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.image2label.ImagenetDataLayer.get_required_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of required parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>have to</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="data.image2label.image2label.ImagenetDataLayer.get_size_in_samples">
<code class="descname">get_size_in_samples</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/image2label.html#ImagenetDataLayer.get_size_in_samples"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.image2label.ImagenetDataLayer.get_size_in_samples" title="Permalink to this definition">¶</a></dt>
<dd><p>Should return the dataset size in samples.
That is, the number of objects in the dataset. This method is used to
calculate a valid epoch size. If this method is not defined, you will need
to make sure that your dataset for evaluation is created only for
one epoch. You will also not be able to use <code class="docutils literal notranslate"><span class="pre">num_epochs</span></code> parameter in the
base config.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">dataset size in samples.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">int</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="data.image2label.image2label.ImagenetDataLayer.input_tensors">
<code class="descname">input_tensors</code><a class="headerlink" href="#data.image2label.image2label.ImagenetDataLayer.input_tensors" title="Permalink to this definition">¶</a></dt>
<dd><p>Dictionary containing input tensors.
This dictionary has to define the following keys: <cite>source_tensors</cite>,
which should contain all tensors describing the input object (i.e. tensors
that are passed to the encoder, e.g. input sequence and input length). And
when <code class="docutils literal notranslate"><span class="pre">self.params['mode']</span> <span class="pre">!=</span> <span class="pre">&quot;infer&quot;</span></code> data layer should also define
<cite>target_tensors</cite> which is the list of all tensors related to the
corresponding target object (i.e. tensors taht are passed to the decoder and
loss, e.g. target sequence and target length). Note that all tensors have
to be created inside <a class="reference internal" href="#data.image2label.image2label.ImagenetDataLayer.build_graph" title="data.image2label.image2label.ImagenetDataLayer.build_graph"><code class="xref py py-meth docutils literal notranslate"><span class="pre">self.build_graph()</span></code></a> method.</p>
</dd></dl>

<dl class="attribute">
<dt id="data.image2label.image2label.ImagenetDataLayer.iterator">
<code class="descname">iterator</code><a class="headerlink" href="#data.image2label.image2label.ImagenetDataLayer.iterator" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> iterator.
Should be created by <a class="reference internal" href="#data.image2label.image2label.ImagenetDataLayer.build_graph" title="data.image2label.image2label.ImagenetDataLayer.build_graph"><code class="xref py py-meth docutils literal notranslate"><span class="pre">self.build_graph()</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="data.image2label.image2label.ImagenetDataLayer.split_data">
<code class="descname">split_data</code><span class="sig-paren">(</span><em>data</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/image2label.html#ImagenetDataLayer.split_data"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.image2label.ImagenetDataLayer.split_data" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-data.image2label.imagenet_preprocessing">
<span id="imagenet-preprocessing"></span><h2>imagenet_preprocessing<a class="headerlink" href="#module-data.image2label.imagenet_preprocessing" title="Permalink to this headline">¶</a></h2>
<p>Provides utilities to preprocess images.
Training images are sampled using the provided bounding boxes, and subsequently
cropped to the sampled bounding box. Images are additionally flipped randomly,
then resized to the target output size (without aspect-ratio preservation).
Images used during evaluation are resized (with aspect-ratio preservation) and
centrally cropped.
All images undergo mean color subtraction.
Note that these steps are colloquially referred to as “ResNet preprocessing,”
and they differ from “VGG preprocessing,” which does not use bounding boxes
and instead does an aspect-preserving resize followed by random crop during
training. (These both differ from “Inception preprocessing,” which introduces
color distortion steps.)</p>
<dl class="function">
<dt id="data.image2label.imagenet_preprocessing._aspect_preserving_resize">
<code class="descclassname">data.image2label.imagenet_preprocessing.</code><code class="descname">_aspect_preserving_resize</code><span class="sig-paren">(</span><em>image</em>, <em>resize_min</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/imagenet_preprocessing.html#_aspect_preserving_resize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.imagenet_preprocessing._aspect_preserving_resize" title="Permalink to this definition">¶</a></dt>
<dd><p>Resize images preserving the original aspect ratio.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>image</strong> – A 3-D image <cite>Tensor</cite>.</li>
<li><strong>resize_min</strong> – A python integer or scalar <cite>Tensor</cite> indicating the size of
the smallest side after resize.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A 3-D tensor containing the resized image.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">resized_image</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="data.image2label.imagenet_preprocessing._central_crop">
<code class="descclassname">data.image2label.imagenet_preprocessing.</code><code class="descname">_central_crop</code><span class="sig-paren">(</span><em>image</em>, <em>crop_height</em>, <em>crop_width</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/imagenet_preprocessing.html#_central_crop"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.imagenet_preprocessing._central_crop" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs central crops of the given image list.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>image</strong> – a 3-D image tensor</li>
<li><strong>crop_height</strong> – the height of the image following the crop.</li>
<li><strong>crop_width</strong> – the width of the image following the crop.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">3-D tensor with cropped image.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="data.image2label.imagenet_preprocessing._decode_crop_and_flip">
<code class="descclassname">data.image2label.imagenet_preprocessing.</code><code class="descname">_decode_crop_and_flip</code><span class="sig-paren">(</span><em>image_buffer</em>, <em>bbox</em>, <em>num_channels</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/imagenet_preprocessing.html#_decode_crop_and_flip"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.imagenet_preprocessing._decode_crop_and_flip" title="Permalink to this definition">¶</a></dt>
<dd><p>Crops the given image to a random part of the image, and randomly flips.
We use the fused decode_and_crop op, which performs better than the two ops
used separately in series, but note that this requires that the image be
passed in as an un-decoded string Tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>image_buffer</strong> – scalar string Tensor representing the raw JPEG image buffer.</li>
<li><strong>bbox</strong> – 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]
where each coordinate is [0, 1) and the coordinates are arranged as
[ymin, xmin, ymax, xmax].</li>
<li><strong>num_channels</strong> – Integer depth of the image buffer for decoding.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">3-D tensor with cropped image.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="data.image2label.imagenet_preprocessing._mean_image_subtraction_and_normalization">
<code class="descclassname">data.image2label.imagenet_preprocessing.</code><code class="descname">_mean_image_subtraction_and_normalization</code><span class="sig-paren">(</span><em>image</em>, <em>means</em>, <em>num_channels</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/imagenet_preprocessing.html#_mean_image_subtraction_and_normalization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.imagenet_preprocessing._mean_image_subtraction_and_normalization" title="Permalink to this definition">¶</a></dt>
<dd><p>Subtracts the given means from each image channel and divides by 127.5.</p>
<dl class="docutils">
<dt>For example:</dt>
<dd>means = [123.68, 116.779, 103.939]
image = _mean_image_subtraction_and_normalization(image, means)</dd>
</dl>
<p>Note that the rank of <cite>image</cite> must be known.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>image</strong> – a tensor of size [height, width, C].</li>
<li><strong>means</strong> – a C-vector of values to subtract from each channel.</li>
<li><strong>num_channels</strong> – number of color channels in the image that will be distorted.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the centered image and normalized image.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last"><code class="xref py py-exc docutils literal notranslate"><span class="pre">ValueError</span></code> – If the rank of <cite>image</cite> is unknown, if <cite>image</cite> has a rank other
than three or if the number of channels in <cite>image</cite> doesn’t match the
number of values in <cite>means</cite>.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="data.image2label.imagenet_preprocessing._parse_example_proto">
<code class="descclassname">data.image2label.imagenet_preprocessing.</code><code class="descname">_parse_example_proto</code><span class="sig-paren">(</span><em>example_serialized</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/imagenet_preprocessing.html#_parse_example_proto"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.imagenet_preprocessing._parse_example_proto" title="Permalink to this definition">¶</a></dt>
<dd><p>Parses an Example proto containing a training example of an image.
The output of the build_image_data.py image preprocessing script is a dataset
containing serialized Example protocol buffers. Each Example proto contains
the following fields (values are included as examples):</p>
<blockquote>
<div>image/height: 462
image/width: 581
image/colorspace: ‘RGB’
image/channels: 3
image/class/label: 615
image/class/synset: ‘n03623198’
image/class/text: ‘knee pad’
image/object/bbox/xmin: 0.1
image/object/bbox/xmax: 0.9
image/object/bbox/ymin: 0.2
image/object/bbox/ymax: 0.6
image/object/bbox/label: 615
image/format: ‘JPEG’
image/filename: ‘ILSVRC2012_val_00041207.JPEG’
image/encoded: &lt;JPEG encoded string&gt;</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>example_serialized</strong> – scalar Tensor tf.string containing a serialized
Example protocol buffer.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Tensor tf.string containing the contents of a JPEG file.
label: Tensor tf.int32 containing the label.
bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]<blockquote>
<div>where each coordinate is [0, 1) and the coordinates are arranged as
[ymin, xmin, ymax, xmax].</div></blockquote>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">image_buffer</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="data.image2label.imagenet_preprocessing._resize_image">
<code class="descclassname">data.image2label.imagenet_preprocessing.</code><code class="descname">_resize_image</code><span class="sig-paren">(</span><em>image</em>, <em>height</em>, <em>width</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/imagenet_preprocessing.html#_resize_image"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.imagenet_preprocessing._resize_image" title="Permalink to this definition">¶</a></dt>
<dd><p>Simple wrapper around tf.resize_images.
This is primarily to make sure we use the same <cite>ResizeMethod</cite> and other
details each time.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>image</strong> – A 3-D image <cite>Tensor</cite>.</li>
<li><strong>height</strong> – The target height for the resized image.</li>
<li><strong>width</strong> – The target width for the resized image.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><dl class="docutils">
<dt>A 3-D tensor containing the resized image. The first two</dt>
<dd><p class="first last">dimensions have the shape [height, width].</p>
</dd>
</dl>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">resized_image</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="data.image2label.imagenet_preprocessing._smallest_size_at_least">
<code class="descclassname">data.image2label.imagenet_preprocessing.</code><code class="descname">_smallest_size_at_least</code><span class="sig-paren">(</span><em>height</em>, <em>width</em>, <em>resize_min</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/imagenet_preprocessing.html#_smallest_size_at_least"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.imagenet_preprocessing._smallest_size_at_least" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes new shape with the smallest side equal to <cite>smallest_side</cite>.
Computes new shape with the smallest side equal to <cite>smallest_side</cite> while
preserving the original aspect ratio.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>height</strong> – an int32 scalar tensor indicating the current height.</li>
<li><strong>width</strong> – an int32 scalar tensor indicating the current width.</li>
<li><strong>resize_min</strong> – A python integer or scalar <cite>Tensor</cite> indicating the size of
the smallest side after resize.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">an int32 scalar tensor indicating the new height.
new_width: an int32 scalar tensor indicating the new width.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">new_height</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="data.image2label.imagenet_preprocessing.parse_record">
<code class="descclassname">data.image2label.imagenet_preprocessing.</code><code class="descname">parse_record</code><span class="sig-paren">(</span><em>raw_record</em>, <em>is_training</em>, <em>image_size=224</em>, <em>num_classes=1000</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/imagenet_preprocessing.html#parse_record"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.imagenet_preprocessing.parse_record" title="Permalink to this definition">¶</a></dt>
<dd><p>Parses a record containing a training example of an image.
The input record is parsed into a label and image, and the image is passed
through preprocessing steps (cropping, flipping, and so on).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>raw_record</strong> – scalar Tensor tf.string containing a serialized
Example protocol buffer.</li>
<li><strong>is_training</strong> – A boolean denoting whether the input is for training.</li>
<li><strong>image_size</strong> (<em>int</em>) – size that images should be resized to.</li>
<li><strong>num_classes</strong> (<em>int</em>) – number of output classes.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">Tuple with processed image tensor and one-hot-encoded label tensor.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="data.image2label.imagenet_preprocessing.preprocess_image">
<code class="descclassname">data.image2label.imagenet_preprocessing.</code><code class="descname">preprocess_image</code><span class="sig-paren">(</span><em>image_buffer</em>, <em>bbox</em>, <em>output_height</em>, <em>output_width</em>, <em>num_channels</em>, <em>is_training=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/image2label/imagenet_preprocessing.html#preprocess_image"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#data.image2label.imagenet_preprocessing.preprocess_image" title="Permalink to this definition">¶</a></dt>
<dd><p>Preprocesses the given image.
Preprocessing includes decoding, cropping, and resizing for both training
and eval images. Training preprocessing, however, introduces some random
distortion of the image to improve accuracy.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>image_buffer</strong> – scalar string Tensor representing the raw JPEG image buffer.</li>
<li><strong>bbox</strong> – 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]
where each coordinate is [0, 1) and the coordinates are arranged as
[ymin, xmin, ymax, xmax].</li>
<li><strong>output_height</strong> – The height of the image after preprocessing.</li>
<li><strong>output_width</strong> – The width of the image after preprocessing.</li>
<li><strong>num_channels</strong> – Integer depth of the image buffer for decoding.</li>
<li><strong>is_training</strong> – <cite>True</cite> if we’re preprocessing the image for training and
<cite>False</cite> otherwise.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A preprocessed image.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="data.speech2text.html" class="btn btn-neutral float-right" title="speech2text" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="data.html" class="btn btn-neutral" title="data" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, NVIDIA.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.2',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  <script type="text/javascript">
      jQuery(function () {
          
          SphinxRtdTheme.Navigation.enableSticky();
          
      });
  </script>  
  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #64d81c;
    }
    .wy-side-nav-search > div.version {
      color: #ffffff;
    }
    .wy-side-nav-search > img {
      max-width: 150px;
    }
    .wy-side-nav-search > a {
      font-size: 23px;
    }
  </style>


</body>
</html>