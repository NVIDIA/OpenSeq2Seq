

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>encoders &mdash; OpenSeq2Seq 0.2 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  
  
  

  

  
  
    

  

  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/theme_override.css" type="text/css" />
  <link rel="stylesheet" href="../_static/theme_override.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="decoders" href="decoders.html" />
    <link rel="prev" title="text2text" href="data.text2text.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> OpenSeq2Seq
          

          
            
            <img src="../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation-instructions.html">Installation instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting-started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models-and-recipes.html">Models and recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distr-training.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mixed-precision.html">Mixed precision training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../in-depth-tutorials.html">In-depth tutorials</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">API documentation</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="models.html">models</a></li>
<li class="toctree-l2"><a class="reference internal" href="data.html">data</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">encoders</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-encoders.encoder">encoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-encoders.ds2_encoder">ds2_encoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-encoders.w2l_encoder">w2l_encoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-encoders.rnn_encoders">rnn_encoders</a></li>
<li class="toctree-l3"><a class="reference internal" href="#transformer-encoders">transformer_encoders</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-encoders.convs2s_encoder">convs2s_encoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-encoders.resnet_encoder">resnet_encoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-encoders.resnet_blocks">resnet_blocks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-encoders.cnn_encoder">cnn_encoder</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="decoders.html">decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="losses.html">losses</a></li>
<li class="toctree-l2"><a class="reference internal" href="optimizers.html">optimizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="parts.html">parts</a></li>
<li class="toctree-l2"><a class="reference internal" href="utils.html">utils</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">OpenSeq2Seq</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="modules.html">API documentation</a> &raquo;</li>
        
      <li>encoders</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/api-docs/encoders.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-encoders">
<span id="encoders"></span><h1>encoders<a class="headerlink" href="#module-encoders" title="Permalink to this headline">¶</a></h1>
<p>This package contains various encoders.
An encoder typically takes data and produces representation.</p>
<div class="section" id="module-encoders.encoder">
<span id="encoder"></span><h2>encoder<a class="headerlink" href="#module-encoders.encoder" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="encoders.encoder.Encoder">
<em class="property">class </em><code class="descclassname">encoders.encoder.</code><code class="descname">Encoder</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>name='encoder'</em>, <em>mode='train'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/encoder.html#Encoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.encoder.Encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Abstract class from which all encoders must inherit.</p>
<dl class="method">
<dt id="encoders.encoder.Encoder.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>name='encoder'</em>, <em>mode='train'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/encoder.html#Encoder.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.encoder.Encoder.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Encoder constructor.
Note that encoder constructors should not modify TensorFlow graph, all
graph construction should happen in the <a class="reference internal" href="#encoders.encoder.Encoder._encode" title="encoders.encoder.Encoder._encode"><code class="xref py py-meth docutils literal notranslate"><span class="pre">self._encode()</span></code></a>
method.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>params</strong> (<em>dict</em>) – parameters describing the encoder.
All supported parameters are listed in <a class="reference internal" href="#encoders.encoder.Encoder.get_required_params" title="encoders.encoder.Encoder.get_required_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_required_params()</span></code></a>,
<a class="reference internal" href="#encoders.encoder.Encoder.get_optional_params" title="encoders.encoder.Encoder.get_optional_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_optional_params()</span></code></a> functions.</li>
<li><strong>model</strong> (instance of a class derived from <a class="reference internal" href="models.html#models.model.Model" title="models.model.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code></a>) – parent model that created this encoder.
Could be None if no model access is required for the use case.</li>
<li><strong>name</strong> (<em>str</em>) – name for encoder variable scope.</li>
<li><strong>mode</strong> (<em>str</em>) – mode encoder is going to be run in.
Could be “train”, “eval” or “infer”.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Config parameters:</p>
<ul class="simple">
<li><strong>initializer</strong> — any valid TensorFlow initializer. If no initializer
is provided, model initializer will be used.</li>
<li><strong>initializer_params</strong> (dict) — dictionary that will be passed to
initializer <code class="docutils literal notranslate"><span class="pre">__init__</span></code> method.</li>
<li><strong>regularizer</strong> — and valid TensorFlow regularizer. If no regularizer
is provided, model regularizer will be used.</li>
<li><strong>regularizer_params</strong> (dict) — dictionary that will be passed to
regularizer <code class="docutils literal notranslate"><span class="pre">__init__</span></code> method.</li>
<li><strong>dtype</strong> — model dtype. Could be either <code class="docutils literal notranslate"><span class="pre">tf.float16</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.float32</span></code>
or “mixed”. For details see
<a class="reference internal" href="../mixed-precision.html#mixed-precision"><span class="std std-ref">mixed precision training</span></a> section in docs. If no
dtype is provided, model dtype will be used.</li>
</ul>
</dd></dl>

<dl class="method">
<dt id="encoders.encoder.Encoder._cast_types">
<code class="descname">_cast_types</code><span class="sig-paren">(</span><em>input_dict</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/encoder.html#Encoder._cast_types"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.encoder.Encoder._cast_types" title="Permalink to this definition">¶</a></dt>
<dd><p>This function performs automatic cast of all inputs to encoder dtype.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input_dict</strong> (<em>dict</em>) – dictionary passed to <a class="reference internal" href="#encoders.encoder.Encoder._encode" title="encoders.encoder.Encoder._encode"><code class="xref py py-meth docutils literal notranslate"><span class="pre">self._encode()</span></code></a>
method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">same as input_dict, but with all Tensors cast to encoder dtype.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="encoders.encoder.Encoder._encode">
<code class="descname">_encode</code><span class="sig-paren">(</span><em>input_dict</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/encoder.html#Encoder._encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.encoder.Encoder._encode" title="Permalink to this definition">¶</a></dt>
<dd><p>This is the main function which should construct encoder graph.
Typically, encoder will take raw input sequence as an input and
produce some hidden representation as an output.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input_dict</strong> (<em>dict</em>) – <p>dictionary containing encoder inputs.
If the encoder is used with <a class="reference internal" href="models.html#module-models.encoder_decoder" title="models.encoder_decoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">models.encoder_decoder</span></code></a> class,
<code class="docutils literal notranslate"><span class="pre">input_dict</span></code> will have the following content:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;source_tensors&quot;</span><span class="p">:</span> <span class="n">data_layer</span><span class="o">.</span><span class="n">input_tensors</span><span class="p">[</span><span class="s1">&#39;source_tensors&#39;</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">dictionary of encoder outputs. Return all necessary outputs.
Typically this will be just:<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="n">outputs</span><span class="p">,</span>
  <span class="s2">&quot;state&quot;</span><span class="p">:</span> <span class="n">state</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="encoders.encoder.Encoder.encode">
<code class="descname">encode</code><span class="sig-paren">(</span><em>input_dict</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/encoder.html#Encoder.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.encoder.Encoder.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around <a class="reference internal" href="#encoders.encoder.Encoder._encode" title="encoders.encoder.Encoder._encode"><code class="xref py py-meth docutils literal notranslate"><span class="pre">self._encode()</span></code></a> method.
Here name, initializer and dtype are set in the variable scope and then
<a class="reference internal" href="#encoders.encoder.Encoder._encode" title="encoders.encoder.Encoder._encode"><code class="xref py py-meth docutils literal notranslate"><span class="pre">self._encode()</span></code></a> method is called.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input_dict</strong> (<em>dict</em>) – see <a class="reference internal" href="#encoders.encoder.Encoder._encode" title="encoders.encoder.Encoder._encode"><code class="xref py py-meth docutils literal notranslate"><span class="pre">self._encode()</span></code></a> docs.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">see <a class="reference internal" href="#encoders.encoder.Encoder._encode" title="encoders.encoder.Encoder._encode"><code class="xref py py-meth docutils literal notranslate"><span class="pre">self._encode()</span></code></a> docs.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="encoders.encoder.Encoder.get_optional_params">
<em class="property">static </em><code class="descname">get_optional_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/encoder.html#Encoder.get_optional_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.encoder.Encoder.get_optional_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of optional parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>can</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <a class="reference internal" href="#encoders.encoder.Encoder.__init__" title="encoders.encoder.Encoder.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code></a> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="encoders.encoder.Encoder.get_required_params">
<em class="property">static </em><code class="descname">get_required_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/encoder.html#Encoder.get_required_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.encoder.Encoder.get_required_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of required parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>have to</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <a class="reference internal" href="#encoders.encoder.Encoder.__init__" title="encoders.encoder.Encoder.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code></a> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="encoders.encoder.Encoder.mode">
<code class="descname">mode</code><a class="headerlink" href="#encoders.encoder.Encoder.mode" title="Permalink to this definition">¶</a></dt>
<dd><p>Mode encoder is run in.</p>
</dd></dl>

<dl class="attribute">
<dt id="encoders.encoder.Encoder.name">
<code class="descname">name</code><a class="headerlink" href="#encoders.encoder.Encoder.name" title="Permalink to this definition">¶</a></dt>
<dd><p>Encoder name.</p>
</dd></dl>

<dl class="attribute">
<dt id="encoders.encoder.Encoder.params">
<code class="descname">params</code><a class="headerlink" href="#encoders.encoder.Encoder.params" title="Permalink to this definition">¶</a></dt>
<dd><p>Parameters used to construct the encoder (dictionary).</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-encoders.ds2_encoder">
<span id="ds2-encoder"></span><h2>ds2_encoder<a class="headerlink" href="#module-encoders.ds2_encoder" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="encoders.ds2_encoder.DeepSpeech2Encoder">
<em class="property">class </em><code class="descclassname">encoders.ds2_encoder.</code><code class="descname">DeepSpeech2Encoder</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>name='ds2_encoder'</em>, <em>mode='train'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/ds2_encoder.html#DeepSpeech2Encoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.ds2_encoder.DeepSpeech2Encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#encoders.encoder.Encoder" title="encoders.encoder.Encoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">encoders.encoder.Encoder</span></code></a></p>
<p>DeepSpeech-2 like encoder.</p>
<dl class="method">
<dt id="encoders.ds2_encoder.DeepSpeech2Encoder.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>name='ds2_encoder'</em>, <em>mode='train'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/ds2_encoder.html#DeepSpeech2Encoder.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.ds2_encoder.DeepSpeech2Encoder.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>DeepSpeech-2 like encoder constructor.</p>
<p>See parent class for arguments description.</p>
<p>Config parameters:</p>
<ul>
<li><p class="first"><strong>dropout_keep_prop</strong> (float) — keep probability for dropout.</p>
</li>
<li><p class="first"><strong>conv_layers</strong> (list) — list with the description of convolutional
layers. For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;conv_layers&quot;</span><span class="p">:</span> <span class="p">[</span>
  <span class="p">{</span>
    <span class="s2">&quot;kernel_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">41</span><span class="p">],</span> <span class="s2">&quot;stride&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
    <span class="s2">&quot;num_channels&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span> <span class="s2">&quot;padding&quot;</span><span class="p">:</span> <span class="s2">&quot;SAME&quot;</span><span class="p">,</span>
  <span class="p">},</span>
  <span class="p">{</span>
    <span class="s2">&quot;kernel_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">21</span><span class="p">],</span> <span class="s2">&quot;stride&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
    <span class="s2">&quot;num_channels&quot;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span> <span class="s2">&quot;padding&quot;</span><span class="p">:</span> <span class="s2">&quot;SAME&quot;</span><span class="p">,</span>
  <span class="p">},</span>
  <span class="p">{</span>
    <span class="s2">&quot;kernel_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">21</span><span class="p">],</span> <span class="s2">&quot;stride&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
    <span class="s2">&quot;num_channels&quot;</span><span class="p">:</span> <span class="mi">96</span><span class="p">,</span> <span class="s2">&quot;padding&quot;</span><span class="p">:</span> <span class="s2">&quot;SAME&quot;</span><span class="p">,</span>
  <span class="p">},</span>
<span class="p">]</span>
</pre></div>
</div>
</li>
<li><p class="first"><strong>activation_fn</strong> — activation function to use.</p>
</li>
<li><p class="first"><strong>num_rnn_layers</strong> — number of RNN layers to use.</p>
</li>
<li><p class="first"><strong>rnn_type</strong> (string) — could be “lstm”, “gru”, “cudnn_gru”,
“cudnn_lstm” or “layernorm_lstm”.</p>
</li>
<li><p class="first"><strong>rnn_unidirectional</strong> (bool) — whether to use uni-directional or
bi-directional RNNs.</p>
</li>
<li><p class="first"><strong>rnn_cell_dim</strong> (int) — dimension of RNN cells.</p>
</li>
<li><p class="first"><strong>row_conv</strong> (bool) — whether to use a “row” (“in plane”) convolutional
layer after RNNs.</p>
</li>
<li><p class="first"><strong>row_conv_width</strong> (int) — width parameter for “row”
convolutional layer.</p>
</li>
<li><p class="first"><strong>n_hidden</strong> (int) — number of hidden units for the last fully connected
layer.</p>
</li>
<li><p class="first"><strong>data_format</strong> (string) — could be either “channels_first” or
“channels_last”. Defaults to “channels_last”.</p>
</li>
<li><p class="first"><strong>bn_momentum</strong> (float) — momentum for batch norm. Defaults to 0.99.</p>
</li>
<li><p class="first"><strong>bn_epsilon</strong> (float) — epsilon for batch norm. Defaults to 1e-3.</p>
</li>
</ul>
</dd></dl>

<dl class="method">
<dt id="encoders.ds2_encoder.DeepSpeech2Encoder._encode">
<code class="descname">_encode</code><span class="sig-paren">(</span><em>input_dict</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/ds2_encoder.html#DeepSpeech2Encoder._encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.ds2_encoder.DeepSpeech2Encoder._encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates TensorFlow graph for DeepSpeech-2 like encoder.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input_dict</strong> (<em>dict</em>) – <p>input dictionary that has to contain
the following fields:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">input_dict</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s2">&quot;source_tensors&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="n">src_sequence</span> <span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence</span> <span class="n">length</span><span class="p">,</span> <span class="n">num</span> <span class="n">features</span><span class="p">]),</span>
    <span class="n">src_length</span> <span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">])</span>
  <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">dictionary with the following tensors:<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s1">&#39;outputs&#39;</span><span class="p">:</span> <span class="n">hidden</span> <span class="n">state</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence</span> <span class="n">length</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">]</span>
  <span class="s1">&#39;src_length&#39;</span><span class="p">:</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="encoders.ds2_encoder.DeepSpeech2Encoder.get_optional_params">
<em class="property">static </em><code class="descname">get_optional_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/ds2_encoder.html#DeepSpeech2Encoder.get_optional_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.ds2_encoder.DeepSpeech2Encoder.get_optional_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of optional parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>can</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <a class="reference internal" href="#encoders.ds2_encoder.DeepSpeech2Encoder.__init__" title="encoders.ds2_encoder.DeepSpeech2Encoder.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code></a> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="encoders.ds2_encoder.DeepSpeech2Encoder.get_required_params">
<em class="property">static </em><code class="descname">get_required_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/ds2_encoder.html#DeepSpeech2Encoder.get_required_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.ds2_encoder.DeepSpeech2Encoder.get_required_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of required parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>have to</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <a class="reference internal" href="#encoders.ds2_encoder.DeepSpeech2Encoder.__init__" title="encoders.ds2_encoder.DeepSpeech2Encoder.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code></a> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="encoders.ds2_encoder.rnn_cell">
<code class="descclassname">encoders.ds2_encoder.</code><code class="descname">rnn_cell</code><span class="sig-paren">(</span><em>rnn_cell_dim</em>, <em>layer_type</em>, <em>dropout_keep_prob=1.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/ds2_encoder.html#rnn_cell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.ds2_encoder.rnn_cell" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper function that creates RNN cell.</p>
</dd></dl>

<dl class="function">
<dt id="encoders.ds2_encoder.row_conv">
<code class="descclassname">encoders.ds2_encoder.</code><code class="descname">row_conv</code><span class="sig-paren">(</span><em>name</em>, <em>input_layer</em>, <em>batch</em>, <em>channels</em>, <em>width</em>, <em>activation_fn</em>, <em>regularizer</em>, <em>training</em>, <em>data_format</em>, <em>bn_momentum</em>, <em>bn_epsilon</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/ds2_encoder.html#row_conv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.ds2_encoder.row_conv" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper function that applies “row” or “in plane” convolution.</p>
</dd></dl>

</div>
<div class="section" id="module-encoders.w2l_encoder">
<span id="w2l-encoder"></span><h2>w2l_encoder<a class="headerlink" href="#module-encoders.w2l_encoder" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="encoders.w2l_encoder.Wave2LetterEncoder">
<em class="property">class </em><code class="descclassname">encoders.w2l_encoder.</code><code class="descname">Wave2LetterEncoder</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>name='w2l_encoder'</em>, <em>mode='train'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/w2l_encoder.html#Wave2LetterEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.w2l_encoder.Wave2LetterEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#encoders.encoder.Encoder" title="encoders.encoder.Encoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">encoders.encoder.Encoder</span></code></a></p>
<p>Wave2Letter like encoder. Fully convolutional model</p>
<dl class="method">
<dt id="encoders.w2l_encoder.Wave2LetterEncoder.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>name='w2l_encoder'</em>, <em>mode='train'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/w2l_encoder.html#Wave2LetterEncoder.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.w2l_encoder.Wave2LetterEncoder.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Wave2Letter like encoder constructor.</p>
<p>See parent class for arguments description.</p>
<p>Config parameters:</p>
<ul>
<li><p class="first"><strong>dropout_keep_prop</strong> (float) — keep probability for dropout.</p>
</li>
<li><p class="first"><strong>convnet_layers</strong> (list) — list with the description of convolutional
layers. For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;convnet_layers&quot;</span><span class="p">:</span> <span class="p">[</span>
  <span class="p">{</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;conv1d&quot;</span><span class="p">,</span> <span class="s2">&quot;repeat&quot;</span> <span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
    <span class="s2">&quot;kernel_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="s2">&quot;stride&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="s2">&quot;num_channels&quot;</span><span class="p">:</span> <span class="mi">250</span><span class="p">,</span> <span class="s2">&quot;padding&quot;</span><span class="p">:</span> <span class="s2">&quot;SAME&quot;</span>
  <span class="p">},</span>
  <span class="p">{</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;conv1d&quot;</span><span class="p">,</span> <span class="s2">&quot;repeat&quot;</span> <span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="s2">&quot;kernel_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">11</span><span class="p">],</span> <span class="s2">&quot;stride&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="s2">&quot;num_channels&quot;</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span> <span class="s2">&quot;padding&quot;</span><span class="p">:</span> <span class="s2">&quot;SAME&quot;</span>
  <span class="p">},</span>
  <span class="p">{</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;conv1d&quot;</span><span class="p">,</span> <span class="s2">&quot;repeat&quot;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;kernel_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">32</span><span class="p">],</span> <span class="s2">&quot;stride&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="s2">&quot;num_channels&quot;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span> <span class="s2">&quot;padding&quot;</span><span class="p">:</span> <span class="s2">&quot;SAME&quot;</span>
  <span class="p">},</span>
  <span class="p">{</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;conv1d&quot;</span><span class="p">,</span> <span class="s2">&quot;repeat&quot;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;kernel_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;stride&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="s2">&quot;num_channels&quot;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span> <span class="s2">&quot;padding&quot;</span><span class="p">:</span> <span class="s2">&quot;SAME&quot;</span>
  <span class="p">},</span>
<span class="p">]</span>
</pre></div>
</div>
</li>
<li><p class="first"><strong>activation_fn</strong> — activation function to use.</p>
</li>
<li><p class="first"><strong>data_format</strong> (string) — could be either “channels_first” or
“channels_last”. Defaults to “channels_last”.</p>
</li>
<li><p class="first"><strong>normalization</strong> — normalization to use. Accepts [None, ‘batch_norm’].
Use None if you don’t want to use normalization. Defaults to ‘batch_norm’.</p>
</li>
<li><p class="first"><strong>bn_momentum</strong> (float) — momentum for batch norm. Defaults to 0.90.</p>
</li>
<li><p class="first"><strong>bn_epsilon</strong> (float) — epsilon for batch norm. Defaults to 1e-3.</p>
</li>
</ul>
</dd></dl>

<dl class="method">
<dt id="encoders.w2l_encoder.Wave2LetterEncoder._encode">
<code class="descname">_encode</code><span class="sig-paren">(</span><em>input_dict</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/w2l_encoder.html#Wave2LetterEncoder._encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.w2l_encoder.Wave2LetterEncoder._encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates TensorFlow graph for Wav2Letter like encoder.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input_dict</strong> (<em>dict</em>) – <p>input dictionary that has to contain
the following fields:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">input_dict</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s2">&quot;source_tensors&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="n">src_sequence</span> <span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence</span> <span class="n">length</span><span class="p">,</span> <span class="n">num</span> <span class="n">features</span><span class="p">]),</span>
    <span class="n">src_length</span> <span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">])</span>
  <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">dictionary with the following tensors:<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s1">&#39;outputs&#39;</span><span class="p">:</span> <span class="n">hidden</span> <span class="n">state</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence</span> <span class="n">length</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">]</span>
  <span class="s1">&#39;src_length&#39;</span><span class="p">:</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="encoders.w2l_encoder.Wave2LetterEncoder.get_optional_params">
<em class="property">static </em><code class="descname">get_optional_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/w2l_encoder.html#Wave2LetterEncoder.get_optional_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.w2l_encoder.Wave2LetterEncoder.get_optional_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of optional parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>can</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <a class="reference internal" href="#encoders.w2l_encoder.Wave2LetterEncoder.__init__" title="encoders.w2l_encoder.Wave2LetterEncoder.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code></a> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="encoders.w2l_encoder.Wave2LetterEncoder.get_required_params">
<em class="property">static </em><code class="descname">get_required_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/w2l_encoder.html#Wave2LetterEncoder.get_required_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.w2l_encoder.Wave2LetterEncoder.get_required_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of required parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>have to</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <a class="reference internal" href="#encoders.w2l_encoder.Wave2LetterEncoder.__init__" title="encoders.w2l_encoder.Wave2LetterEncoder.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code></a> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-encoders.rnn_encoders">
<span id="rnn-encoders"></span><h2>rnn_encoders<a class="headerlink" href="#module-encoders.rnn_encoders" title="Permalink to this headline">¶</a></h2>
<p>RNN-based encoders</p>
<dl class="class">
<dt id="encoders.rnn_encoders.BidirectionalRNNEncoderWithEmbedding">
<em class="property">class </em><code class="descclassname">encoders.rnn_encoders.</code><code class="descname">BidirectionalRNNEncoderWithEmbedding</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>name='bidir_rnn_encoder_with_emb'</em>, <em>mode='train'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/rnn_encoders.html#BidirectionalRNNEncoderWithEmbedding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.rnn_encoders.BidirectionalRNNEncoderWithEmbedding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#encoders.encoder.Encoder" title="encoders.encoder.Encoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">encoders.encoder.Encoder</span></code></a></p>
<p>Bi-directional RNN-based encoder with embeddings.
Can support various RNN cell types.</p>
<dl class="method">
<dt id="encoders.rnn_encoders.BidirectionalRNNEncoderWithEmbedding.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>name='bidir_rnn_encoder_with_emb'</em>, <em>mode='train'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/rnn_encoders.html#BidirectionalRNNEncoderWithEmbedding.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.rnn_encoders.BidirectionalRNNEncoderWithEmbedding.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initializes bi-directional encoder with embeddings
:param params: dictionary with encoder parameters
Must define:</p>
<blockquote>
<div><ul class="simple">
<li>src_vocab_size - data vocabulary size</li>
<li>src_emb_size - size of embedding to use</li>
<li>encoder_cell_units - number of units in RNN cell</li>
<li>encoder_cell_type - cell type: lstm, gru, etc.</li>
<li>encoder_layers - number of layers</li>
<li>encoder_dp_input_keep_prob -</li>
<li>encoder_dp_output_keep_prob -</li>
<li>encoder_use_skip_connections - true/false</li>
<li>time_major (optional)</li>
<li>use_swap_memory (optional)</li>
<li>mode - train or infer</li>
</ul>
<p>… add any cell-specific parameters here as well</p>
</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>encoder_params</strong> – </td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="encoders.rnn_encoders.BidirectionalRNNEncoderWithEmbedding._encode">
<code class="descname">_encode</code><span class="sig-paren">(</span><em>input_dict</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/rnn_encoders.html#BidirectionalRNNEncoderWithEmbedding._encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.rnn_encoders.BidirectionalRNNEncoderWithEmbedding._encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encodes data into representation
:param input_dict: a Python dictionary.
Must define:</p>
<blockquote>
<div><ul class="simple">
<li><dl class="first docutils">
<dt>src_inputs - a Tensor of shape [batch_size, time] or [time, batch_size]</dt>
<dd>(depending on time_major param)</dd>
</dl>
</li>
<li>src_lengths - a Tensor of shape [batch_size]</li>
</ul>
</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">a Python dictionary with:
* encoder_outputs - a Tensor of shape<blockquote>
<div>[batch_size, time, representation_dim]</div></blockquote>
<p>or [time, batch_size, representation_dim]
* encoder_state - a Tensor of shape [batch_size, dim]
* src_lengths - (copy ref from input) a Tensor of shape [batch_size]</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="encoders.rnn_encoders.BidirectionalRNNEncoderWithEmbedding.enc_emb_w">
<code class="descname">enc_emb_w</code><a class="headerlink" href="#encoders.rnn_encoders.BidirectionalRNNEncoderWithEmbedding.enc_emb_w" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="encoders.rnn_encoders.BidirectionalRNNEncoderWithEmbedding.get_optional_params">
<em class="property">static </em><code class="descname">get_optional_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/rnn_encoders.html#BidirectionalRNNEncoderWithEmbedding.get_optional_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.rnn_encoders.BidirectionalRNNEncoderWithEmbedding.get_optional_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of optional parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>can</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <a class="reference internal" href="#encoders.rnn_encoders.BidirectionalRNNEncoderWithEmbedding.__init__" title="encoders.rnn_encoders.BidirectionalRNNEncoderWithEmbedding.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code></a> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="encoders.rnn_encoders.BidirectionalRNNEncoderWithEmbedding.get_required_params">
<em class="property">static </em><code class="descname">get_required_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/rnn_encoders.html#BidirectionalRNNEncoderWithEmbedding.get_required_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.rnn_encoders.BidirectionalRNNEncoderWithEmbedding.get_required_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of required parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>have to</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <a class="reference internal" href="#encoders.rnn_encoders.BidirectionalRNNEncoderWithEmbedding.__init__" title="encoders.rnn_encoders.BidirectionalRNNEncoderWithEmbedding.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code></a> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="encoders.rnn_encoders.BidirectionalRNNEncoderWithEmbedding.src_emb_size">
<code class="descname">src_emb_size</code><a class="headerlink" href="#encoders.rnn_encoders.BidirectionalRNNEncoderWithEmbedding.src_emb_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="encoders.rnn_encoders.BidirectionalRNNEncoderWithEmbedding.src_vocab_size">
<code class="descname">src_vocab_size</code><a class="headerlink" href="#encoders.rnn_encoders.BidirectionalRNNEncoderWithEmbedding.src_vocab_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding">
<em class="property">class </em><code class="descclassname">encoders.rnn_encoders.</code><code class="descname">GNMTLikeEncoderWithEmbedding</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>name='gnmt_encoder_with_emb'</em>, <em>mode='train'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/rnn_encoders.html#GNMTLikeEncoderWithEmbedding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#encoders.encoder.Encoder" title="encoders.encoder.Encoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">encoders.encoder.Encoder</span></code></a></p>
<p>Encoder similar to the one used in
GNMT model: <a class="reference external" href="https://arxiv.org/abs/1609.08144">https://arxiv.org/abs/1609.08144</a>.
Must have at least 2 layers</p>
<dl class="method">
<dt id="encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>name='gnmt_encoder_with_emb'</em>, <em>mode='train'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/rnn_encoders.html#GNMTLikeEncoderWithEmbedding.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Encodes data into representation
:param params: a Python dictionary.
Must define:</p>
<blockquote>
<div><ul class="simple">
<li><dl class="first docutils">
<dt>src_inputs - a Tensor of shape [batch_size, time] or [time, batch_size]</dt>
<dd>(depending on time_major param)</dd>
</dl>
</li>
<li>src_lengths - a Tensor of shape [batch_size]</li>
</ul>
</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">a Python dictionary with:
* encoder_outputs - a Tensor of shape<blockquote>
<div>[batch_size, time, representation_dim]</div></blockquote>
<p>or [time, batch_size, representation_dim]
* encoder_state - a Tensor of shape [batch_size, dim]
* src_lengths - (copy ref from input) a Tensor of shape [batch_size]</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding.enc_emb_w">
<code class="descname">enc_emb_w</code><a class="headerlink" href="#encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding.enc_emb_w" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding.get_optional_params">
<em class="property">static </em><code class="descname">get_optional_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/rnn_encoders.html#GNMTLikeEncoderWithEmbedding.get_optional_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding.get_optional_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of optional parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>can</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <a class="reference internal" href="#encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding.__init__" title="encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code></a> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding.get_required_params">
<em class="property">static </em><code class="descname">get_required_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/rnn_encoders.html#GNMTLikeEncoderWithEmbedding.get_required_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding.get_required_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of required parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>have to</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <a class="reference internal" href="#encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding.__init__" title="encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code></a> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding.src_emb_size">
<code class="descname">src_emb_size</code><a class="headerlink" href="#encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding.src_emb_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding.src_vocab_size">
<code class="descname">src_vocab_size</code><a class="headerlink" href="#encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding.src_vocab_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding_cuDNN">
<em class="property">class </em><code class="descclassname">encoders.rnn_encoders.</code><code class="descname">GNMTLikeEncoderWithEmbedding_cuDNN</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>name='gnmt_encoder_with_emb_cudnn'</em>, <em>mode='train'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/rnn_encoders.html#GNMTLikeEncoderWithEmbedding_cuDNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding_cuDNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#encoders.encoder.Encoder" title="encoders.encoder.Encoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">encoders.encoder.Encoder</span></code></a></p>
<p>Encoder similar to the one used in
GNMT model: <a class="reference external" href="https://arxiv.org/abs/1609.08144">https://arxiv.org/abs/1609.08144</a>.
Must have at least 2 layers. Uses cuDNN RNN blocks for efficiency</p>
<dl class="method">
<dt id="encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding_cuDNN.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>name='gnmt_encoder_with_emb_cudnn'</em>, <em>mode='train'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/rnn_encoders.html#GNMTLikeEncoderWithEmbedding_cuDNN.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding_cuDNN.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Encodes data into representation
:param params: a Python dictionary.
Must define:</p>
<blockquote>
<div><ul class="simple">
<li><dl class="first docutils">
<dt>src_inputs - a Tensor of shape [batch_size, time] or [time, batch_size]</dt>
<dd>(depending on time_major param)</dd>
</dl>
</li>
<li>src_lengths - a Tensor of shape [batch_size]</li>
</ul>
</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">a Python dictionary with:
* encoder_outputs - a Tensor of shape<blockquote>
<div>[batch_size, time, representation_dim]</div></blockquote>
<p>or [time, batch_size, representation_dim]
* encoder_state - a Tensor of shape [batch_size, dim]
* src_lengths - (copy ref from input) a Tensor of shape [batch_size]</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding_cuDNN.enc_emb_w">
<code class="descname">enc_emb_w</code><a class="headerlink" href="#encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding_cuDNN.enc_emb_w" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding_cuDNN.get_optional_params">
<em class="property">static </em><code class="descname">get_optional_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/rnn_encoders.html#GNMTLikeEncoderWithEmbedding_cuDNN.get_optional_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding_cuDNN.get_optional_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of optional parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>can</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <a class="reference internal" href="#encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding_cuDNN.__init__" title="encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding_cuDNN.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code></a> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding_cuDNN.get_required_params">
<em class="property">static </em><code class="descname">get_required_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/rnn_encoders.html#GNMTLikeEncoderWithEmbedding_cuDNN.get_required_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding_cuDNN.get_required_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of required parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>have to</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <a class="reference internal" href="#encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding_cuDNN.__init__" title="encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding_cuDNN.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code></a> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding_cuDNN.src_emb_size">
<code class="descname">src_emb_size</code><a class="headerlink" href="#encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding_cuDNN.src_emb_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding_cuDNN.src_vocab_size">
<code class="descname">src_vocab_size</code><a class="headerlink" href="#encoders.rnn_encoders.GNMTLikeEncoderWithEmbedding_cuDNN.src_vocab_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="encoders.rnn_encoders.UnidirectionalRNNEncoderWithEmbedding">
<em class="property">class </em><code class="descclassname">encoders.rnn_encoders.</code><code class="descname">UnidirectionalRNNEncoderWithEmbedding</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>name='unidir_rnn_encoder_with_emb'</em>, <em>mode='train'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/rnn_encoders.html#UnidirectionalRNNEncoderWithEmbedding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.rnn_encoders.UnidirectionalRNNEncoderWithEmbedding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#encoders.encoder.Encoder" title="encoders.encoder.Encoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">encoders.encoder.Encoder</span></code></a></p>
<p>Uni-directional RNN decoder with embeddings.
Can support various RNN cell types.</p>
<dl class="method">
<dt id="encoders.rnn_encoders.UnidirectionalRNNEncoderWithEmbedding.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>name='unidir_rnn_encoder_with_emb'</em>, <em>mode='train'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/rnn_encoders.html#UnidirectionalRNNEncoderWithEmbedding.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.rnn_encoders.UnidirectionalRNNEncoderWithEmbedding.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initializes uni-directional encoder with embeddings
:param params: dictionary with encoder parameters
Must define:</p>
<blockquote>
<div><ul class="simple">
<li>src_vocab_size - data vocabulary size</li>
<li>src_emb_size - size of embedding to use</li>
<li>encoder_cell_units - number of units in RNN cell</li>
<li>encoder_cell_type - cell type: lstm, gru, etc.</li>
<li>encoder_layers - number of layers</li>
<li>encoder_dp_input_keep_prob -</li>
<li>encoder_dp_output_keep_prob -</li>
<li>encoder_use_skip_connections - true/false</li>
<li>time_major (optional)</li>
<li>use_swap_memory (optional)</li>
<li>mode - train or infer</li>
</ul>
<p>… add any cell-specific parameters here as well</p>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="encoders.rnn_encoders.UnidirectionalRNNEncoderWithEmbedding._encode">
<code class="descname">_encode</code><span class="sig-paren">(</span><em>input_dict</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/rnn_encoders.html#UnidirectionalRNNEncoderWithEmbedding._encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.rnn_encoders.UnidirectionalRNNEncoderWithEmbedding._encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encodes data into representation
:param input_dict: a Python dictionary.
Must define:</p>
<blockquote>
<div><ul class="simple">
<li><dl class="first docutils">
<dt>src_inputs - a Tensor of shape [batch_size, time] or [time, batch_size]</dt>
<dd>(depending on time_major param)</dd>
</dl>
</li>
<li>src_lengths - a Tensor of shape [batch_size]</li>
</ul>
</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">a Python dictionary with:
* encoder_outputs - a Tensor of shape<blockquote>
<div>[batch_size, time, representation_dim]</div></blockquote>
<p>or [time, batch_size, representation_dim]
* encoder_state - a Tensor of shape [batch_size, dim]
* src_lengths - (copy ref from input) a Tensor of shape [batch_size]</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="encoders.rnn_encoders.UnidirectionalRNNEncoderWithEmbedding.enc_emb_w">
<code class="descname">enc_emb_w</code><a class="headerlink" href="#encoders.rnn_encoders.UnidirectionalRNNEncoderWithEmbedding.enc_emb_w" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="encoders.rnn_encoders.UnidirectionalRNNEncoderWithEmbedding.get_optional_params">
<em class="property">static </em><code class="descname">get_optional_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/rnn_encoders.html#UnidirectionalRNNEncoderWithEmbedding.get_optional_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.rnn_encoders.UnidirectionalRNNEncoderWithEmbedding.get_optional_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of optional parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>can</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <a class="reference internal" href="#encoders.rnn_encoders.UnidirectionalRNNEncoderWithEmbedding.__init__" title="encoders.rnn_encoders.UnidirectionalRNNEncoderWithEmbedding.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code></a> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="encoders.rnn_encoders.UnidirectionalRNNEncoderWithEmbedding.get_required_params">
<em class="property">static </em><code class="descname">get_required_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/rnn_encoders.html#UnidirectionalRNNEncoderWithEmbedding.get_required_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.rnn_encoders.UnidirectionalRNNEncoderWithEmbedding.get_required_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of required parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>have to</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <a class="reference internal" href="#encoders.rnn_encoders.UnidirectionalRNNEncoderWithEmbedding.__init__" title="encoders.rnn_encoders.UnidirectionalRNNEncoderWithEmbedding.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code></a> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="encoders.rnn_encoders.UnidirectionalRNNEncoderWithEmbedding.src_emb_size">
<code class="descname">src_emb_size</code><a class="headerlink" href="#encoders.rnn_encoders.UnidirectionalRNNEncoderWithEmbedding.src_emb_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="encoders.rnn_encoders.UnidirectionalRNNEncoderWithEmbedding.src_vocab_size">
<code class="descname">src_vocab_size</code><a class="headerlink" href="#encoders.rnn_encoders.UnidirectionalRNNEncoderWithEmbedding.src_vocab_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="transformer-encoders">
<h2>transformer_encoders<a class="headerlink" href="#transformer-encoders" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-encoders.convs2s_encoder">
<span id="convs2s-encoder"></span><h2>convs2s_encoder<a class="headerlink" href="#module-encoders.convs2s_encoder" title="Permalink to this headline">¶</a></h2>
<p>Conv-based encoder</p>
<dl class="class">
<dt id="encoders.convs2s_encoder.ConvS2SEncoder">
<em class="property">class </em><code class="descclassname">encoders.convs2s_encoder.</code><code class="descname">ConvS2SEncoder</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>name='convs2s_encoder_with_emb'</em>, <em>mode='train'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/convs2s_encoder.html#ConvS2SEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.convs2s_encoder.ConvS2SEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#encoders.encoder.Encoder" title="encoders.encoder.Encoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">encoders.encoder.Encoder</span></code></a></p>
<p>Fully convolutional Encoder of ConvS2S</p>
<dl class="staticmethod">
<dt id="encoders.convs2s_encoder.ConvS2SEncoder.get_optional_params">
<em class="property">static </em><code class="descname">get_optional_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/convs2s_encoder.html#ConvS2SEncoder.get_optional_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.convs2s_encoder.ConvS2SEncoder.get_optional_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of optional parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>can</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="encoders.convs2s_encoder.ConvS2SEncoder.get_required_params">
<em class="property">static </em><code class="descname">get_required_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/convs2s_encoder.html#ConvS2SEncoder.get_required_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.convs2s_encoder.ConvS2SEncoder.get_required_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of required parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>have to</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="encoders.convs2s_encoder.ConvS2SEncoder.src_emb_size">
<code class="descname">src_emb_size</code><a class="headerlink" href="#encoders.convs2s_encoder.ConvS2SEncoder.src_emb_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="encoders.convs2s_encoder.ConvS2SEncoder.src_vocab_size">
<code class="descname">src_vocab_size</code><a class="headerlink" href="#encoders.convs2s_encoder.ConvS2SEncoder.src_vocab_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-encoders.resnet_encoder">
<span id="resnet-encoder"></span><h2>resnet_encoder<a class="headerlink" href="#module-encoders.resnet_encoder" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="encoders.resnet_encoder.ResNetEncoder">
<em class="property">class </em><code class="descclassname">encoders.resnet_encoder.</code><code class="descname">ResNetEncoder</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>name='resnet_encoder'</em>, <em>mode='train'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/resnet_encoder.html#ResNetEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.resnet_encoder.ResNetEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#encoders.encoder.Encoder" title="encoders.encoder.Encoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">encoders.encoder.Encoder</span></code></a></p>
<dl class="staticmethod">
<dt id="encoders.resnet_encoder.ResNetEncoder.get_optional_params">
<em class="property">static </em><code class="descname">get_optional_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/resnet_encoder.html#ResNetEncoder.get_optional_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.resnet_encoder.ResNetEncoder.get_optional_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of optional parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>can</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="encoders.resnet_encoder.ResNetEncoder.get_required_params">
<em class="property">static </em><code class="descname">get_required_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/resnet_encoder.html#ResNetEncoder.get_required_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.resnet_encoder.ResNetEncoder.get_required_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of required parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>have to</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-encoders.resnet_blocks">
<span id="resnet-blocks"></span><h2>resnet_blocks<a class="headerlink" href="#module-encoders.resnet_blocks" title="Permalink to this headline">¶</a></h2>
<p>Contains definitions for Residual Networks.</p>
<p>Residual networks (‘v1’ ResNets) were originally proposed in:
[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun</p>
<blockquote>
<div>Deep Residual Learning for Image Recognition. arXiv:1512.03385</div></blockquote>
<p>The full preactivation ‘v2’ ResNet variant was introduced by:
[2] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun</p>
<blockquote>
<div>Identity Mappings in Deep Residual Networks. arXiv: 1603.05027</div></blockquote>
<p>The key difference of the full preactivation ‘v2’ variant compared to the
‘v1’ variant in [1] is the use of batch normalization before every weight layer
rather than after.</p>
<dl class="function">
<dt id="encoders.resnet_blocks.batch_norm">
<code class="descclassname">encoders.resnet_blocks.</code><code class="descname">batch_norm</code><span class="sig-paren">(</span><em>inputs</em>, <em>training</em>, <em>data_format</em>, <em>regularizer</em>, <em>momentum</em>, <em>epsilon</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/resnet_blocks.html#batch_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.resnet_blocks.batch_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a batch normalization using a standard set of parameters.</p>
</dd></dl>

<dl class="function">
<dt id="encoders.resnet_blocks.block_layer">
<code class="descclassname">encoders.resnet_blocks.</code><code class="descname">block_layer</code><span class="sig-paren">(</span><em>inputs</em>, <em>filters</em>, <em>bottleneck</em>, <em>block_fn</em>, <em>blocks</em>, <em>strides</em>, <em>training</em>, <em>name</em>, <em>data_format</em>, <em>regularizer</em>, <em>bn_regularizer</em>, <em>bn_momentum</em>, <em>bn_epsilon</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/resnet_blocks.html#block_layer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.resnet_blocks.block_layer" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates one layer of blocks for the ResNet model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inputs</strong> – A tensor of size [batch, channels, height_in, width_in] or
[batch, height_in, width_in, channels] depending on data_format.</li>
<li><strong>filters</strong> – The number of filters for the first convolution of the layer.</li>
<li><strong>bottleneck</strong> – Is the block created a bottleneck block.</li>
<li><strong>block_fn</strong> – The block to use within the model, either <cite>building_block</cite> or
<cite>bottleneck_block</cite>.</li>
<li><strong>blocks</strong> – The number of blocks contained in the layer.</li>
<li><strong>strides</strong> – The stride to use for the first convolution of the layer. If
greater than 1, this layer will ultimately downsample the input.</li>
<li><strong>training</strong> – Either True or False, whether we are currently training the
model. Needed for batch norm.</li>
<li><strong>name</strong> – A string name for the tensor output of the block layer.</li>
<li><strong>data_format</strong> – The input format (‘channels_last’ or ‘channels_first’).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">The output tensor of the block layer.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="encoders.resnet_blocks.bottleneck_block_v1">
<code class="descclassname">encoders.resnet_blocks.</code><code class="descname">bottleneck_block_v1</code><span class="sig-paren">(</span><em>inputs</em>, <em>filters</em>, <em>training</em>, <em>projection_shortcut</em>, <em>strides</em>, <em>data_format</em>, <em>regularizer</em>, <em>bn_regularizer</em>, <em>bn_momentum</em>, <em>bn_epsilon</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/resnet_blocks.html#bottleneck_block_v1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.resnet_blocks.bottleneck_block_v1" title="Permalink to this definition">¶</a></dt>
<dd><p>A single block for ResNet v1, with a bottleneck.</p>
<p>Similar to _building_block_v1(), except using the “bottleneck” blocks
described in:</p>
<blockquote>
<div><dl class="docutils">
<dt>Convolution then batch normalization then ReLU as described by:</dt>
<dd>Deep Residual Learning for Image Recognition
<a class="reference external" href="https://arxiv.org/pdf/1512.03385.pdf">https://arxiv.org/pdf/1512.03385.pdf</a>
by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Dec 2015.</dd>
</dl>
</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inputs</strong> – A tensor of size [batch, channels, height_in, width_in] or
[batch, height_in, width_in, channels] depending on data_format.</li>
<li><strong>filters</strong> – The number of filters for the convolutions.</li>
<li><strong>training</strong> – A Boolean for whether the model is in training or inference
mode. Needed for batch normalization.</li>
<li><strong>projection_shortcut</strong> – The function to use for projection shortcuts
(typically a 1x1 convolution when downsampling the input).</li>
<li><strong>strides</strong> – The block’s stride. If greater than 1, this block will ultimately
downsample the input.</li>
<li><strong>data_format</strong> – The input format (‘channels_last’ or ‘channels_first’).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">The output tensor of the block; shape should match inputs.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="encoders.resnet_blocks.bottleneck_block_v2">
<code class="descclassname">encoders.resnet_blocks.</code><code class="descname">bottleneck_block_v2</code><span class="sig-paren">(</span><em>inputs</em>, <em>filters</em>, <em>training</em>, <em>projection_shortcut</em>, <em>strides</em>, <em>data_format</em>, <em>regularizer</em>, <em>bn_regularizer</em>, <em>bn_momentum</em>, <em>bn_epsilon</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/resnet_blocks.html#bottleneck_block_v2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.resnet_blocks.bottleneck_block_v2" title="Permalink to this definition">¶</a></dt>
<dd><p>A single block for ResNet v2, without a bottleneck.</p>
<p>Similar to _building_block_v2(), except using the “bottleneck” blocks
described in:</p>
<blockquote>
<div><dl class="docutils">
<dt>Convolution then batch normalization then ReLU as described by:</dt>
<dd>Deep Residual Learning for Image Recognition
<a class="reference external" href="https://arxiv.org/pdf/1512.03385.pdf">https://arxiv.org/pdf/1512.03385.pdf</a>
by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Dec 2015.</dd>
</dl>
</div></blockquote>
<dl class="docutils">
<dt>Adapted to the ordering conventions of:</dt>
<dd><dl class="first last docutils">
<dt>Batch normalization then ReLu then convolution as described by:</dt>
<dd>Identity Mappings in Deep Residual Networks
<a class="reference external" href="https://arxiv.org/pdf/1603.05027.pdf">https://arxiv.org/pdf/1603.05027.pdf</a>
by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Jul 2016.</dd>
</dl>
</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inputs</strong> – A tensor of size [batch, channels, height_in, width_in] or
[batch, height_in, width_in, channels] depending on data_format.</li>
<li><strong>filters</strong> – The number of filters for the convolutions.</li>
<li><strong>training</strong> – A Boolean for whether the model is in training or inference
mode. Needed for batch normalization.</li>
<li><strong>projection_shortcut</strong> – The function to use for projection shortcuts
(typically a 1x1 convolution when downsampling the input).</li>
<li><strong>strides</strong> – The block’s stride. If greater than 1, this block will ultimately
downsample the input.</li>
<li><strong>data_format</strong> – The input format (‘channels_last’ or ‘channels_first’).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">The output tensor of the block; shape should match inputs.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="encoders.resnet_blocks.building_block_v1">
<code class="descclassname">encoders.resnet_blocks.</code><code class="descname">building_block_v1</code><span class="sig-paren">(</span><em>inputs</em>, <em>filters</em>, <em>training</em>, <em>projection_shortcut</em>, <em>strides</em>, <em>data_format</em>, <em>regularizer</em>, <em>bn_regularizer</em>, <em>bn_momentum</em>, <em>bn_epsilon</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/resnet_blocks.html#building_block_v1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.resnet_blocks.building_block_v1" title="Permalink to this definition">¶</a></dt>
<dd><p>A single block for ResNet v1, without a bottleneck.</p>
<dl class="docutils">
<dt>Convolution then batch normalization then ReLU as described by:</dt>
<dd>Deep Residual Learning for Image Recognition
<a class="reference external" href="https://arxiv.org/pdf/1512.03385.pdf">https://arxiv.org/pdf/1512.03385.pdf</a>
by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Dec 2015.</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inputs</strong> – A tensor of size [batch, channels, height_in, width_in] or
[batch, height_in, width_in, channels] depending on data_format.</li>
<li><strong>filters</strong> – The number of filters for the convolutions.</li>
<li><strong>training</strong> – A Boolean for whether the model is in training or inference
mode. Needed for batch normalization.</li>
<li><strong>projection_shortcut</strong> – The function to use for projection shortcuts
(typically a 1x1 convolution when downsampling the input).</li>
<li><strong>strides</strong> – The block’s stride. If greater than 1, this block will ultimately
downsample the input.</li>
<li><strong>data_format</strong> – The input format (‘channels_last’ or ‘channels_first’).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">The output tensor of the block; shape should match inputs.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="encoders.resnet_blocks.building_block_v2">
<code class="descclassname">encoders.resnet_blocks.</code><code class="descname">building_block_v2</code><span class="sig-paren">(</span><em>inputs</em>, <em>filters</em>, <em>training</em>, <em>projection_shortcut</em>, <em>strides</em>, <em>data_format</em>, <em>regularizer</em>, <em>bn_regularizer</em>, <em>bn_momentum</em>, <em>bn_epsilon</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/resnet_blocks.html#building_block_v2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.resnet_blocks.building_block_v2" title="Permalink to this definition">¶</a></dt>
<dd><p>A single block for ResNet v2, without a bottleneck.</p>
<dl class="docutils">
<dt>Batch normalization then ReLu then convolution as described by:</dt>
<dd>Identity Mappings in Deep Residual Networks
<a class="reference external" href="https://arxiv.org/pdf/1603.05027.pdf">https://arxiv.org/pdf/1603.05027.pdf</a>
by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Jul 2016.</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inputs</strong> – A tensor of size [batch, channels, height_in, width_in] or
[batch, height_in, width_in, channels] depending on data_format.</li>
<li><strong>filters</strong> – The number of filters for the convolutions.</li>
<li><strong>training</strong> – A Boolean for whether the model is in training or inference
mode. Needed for batch normalization.</li>
<li><strong>projection_shortcut</strong> – The function to use for projection shortcuts
(typically a 1x1 convolution when downsampling the input).</li>
<li><strong>strides</strong> – The block’s stride. If greater than 1, this block will ultimately
downsample the input.</li>
<li><strong>data_format</strong> – The input format (‘channels_last’ or ‘channels_first’).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">The output tensor of the block; shape should match inputs.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="encoders.resnet_blocks.conv2d_fixed_padding">
<code class="descclassname">encoders.resnet_blocks.</code><code class="descname">conv2d_fixed_padding</code><span class="sig-paren">(</span><em>inputs</em>, <em>filters</em>, <em>kernel_size</em>, <em>strides</em>, <em>data_format</em>, <em>regularizer</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/resnet_blocks.html#conv2d_fixed_padding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.resnet_blocks.conv2d_fixed_padding" title="Permalink to this definition">¶</a></dt>
<dd><p>Strided 2-D convolution with explicit padding.</p>
</dd></dl>

<dl class="function">
<dt id="encoders.resnet_blocks.fixed_padding">
<code class="descclassname">encoders.resnet_blocks.</code><code class="descname">fixed_padding</code><span class="sig-paren">(</span><em>inputs</em>, <em>kernel_size</em>, <em>data_format</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/resnet_blocks.html#fixed_padding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.resnet_blocks.fixed_padding" title="Permalink to this definition">¶</a></dt>
<dd><p>Pads the input along the spatial dimensions independently of input size.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inputs</strong> – A tensor of size [batch, channels, height_in, width_in] or
[batch, height_in, width_in, channels] depending on data_format.</li>
<li><strong>kernel_size</strong> – The kernel to be used in the conv2d or max_pool2d operation.
Should be a positive integer.</li>
<li><strong>data_format</strong> – The input format (‘channels_last’ or ‘channels_first’).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A tensor with the same format as the input with the data either intact
(if kernel_size == 1) or padded (if kernel_size &gt; 1).</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-encoders.cnn_encoder">
<span id="cnn-encoder"></span><h2>cnn_encoder<a class="headerlink" href="#module-encoders.cnn_encoder" title="Permalink to this headline">¶</a></h2>
<p>This module contains classes and functions to build “general” convolutional
neural networks from the description of arbitrary “layers”.</p>
<dl class="class">
<dt id="encoders.cnn_encoder.CNNEncoder">
<em class="property">class </em><code class="descclassname">encoders.cnn_encoder.</code><code class="descname">CNNEncoder</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>name='cnn_encoder'</em>, <em>mode='train'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/cnn_encoder.html#CNNEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.cnn_encoder.CNNEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#encoders.encoder.Encoder" title="encoders.encoder.Encoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">encoders.encoder.Encoder</span></code></a></p>
<p>General CNN encoder that can be used to construct various different models.</p>
<dl class="method">
<dt id="encoders.cnn_encoder.CNNEncoder.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>params</em>, <em>model</em>, <em>name='cnn_encoder'</em>, <em>mode='train'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/cnn_encoder.html#CNNEncoder.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.cnn_encoder.CNNEncoder.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>CNN Encoder constructor.</p>
<p>See parent class for arguments description.</p>
<p>Config parameters:</p>
<ul>
<li><p class="first"><strong>cnn_layers</strong> (list) — list with the description of “convolutional”
layers. For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;conv_layers&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">conv2d</span><span class="p">,</span> <span class="p">{</span>
        <span class="s1">&#39;filters&#39;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span> <span class="s1">&#39;kernel_size&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span>
        <span class="s1">&#39;strides&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="s1">&#39;padding&#39;</span><span class="p">:</span> <span class="s1">&#39;VALID&#39;</span><span class="p">,</span>
        <span class="s1">&#39;activation&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
    <span class="p">}),</span>
    <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">max_pooling2d</span><span class="p">,</span> <span class="p">{</span>
        <span class="s1">&#39;pool_size&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s1">&#39;strides&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
    <span class="p">}),</span>
    <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">conv2d</span><span class="p">,</span> <span class="p">{</span>
        <span class="s1">&#39;filters&#39;</span><span class="p">:</span> <span class="mi">192</span><span class="p">,</span> <span class="s1">&#39;kernel_size&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
        <span class="s1">&#39;strides&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s1">&#39;padding&#39;</span><span class="p">:</span> <span class="s1">&#39;SAME&#39;</span><span class="p">,</span>
    <span class="p">}),</span>
    <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">batch_normalization</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;momentum&#39;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span> <span class="s1">&#39;epsilon&#39;</span><span class="p">:</span> <span class="mf">0.0001</span><span class="p">}),</span>
    <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="p">{}),</span>
<span class="p">]</span>
</pre></div>
</div>
<p>Note that you don’t need to provide “regularizer”, “training” and
“data_format” parameters since they will be automatically added.</p>
</li>
<li><p class="first"><strong>cnn_layers</strong> (list) — list with the description of “fully-connected”
layers. The only different from convolutional layers is that the input
will be automatically reshaped to 2D (batch size x num features).
For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s1">&#39;fc_layers&#39;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;units&#39;</span><span class="p">:</span> <span class="mi">4096</span><span class="p">,</span> <span class="s1">&#39;activation&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">}),</span>
    <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;rate&#39;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">}),</span>
    <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;units&#39;</span><span class="p">:</span> <span class="mi">4096</span><span class="p">,</span> <span class="s1">&#39;activation&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">}),</span>
    <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;rate&#39;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">}),</span>
<span class="p">],</span>
</pre></div>
</div>
<p>Note that you don’t need to provide “regularizer”, “training” and
“data_format” parameters since they will be automatically added.</p>
</li>
<li><p class="first"><strong>data_format</strong> (string) — could be either “channels_first” or
“channels_last”. Defaults to “channels_first”.</p>
</li>
</ul>
</dd></dl>

<dl class="staticmethod">
<dt id="encoders.cnn_encoder.CNNEncoder.get_optional_params">
<em class="property">static </em><code class="descname">get_optional_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/cnn_encoder.html#CNNEncoder.get_optional_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.cnn_encoder.CNNEncoder.get_optional_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of optional parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>can</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <a class="reference internal" href="#encoders.cnn_encoder.CNNEncoder.__init__" title="encoders.cnn_encoder.CNNEncoder.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code></a> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="encoders.cnn_encoder.CNNEncoder.get_required_params">
<em class="property">static </em><code class="descname">get_required_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/cnn_encoder.html#CNNEncoder.get_required_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.cnn_encoder.CNNEncoder.get_required_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method with description of required parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Dictionary containing all the parameters that <strong>have to</strong> be
included into the <code class="docutils literal notranslate"><span class="pre">params</span></code> parameter of the
class <a class="reference internal" href="#encoders.cnn_encoder.CNNEncoder.__init__" title="encoders.cnn_encoder.CNNEncoder.__init__"><code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code></a> method.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="encoders.cnn_encoder.build_layer">
<code class="descclassname">encoders.cnn_encoder.</code><code class="descname">build_layer</code><span class="sig-paren">(</span><em>inputs</em>, <em>layer</em>, <em>layer_params</em>, <em>data_format</em>, <em>regularizer</em>, <em>training</em>, <em>verbose=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encoders/cnn_encoder.html#build_layer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoders.cnn_encoder.build_layer" title="Permalink to this definition">¶</a></dt>
<dd><p>This function builds a layer from the layer function and it’s parameters.</p>
<p>It will automatically add regularizer parameter to the layer_params if the
layer supports regularization. To check this, it will look for the
“regularizer”, “kernel_regularizer” and “gamma_regularizer” names in this
order in the <code class="docutils literal notranslate"><span class="pre">layer</span></code> call signature. If one of this parameters is supported
it will pass regularizer object as a value for that parameter. Based on the
same “checking signature” technique “data_format” and “training” parameters
will try to be added.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inputs</strong> – input Tensor that will be passed to the layer. Note that layer has
to accept input as the first parameter.</li>
<li><strong>layer</strong> – layer function or class with <code class="docutils literal notranslate"><span class="pre">__call__</span></code> method defined.</li>
<li><strong>layer_params</strong> (<em>dict</em>) – parameters passed to the <code class="docutils literal notranslate"><span class="pre">layer</span></code>.</li>
<li><strong>data_format</strong> (<em>string</em>) – data format (“channels_first” or “channels_last”)
that will be tried to be passed as an additional argument.</li>
<li><strong>regularizer</strong> – regularizer instance that will be tried to be passed as an
additional argument.</li>
<li><strong>training</strong> (<em>bool</em>) – whether layer is built in training mode. Will be tried to
be passed as an additional argument.</li>
<li><strong>verbose</strong> (<em>bool</em>) – whether to print information about built layers.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">Tensor with layer output.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="decoders.html" class="btn btn-neutral float-right" title="decoders" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="data.text2text.html" class="btn btn-neutral" title="text2text" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, NVIDIA.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.2',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  <script type="text/javascript">
      jQuery(function () {
          
          SphinxRtdTheme.Navigation.enableSticky();
          
      });
  </script>  
  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #64d81c;
    }
    .wy-side-nav-search > div.version {
      color: #ffffff;
    }
    .wy-side-nav-search > img {
      max-width: 150px;
    }
    .wy-side-nav-search > a {
      font-size: 23px;
    }
  </style>


</body>
</html>