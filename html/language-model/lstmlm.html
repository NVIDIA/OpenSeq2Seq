

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>LSTMLM &mdash; OpenSeq2Seq 0.2 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  
  
  

  

  
  
    

  

  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/theme_override.css" type="text/css" />
  <link rel="stylesheet" href="../_static/theme_override.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Sentiment Analysis" href="../sentiment-analysis.html" />
    <link rel="prev" title="Language Model" href="../language-model.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> OpenSeq2Seq
          

          
            
            <img src="../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../machine-translation.html">Machine Translation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../speech-recognition.html">Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../speech-synthesis.html">Speech Synthesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../language-model.html">Language Model</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../sentiment-analysis.html">Sentiment Analysis</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../sentiment-analysis.html#models">Models</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">LSTMLM</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#model">Model</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../sentiment-analysis.html#getting-started">Getting started</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../speech-commands.html">Speech Commands</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distr-training.html">Multi-GPU and Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mixed-precision.html">Mixed Precision Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../in-depth-tutorials.html">In-depth Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../interactive-infer-demos.html">Interactive Infer Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api-docs/modules.html">API documentation</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">OpenSeq2Seq</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../language-model.html">Language Model</a> &raquo;</li>
        
      <li>LSTMLM</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/language-model/lstmlm.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="lstmlm">
<span id="id1"></span><h1>LSTMLM<a class="headerlink" href="#lstmlm" title="Permalink to this headline">¶</a></h1>
<div class="section" id="model">
<h2>Model<a class="headerlink" href="#model" title="Permalink to this headline">¶</a></h2>
<p>This is a word-level language model that uses a basic uni-directional LSTM architecture. To train on the dataset WikiText-103, we use 3 layer LSTM model, each layer with 1024 units and embedding size of 400. We break the data into sequences of length 96.</p>
<p>The biggest problem when training RNN-based language models is overfitting. To reduce overfitting, we use several techniques proposed in the paper <cite>Regularizing and Optimizing LSTM Language Models (Smerity et al., 2017) &lt;https://arxiv.org/pdf/1708.02182.pdf&gt;</cite>.</p>
<ul class="simple">
<li>weights tied: share the same variables between the embedding matrix with the kernel output project layer after the RNN. It means that the LSTM cell at the last layer has the same number of hidden units as the embedding size. Due to the huge vocab size, this technique reduces the number of parameters by 100M.</li>
<li>random start: According to Smerity et al., if we always break the training data into sequences of length 96, any element at the index divisible by 96 “never has any elements to backprop into”. To avoid this, we randomly choose the start token index to be between [0, 95].</li>
<li>embedding dropout: we use dropout with the embedding matrix (which is also the kernel for the output projection layer)</li>
<li><dl class="first docutils">
<dt>LSTM dropout: we use various dropout methods with LSTM cells. For more information on these different techniques of dropout, this is <cite>an excellent blog post &lt;https://medium.com/&#64;bingobee01/a-review-of-dropout-as-applied-to-rnns-72e79ecd5b7b&gt;</cite>. The cell in the last layer uses a different keep probability because with weight tied, it often has a much smaller number of hidden units.</dt>
<dd><ul class="first last">
<li>input_weight_keep_prob: keep probability for dropout of W (kernel used to multiply with the input tensor)</li>
<li>recurrent_weight_keep_prob: keep probability for dropout of U (kernel used to multiply with last hidden state tensor)</li>
<li>recurrent_keep_prob: keep probability for dropout when applying tanh on the input transform</li>
<li>encoder_dp_input_keep_prob: keep probability for dropout on input of a LSTM cell in the layer which is not the last layer</li>
<li>encoder_dp_output_keep_prob: keep probability for dropout on output of a LSTM cell in the layer which is not the last layer</li>
<li>encoder_last_input_keep_prob: like encoder_dp_input_keep_prob but for the cell in the last layer</li>
<li>encoder_dp_output_keep_prob: like encoder_dp_output_keep_prob but for the cell in the last layer</li>
</ul>
</dd>
</dl>
</li>
</ul>
<p>The model has 123.7M tokens. Using single-precision training on 4 GPUs, it takes 36 hours to get to the perplexity of 51, and double that amount of time to get the perplexity of 48.6. Using mixed-precision, we’re able to double the batch size and reduce the training time by half.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../sentiment-analysis.html" class="btn btn-neutral float-right" title="Sentiment Analysis" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../language-model.html" class="btn btn-neutral" title="Language Model" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, NVIDIA.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.2',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  <script type="text/javascript">
      jQuery(function () {
          
          SphinxRtdTheme.Navigation.enableSticky();
          
      });
  </script>  
  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #64d81c;
    }
    .wy-side-nav-search > div.version {
      color: #ffffff;
    }
    .wy-side-nav-search > img {
      max-width: 150px;
    }
    .wy-side-nav-search > a {
      font-size: 23px;
    }
  </style>


</body>
</html>