

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>parts.rnns.rnn_beam_search_decoder &mdash; OpenSeq2Seq 0.2 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
  
  
  

  

  
  
    

  

  
    <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/theme_override.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/theme_override.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> OpenSeq2Seq
          

          
            
            <img src="../../../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../installation.html">Installation instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../machine-translation.html">Machine Translation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../speech-recognition.html">Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../speech-synthesis.html">Speech Synthesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distr-training.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mixed-precision.html">Mixed precision training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../in-depth-tutorials.html">In-depth tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../interactive-infer-demos.html">Interactive Infer Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api-docs/modules.html">API documentation</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">OpenSeq2Seq</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>parts.rnns.rnn_beam_search_decoder</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for parts.rnns.rnn_beam_search_decoder</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2017 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
<span class="sd">&quot;&quot;&quot;A decoder that performs beam search.&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">unicode_literals</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="k">import</span> <span class="nb">range</span>

<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">tensorflow.contrib.seq2seq.python.ops</span> <span class="k">import</span> <span class="n">beam_search_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.contrib.seq2seq.python.ops</span> <span class="k">import</span> <span class="n">decoder</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">dtypes</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">tensor_shape</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">tensor_util</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.layers</span> <span class="k">import</span> <span class="n">base</span> <span class="k">as</span> <span class="n">layers_base</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">array_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">control_flow_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">embedding_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">math_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">nn_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">rnn_cell_impl</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">tensor_array_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util</span> <span class="k">import</span> <span class="n">nest</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;BeamSearchDecoderOutput&quot;</span><span class="p">,</span>
    <span class="s2">&quot;BeamSearchDecoderState&quot;</span><span class="p">,</span>
    <span class="s2">&quot;BeamSearchDecoder&quot;</span><span class="p">,</span>
    <span class="s2">&quot;FinalBeamSearchDecoderOutput&quot;</span><span class="p">,</span>
    <span class="s2">&quot;tile_batch&quot;</span><span class="p">,</span>
<span class="p">]</span>


<div class="viewcode-block" id="BeamSearchDecoderState"><a class="viewcode-back" href="../../../api-docs/parts.rnns.html#parts.rnns.rnn_beam_search_decoder.BeamSearchDecoderState">[docs]</a><span class="k">class</span> <span class="nc">BeamSearchDecoderState</span><span class="p">(</span>
    <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span><span class="s2">&quot;BeamSearchDecoderState&quot;</span><span class="p">,</span>
                           <span class="p">(</span><span class="s2">&quot;cell_state&quot;</span><span class="p">,</span> <span class="s2">&quot;log_probs&quot;</span><span class="p">,</span> <span class="s2">&quot;finished&quot;</span><span class="p">,</span> <span class="s2">&quot;lengths&quot;</span><span class="p">))):</span>
  <span class="k">pass</span></div>


<div class="viewcode-block" id="BeamSearchDecoderOutput"><a class="viewcode-back" href="../../../api-docs/parts.rnns.html#parts.rnns.rnn_beam_search_decoder.BeamSearchDecoderOutput">[docs]</a><span class="k">class</span> <span class="nc">BeamSearchDecoderOutput</span><span class="p">(</span>
    <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span><span class="s2">&quot;BeamSearchDecoderOutput&quot;</span><span class="p">,</span>
                           <span class="p">(</span><span class="s2">&quot;scores&quot;</span><span class="p">,</span> <span class="s2">&quot;predicted_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;parent_ids&quot;</span><span class="p">))):</span>
  <span class="k">pass</span></div>


<div class="viewcode-block" id="FinalBeamSearchDecoderOutput"><a class="viewcode-back" href="../../../api-docs/parts.rnns.html#parts.rnns.rnn_beam_search_decoder.FinalBeamSearchDecoderOutput">[docs]</a><span class="k">class</span> <span class="nc">FinalBeamSearchDecoderOutput</span><span class="p">(</span>
    <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span><span class="s2">&quot;FinalBeamDecoderOutput&quot;</span><span class="p">,</span>
                           <span class="p">[</span><span class="s2">&quot;predicted_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;beam_search_decoder_output&quot;</span><span class="p">])):</span>
  <span class="sd">&quot;&quot;&quot;Final outputs returned by the beam search after all decoding is finished.</span>

<span class="sd">  Args:</span>
<span class="sd">    predicted_ids: The final prediction. A tensor of shape</span>
<span class="sd">      `[batch_size, T, beam_width]` (or `[T, batch_size, beam_width]` if</span>
<span class="sd">      `output_time_major` is True). Beams are ordered from best to worst.</span>
<span class="sd">    beam_search_decoder_output: An instance of `BeamSearchDecoderOutput` that</span>
<span class="sd">      describes the state of the beam search.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">pass</span></div>


<span class="k">def</span> <span class="nf">_tile_batch</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">multiplier</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Core single-tensor implementation of tile_batch.&quot;&quot;&quot;</span>
  <span class="n">t</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;t&quot;</span><span class="p">)</span>
  <span class="n">shape_t</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;t must have statically known rank&quot;</span><span class="p">)</span>
  <span class="n">tiling</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">tiling</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">multiplier</span>
  <span class="n">tiled_static_batch_size</span> <span class="o">=</span> <span class="p">(</span>
      <span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">value</span> <span class="o">*</span> <span class="n">multiplier</span> <span class="k">if</span> <span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
  <span class="n">tiled</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">array_ops</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tiling</span><span class="p">)</span>
  <span class="n">tiled</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tiled</span><span class="p">,</span>
                            <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
                                <span class="p">([</span><span class="n">shape_t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">multiplier</span><span class="p">],</span> <span class="n">shape_t</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="mi">0</span><span class="p">))</span>
  <span class="n">tiled</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span>
      <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="n">tiled_static_batch_size</span><span class="p">])</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
          <span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
  <span class="k">return</span> <span class="n">tiled</span>


<div class="viewcode-block" id="tile_batch"><a class="viewcode-back" href="../../../api-docs/parts.rnns.html#parts.rnns.rnn_beam_search_decoder.tile_batch">[docs]</a><span class="k">def</span> <span class="nf">tile_batch</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">multiplier</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Tile the batch dimension of a (possibly nested structure of) tensor(s) t.</span>

<span class="sd">  For each tensor t in a (possibly nested structure) of tensors,</span>
<span class="sd">  this function takes a tensor t shaped `[batch_size, s0, s1, ...]` composed of</span>
<span class="sd">  minibatch entries `t[0], ..., t[batch_size - 1]` and tiles it to have a shape</span>
<span class="sd">  `[batch_size * multiplier, s0, s1, ...]` composed of minibatch entries</span>
<span class="sd">  `t[0], t[0], ..., t[1], t[1], ...` where each minibatch entry is repeated</span>
<span class="sd">  `multiplier` times.</span>

<span class="sd">  Args:</span>
<span class="sd">    t: `Tensor` shaped `[batch_size, ...]`.</span>
<span class="sd">    multiplier: Python int.</span>
<span class="sd">    name: Name scope for any created operations.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A (possibly nested structure of) `Tensor` shaped</span>
<span class="sd">    `[batch_size * multiplier, ...]`.</span>

<span class="sd">  Raises:</span>
<span class="sd">    ValueError: if tensor(s) `t` do not have a statically known rank or</span>
<span class="sd">    the rank is &lt; 1.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">flat_t</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
  <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;tile_batch&quot;</span><span class="p">,</span> <span class="n">flat_t</span> <span class="o">+</span> <span class="p">[</span><span class="n">multiplier</span><span class="p">]):</span>
    <span class="k">return</span> <span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t_</span><span class="p">:</span> <span class="n">_tile_batch</span><span class="p">(</span><span class="n">t_</span><span class="p">,</span> <span class="n">multiplier</span><span class="p">),</span> <span class="n">t</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_check_maybe</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">tensor_array_ops</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;TensorArray state is not supported by BeamSearchDecoder: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">t</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
        <span class="s2">&quot;Expected tensor (</span><span class="si">%s</span><span class="s2">) to have known rank, but ndims == None.&quot;</span> <span class="o">%</span> <span class="n">t</span><span class="p">)</span>


<div class="viewcode-block" id="BeamSearchDecoder"><a class="viewcode-back" href="../../../api-docs/parts.rnns.html#parts.rnns.rnn_beam_search_decoder.BeamSearchDecoder">[docs]</a><span class="k">class</span> <span class="nc">BeamSearchDecoder</span><span class="p">(</span><span class="n">decoder</span><span class="o">.</span><span class="n">Decoder</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;BeamSearch sampling decoder.</span>

<span class="sd">    **NOTE** If you are using the `BeamSearchDecoder` with a cell wrapped in</span>
<span class="sd">    `AttentionWrapper`, then you must ensure that:</span>

<span class="sd">    - The encoder output has been tiled to `beam_width` via</span>
<span class="sd">      @{tf.contrib.seq2seq.tile_batch} (NOT `tf.tile`).</span>
<span class="sd">    - The `batch_size` argument passed to the `zero_state` method of this</span>
<span class="sd">      wrapper is equal to `true_batch_size * beam_width`.</span>
<span class="sd">    - The initial state created with `zero_state` above contains a</span>
<span class="sd">      `cell_state` value containing properly tiled final state from the</span>
<span class="sd">      encoder.</span>

<span class="sd">    An example:</span>

<span class="sd">    ```</span>
<span class="sd">    tiled_encoder_outputs = tf.contrib.seq2seq.tile_batch(</span>
<span class="sd">        encoder_outputs, multiplier=beam_width)</span>
<span class="sd">    tiled_encoder_final_state = tf.conrib.seq2seq.tile_batch(</span>
<span class="sd">        encoder_final_state, multiplier=beam_width)</span>
<span class="sd">    tiled_sequence_length = tf.contrib.seq2seq.tile_batch(</span>
<span class="sd">        sequence_length, multiplier=beam_width)</span>
<span class="sd">    attention_mechanism = MyFavoriteAttentionMechanism(</span>
<span class="sd">        num_units=attention_depth,</span>
<span class="sd">        memory=tiled_inputs,</span>
<span class="sd">        memory_sequence_length=tiled_sequence_length)</span>
<span class="sd">    attention_cell = AttentionWrapper(cell, attention_mechanism, ...)</span>
<span class="sd">    decoder_initial_state = attention_cell.zero_state(</span>
<span class="sd">        dtype, batch_size=true_batch_size * beam_width)</span>
<span class="sd">    decoder_initial_state = decoder_initial_state.clone(</span>
<span class="sd">        cell_state=tiled_encoder_final_state)</span>
<span class="sd">    ```</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="BeamSearchDecoder.__init__"><a class="viewcode-back" href="../../../api-docs/parts.rnns.html#parts.rnns.rnn_beam_search_decoder.BeamSearchDecoder.__init__">[docs]</a>  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">cell</span><span class="p">,</span>
               <span class="n">embedding</span><span class="p">,</span>
               <span class="n">start_tokens</span><span class="p">,</span>
               <span class="n">end_token</span><span class="p">,</span>
               <span class="n">initial_state</span><span class="p">,</span>
               <span class="n">beam_width</span><span class="p">,</span>
               <span class="n">output_layer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">length_penalty_weight</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initialize the BeamSearchDecoder.</span>

<span class="sd">    Args:</span>
<span class="sd">      cell: An `RNNCell` instance.</span>
<span class="sd">      embedding: A callable that takes a vector tensor of `ids` (argmax ids),</span>
<span class="sd">        or the `params` argument for `embedding_lookup`.</span>
<span class="sd">      start_tokens: `int32` vector shaped `[batch_size]`, the start tokens.</span>
<span class="sd">      end_token: `int32` scalar, the token that marks end of decoding.</span>
<span class="sd">      initial_state: A (possibly nested tuple of...) tensors and TensorArrays.</span>
<span class="sd">      beam_width:  Python integer, the number of beams.</span>
<span class="sd">      output_layer: (Optional) An instance of `tf.layers.Layer`, i.e.,</span>
<span class="sd">        `tf.layers.Dense`.  Optional layer to apply to the RNN output prior</span>
<span class="sd">        to storing the result or sampling.</span>
<span class="sd">      length_penalty_weight: Float weight to penalize length. Disabled with 0.0.</span>

<span class="sd">    Raises:</span>
<span class="sd">      TypeError: if `cell` is not an instance of `RNNCell`,</span>
<span class="sd">        or `output_layer` is not an instance of `tf.layers.Layer`.</span>
<span class="sd">      ValueError: If `start_tokens` is not a vector or</span>
<span class="sd">        `end_token` is not a scalar.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">rnn_cell_impl</span><span class="o">.</span><span class="n">_like_rnncell</span><span class="p">(</span><span class="n">cell</span><span class="p">):</span>  <span class="c1"># pylint: disable=protected-access</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;cell must be an RNNCell, received: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">cell</span><span class="p">))</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">output_layer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span>
        <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_layer</span><span class="p">,</span> <span class="n">layers_base</span><span class="o">.</span><span class="n">Layer</span><span class="p">)):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
          <span class="s2">&quot;output_layer must be a Layer, received: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">output_layer</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_cell</span> <span class="o">=</span> <span class="n">cell</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_output_layer</span> <span class="o">=</span> <span class="n">output_layer</span>

    <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">embedding</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_fn</span> <span class="o">=</span> <span class="n">embedding</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_fn</span> <span class="o">=</span> <span class="p">(</span>
          <span class="k">lambda</span> <span class="n">ids</span><span class="p">:</span> <span class="n">embedding_ops</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="n">ids</span><span class="p">))</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_start_tokens</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span>
        <span class="n">start_tokens</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;start_tokens&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_start_tokens</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">ndims</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;start_tokens must be a vector&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_end_token</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span>
        <span class="n">end_token</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;end_token&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_end_token</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">ndims</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;end_token must be a scalar&quot;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">start_tokens</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_beam_width</span> <span class="o">=</span> <span class="n">beam_width</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_length_penalty_weight</span> <span class="o">=</span> <span class="n">length_penalty_weight</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_initial_cell_state</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_split_batch_beams</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cell</span><span class="o">.</span><span class="n">state_size</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_start_tokens</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
        <span class="n">array_ops</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_start_tokens</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_beam_width</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_start_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_fn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_start_tokens</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_finished</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span>
        <span class="n">array_ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
        <span class="n">depth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_beam_width</span><span class="p">,</span>
        <span class="n">on_value</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">off_value</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span></div>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span>

  <span class="k">def</span> <span class="nf">_rnn_output_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cell</span><span class="o">.</span><span class="n">output_size</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_layer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">size</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># To use layer&#39;s compute_output_shape, we need to convert the</span>
      <span class="c1"># RNNCell&#39;s output_size entries into shapes with an unknown</span>
      <span class="c1"># batch size.  We then pass this through the layer&#39;s</span>
      <span class="c1"># compute_output_shape and read off all but the first (batch)</span>
      <span class="c1"># dimensions to get the output size of the rnn with the layer</span>
      <span class="c1"># applied to the top.</span>
      <span class="n">output_shape_with_unknown_batch</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span>
          <span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="kc">None</span><span class="p">])</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">s</span><span class="p">),</span> <span class="n">size</span><span class="p">)</span>
      <span class="n">layer_output_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_layer</span><span class="o">.</span><span class="n">compute_output_shape</span><span class="p">(</span>
          <span class="n">output_shape_with_unknown_batch</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">layer_output_shape</span><span class="p">)</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">tracks_own_finished</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The BeamSearchDecoder shuffles its beams and their finished state.</span>

<span class="sd">    For this reason, it conflicts with the `dynamic_decode` function&#39;s</span>
<span class="sd">    tracking of finished states.  Setting this property to true avoids</span>
<span class="sd">    early stopping of decoding due to mismanagement of the finished state</span>
<span class="sd">    in `dynamic_decode`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      `True`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="kc">True</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">output_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># Return the cell output and the id</span>
    <span class="k">return</span> <span class="n">BeamSearchDecoderOutput</span><span class="p">(</span>
        <span class="n">scores</span><span class="o">=</span><span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_beam_width</span><span class="p">]),</span>
        <span class="n">predicted_ids</span><span class="o">=</span><span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_beam_width</span><span class="p">]),</span>
        <span class="n">parent_ids</span><span class="o">=</span><span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_beam_width</span><span class="p">]))</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">output_dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># Assume the dtype of the cell is the output_size structure</span>
    <span class="c1"># containing the input_state&#39;s first component&#39;s dtype.</span>
    <span class="c1"># Return that structure and int32 (the id)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_initial_cell_state</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
    <span class="k">return</span> <span class="n">BeamSearchDecoderOutput</span><span class="p">(</span>
        <span class="n">scores</span><span class="o">=</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="n">dtype</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rnn_output_size</span><span class="p">()),</span>
        <span class="n">predicted_ids</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
        <span class="n">parent_ids</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

<div class="viewcode-block" id="BeamSearchDecoder.initialize"><a class="viewcode-back" href="../../../api-docs/parts.rnns.html#parts.rnns.rnn_beam_search_decoder.BeamSearchDecoder.initialize">[docs]</a>  <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initialize the decoder.</span>

<span class="sd">    Args:</span>
<span class="sd">      name: Name scope for any created operations.</span>

<span class="sd">    Returns:</span>
<span class="sd">      `(finished, start_inputs, initial_state)`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">finished</span><span class="p">,</span> <span class="n">start_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_finished</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_start_inputs</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_initial_cell_state</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">log_probs</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span>  <span class="c1"># shape(batch_sz, beam_sz)</span>
        <span class="n">array_ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
        <span class="n">depth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_beam_width</span><span class="p">,</span>
        <span class="n">on_value</span><span class="o">=</span><span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">),</span>
        <span class="n">off_value</span><span class="o">=-</span><span class="n">np</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">float16</span> <span class="k">else</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">Inf</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

    <span class="n">initial_state</span> <span class="o">=</span> <span class="n">BeamSearchDecoderState</span><span class="p">(</span>
        <span class="n">cell_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_initial_cell_state</span><span class="p">,</span>
        <span class="n">log_probs</span><span class="o">=</span><span class="n">log_probs</span><span class="p">,</span>
        <span class="n">finished</span><span class="o">=</span><span class="n">finished</span><span class="p">,</span>
        <span class="n">lengths</span><span class="o">=</span><span class="n">array_ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_beam_width</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">finished</span><span class="p">,</span> <span class="n">start_inputs</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">)</span></div>

<div class="viewcode-block" id="BeamSearchDecoder.finalize"><a class="viewcode-back" href="../../../api-docs/parts.rnns.html#parts.rnns.rnn_beam_search_decoder.BeamSearchDecoder.finalize">[docs]</a>  <span class="k">def</span> <span class="nf">finalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">final_state</span><span class="p">,</span> <span class="n">sequence_lengths</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Finalize and return the predicted_ids.</span>

<span class="sd">    Args:</span>
<span class="sd">      outputs: An instance of BeamSearchDecoderOutput.</span>
<span class="sd">      final_state: An instance of BeamSearchDecoderState. Passed through to the</span>
<span class="sd">        output.</span>
<span class="sd">      sequence_lengths: An `int64` tensor shaped `[batch_size, beam_width]`.</span>
<span class="sd">        The sequence lengths determined for each beam during decode.</span>
<span class="sd">        **NOTE** These are ignored; the updated sequence lengths are stored in</span>
<span class="sd">        `final_state.lengths`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      outputs: An instance of `FinalBeamSearchDecoderOutput` where the</span>
<span class="sd">        predicted_ids are the result of calling _gather_tree.</span>
<span class="sd">      final_state: The same input instance of `BeamSearchDecoderState`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">del</span> <span class="n">sequence_lengths</span>
    <span class="c1"># Get max_sequence_length across all beams for each batch.</span>
    <span class="n">max_sequence_lengths</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">to_int32</span><span class="p">(</span>
        <span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">final_state</span><span class="o">.</span><span class="n">lengths</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">predicted_ids</span> <span class="o">=</span> <span class="n">beam_search_ops</span><span class="o">.</span><span class="n">gather_tree</span><span class="p">(</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">predicted_ids</span><span class="p">,</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">parent_ids</span><span class="p">,</span>
        <span class="n">max_sequence_lengths</span><span class="o">=</span><span class="n">max_sequence_lengths</span><span class="p">,</span>
        <span class="n">end_token</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_end_token</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">FinalBeamSearchDecoderOutput</span><span class="p">(</span>
        <span class="n">beam_search_decoder_output</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">predicted_ids</span><span class="o">=</span><span class="n">predicted_ids</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">final_state</span></div>

<div class="viewcode-block" id="BeamSearchDecoder._merge_batch_beams"><a class="viewcode-back" href="../../../api-docs/parts.rnns.html#parts.rnns.rnn_beam_search_decoder.BeamSearchDecoder._merge_batch_beams">[docs]</a>  <span class="k">def</span> <span class="nf">_merge_batch_beams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Merges the tensor from a batch of beams into a batch by beams.</span>

<span class="sd">    More exactly, t is a tensor of dimension [batch_size, beam_width, s]. We</span>
<span class="sd">    reshape this into [batch_size*beam_width, s]</span>

<span class="sd">    Args:</span>
<span class="sd">      t: Tensor of dimension [batch_size, beam_width, s]</span>
<span class="sd">      s: (Possibly known) depth shape.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A reshaped version of t with dimension [batch_size * beam_width, s].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
      <span class="n">s</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">as_shape</span><span class="p">(</span><span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">s</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="n">t_shape</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">static_batch_size</span> <span class="o">=</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span><span class="p">)</span>
    <span class="n">batch_size_beam_width</span> <span class="o">=</span> <span class="p">(</span>
        <span class="kc">None</span>
        <span class="k">if</span> <span class="n">static_batch_size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">static_batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_beam_width</span><span class="p">)</span>
    <span class="n">reshaped_t</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">t</span><span class="p">,</span>
        <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">(([</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_beam_width</span><span class="p">],</span> <span class="n">t_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]),</span>
                         <span class="mi">0</span><span class="p">))</span>
    <span class="n">reshaped_t</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span>
        <span class="p">(</span><span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="n">batch_size_beam_width</span><span class="p">])</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">s</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">reshaped_t</span></div>

<div class="viewcode-block" id="BeamSearchDecoder._split_batch_beams"><a class="viewcode-back" href="../../../api-docs/parts.rnns.html#parts.rnns.rnn_beam_search_decoder.BeamSearchDecoder._split_batch_beams">[docs]</a>  <span class="k">def</span> <span class="nf">_split_batch_beams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Splits the tensor from a batch by beams into a batch of beams.</span>

<span class="sd">    More exactly, t is a tensor of dimension [batch_size*beam_width, s]. We</span>
<span class="sd">    reshape this into [batch_size, beam_width, s]</span>

<span class="sd">    Args:</span>
<span class="sd">      t: Tensor of dimension [batch_size*beam_width, s].</span>
<span class="sd">      s: (Possibly known) depth shape.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A reshaped version of t with dimension [batch_size, beam_width, s].</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If, after reshaping, the new tensor is not shaped</span>
<span class="sd">        `[batch_size, beam_width, s]` (assuming batch_size and beam_width</span>
<span class="sd">        are known statically).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
      <span class="n">s</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">s</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="n">t_shape</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">reshaped_t</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">t</span><span class="p">,</span>
        <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">(([</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_beam_width</span><span class="p">],</span> <span class="n">t_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span>
                         <span class="mi">0</span><span class="p">))</span>
    <span class="n">static_batch_size</span> <span class="o">=</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span><span class="p">)</span>
    <span class="n">expected_reshaped_shape</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span>
        <span class="p">[</span><span class="n">static_batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_beam_width</span><span class="p">])</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">reshaped_t</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="n">expected_reshaped_shape</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unexpected behavior when reshaping between beam width &quot;</span>
                       <span class="s2">&quot;and batch size.  The reshaped tensor has shape: </span><span class="si">%s</span><span class="s2">.  &quot;</span>
                       <span class="s2">&quot;We expected it to have shape &quot;</span>
                       <span class="s2">&quot;(batch_size, beam_width, depth) == </span><span class="si">%s</span><span class="s2">.  Perhaps you &quot;</span>
                       <span class="s2">&quot;forgot to create a zero_state with &quot;</span>
                       <span class="s2">&quot;batch_size=encoder_batch_size * beam_width?&quot;</span> <span class="o">%</span>
                       <span class="p">(</span><span class="n">reshaped_t</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">expected_reshaped_shape</span><span class="p">))</span>
    <span class="n">reshaped_t</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">expected_reshaped_shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">reshaped_t</span></div>

<div class="viewcode-block" id="BeamSearchDecoder._maybe_split_batch_beams"><a class="viewcode-back" href="../../../api-docs/parts.rnns.html#parts.rnns.rnn_beam_search_decoder.BeamSearchDecoder._maybe_split_batch_beams">[docs]</a>  <span class="k">def</span> <span class="nf">_maybe_split_batch_beams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Maybe splits the tensor from a batch by beams into a batch of beams.</span>

<span class="sd">    We do this so that we can use nest and not run into problems with shapes.</span>

<span class="sd">    Args:</span>
<span class="sd">      t: `Tensor`, either scalar or shaped `[batch_size * beam_width] + s`.</span>
<span class="sd">      s: `Tensor`, Python int, or `TensorShape`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      If `t` is a matrix or higher order tensor, then the return value is</span>
<span class="sd">      `t` reshaped to `[batch_size, beam_width] + s`.  Otherwise `t` is</span>
<span class="sd">      returned unchanged.</span>

<span class="sd">    Raises:</span>
<span class="sd">      TypeError: If `t` is an instance of `TensorArray`.</span>
<span class="sd">      ValueError: If the rank of `t` is not statically known.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_maybe</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split_batch_beams</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">t</span></div>

<div class="viewcode-block" id="BeamSearchDecoder._maybe_merge_batch_beams"><a class="viewcode-back" href="../../../api-docs/parts.rnns.html#parts.rnns.rnn_beam_search_decoder.BeamSearchDecoder._maybe_merge_batch_beams">[docs]</a>  <span class="k">def</span> <span class="nf">_maybe_merge_batch_beams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Splits the tensor from a batch by beams into a batch of beams.</span>

<span class="sd">    More exactly, `t` is a tensor of dimension `[batch_size * beam_width] + s`,</span>
<span class="sd">    then we reshape it to `[batch_size, beam_width] + s`.</span>

<span class="sd">    Args:</span>
<span class="sd">      t: `Tensor` of dimension `[batch_size * beam_width] + s`.</span>
<span class="sd">      s: `Tensor`, Python int, or `TensorShape`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A reshaped version of t with shape `[batch_size, beam_width] + s`.</span>

<span class="sd">    Raises:</span>
<span class="sd">      TypeError: If `t` is an instance of `TensorArray`.</span>
<span class="sd">      ValueError:  If the rank of `t` is not statically known.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_maybe</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_merge_batch_beams</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">t</span></div>

<div class="viewcode-block" id="BeamSearchDecoder.step"><a class="viewcode-back" href="../../../api-docs/parts.rnns.html#parts.rnns.rnn_beam_search_decoder.BeamSearchDecoder.step">[docs]</a>  <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Perform a decoding step.</span>

<span class="sd">    Args:</span>
<span class="sd">      time: scalar `int32` tensor.</span>
<span class="sd">      inputs: A (structure of) input tensors.</span>
<span class="sd">      state: A (structure of) state tensors and TensorArrays.</span>
<span class="sd">      name: Name scope for any created operations.</span>

<span class="sd">    Returns:</span>
<span class="sd">      `(outputs, next_state, next_inputs, finished)`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span>
    <span class="n">beam_width</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_beam_width</span>
    <span class="n">end_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_end_token</span>
    <span class="n">length_penalty_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_length_penalty_weight</span>

    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;BeamSearchDecoderStep&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">)):</span>
      <span class="n">cell_state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">cell_state</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span>
          <span class="k">lambda</span> <span class="n">inp</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_merge_batch_beams</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]),</span> <span class="n">inputs</span><span class="p">)</span>
      <span class="n">cell_state</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_maybe_merge_batch_beams</span><span class="p">,</span> <span class="n">cell_state</span><span class="p">,</span>
                                      <span class="bp">self</span><span class="o">.</span><span class="n">_cell</span><span class="o">.</span><span class="n">state_size</span><span class="p">)</span>
      <span class="n">cell_outputs</span><span class="p">,</span> <span class="n">next_cell_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cell</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">cell_state</span><span class="p">)</span>
      <span class="n">cell_outputs</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span>
          <span class="k">lambda</span> <span class="n">out</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split_batch_beams</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">cell_outputs</span><span class="p">)</span>
      <span class="n">next_cell_state</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_split_batch_beams</span><span class="p">,</span> <span class="n">next_cell_state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cell</span><span class="o">.</span><span class="n">state_size</span><span class="p">)</span>

      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_layer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">cell_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_layer</span><span class="p">(</span><span class="n">cell_outputs</span><span class="p">)</span>

      <span class="n">beam_search_output</span><span class="p">,</span> <span class="n">beam_search_state</span> <span class="o">=</span> <span class="n">_beam_search_step</span><span class="p">(</span>
          <span class="n">time</span><span class="o">=</span><span class="n">time</span><span class="p">,</span>
          <span class="n">logits</span><span class="o">=</span><span class="n">cell_outputs</span><span class="p">,</span>
          <span class="n">next_cell_state</span><span class="o">=</span><span class="n">next_cell_state</span><span class="p">,</span>
          <span class="n">beam_state</span><span class="o">=</span><span class="n">state</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
          <span class="n">beam_width</span><span class="o">=</span><span class="n">beam_width</span><span class="p">,</span>
          <span class="n">end_token</span><span class="o">=</span><span class="n">end_token</span><span class="p">,</span>
          <span class="n">length_penalty_weight</span><span class="o">=</span><span class="n">length_penalty_weight</span><span class="p">)</span>

      <span class="n">finished</span> <span class="o">=</span> <span class="n">beam_search_state</span><span class="o">.</span><span class="n">finished</span>
      <span class="n">sample_ids</span> <span class="o">=</span> <span class="n">beam_search_output</span><span class="o">.</span><span class="n">predicted_ids</span>
      <span class="n">next_inputs</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
          <span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_all</span><span class="p">(</span><span class="n">finished</span><span class="p">),</span> <span class="k">lambda</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_start_inputs</span><span class="p">,</span>
          <span class="k">lambda</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_fn</span><span class="p">(</span><span class="n">sample_ids</span><span class="p">))</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">beam_search_output</span><span class="p">,</span> <span class="n">beam_search_state</span><span class="p">,</span> <span class="n">next_inputs</span><span class="p">,</span> <span class="n">finished</span><span class="p">)</span></div></div>


<span class="k">def</span> <span class="nf">_beam_search_step</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">next_cell_state</span><span class="p">,</span> <span class="n">beam_state</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                      <span class="n">beam_width</span><span class="p">,</span> <span class="n">end_token</span><span class="p">,</span> <span class="n">length_penalty_weight</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Performs a single step of Beam Search Decoding.</span>

<span class="sd">  Args:</span>
<span class="sd">    time: Beam search time step, should start at 0. At time 0 we assume</span>
<span class="sd">      that all beams are equal and consider only the first beam for</span>
<span class="sd">      continuations.</span>
<span class="sd">    logits: Logits at the current time step. A tensor of shape</span>
<span class="sd">      `[batch_size, beam_width, vocab_size]`</span>
<span class="sd">    next_cell_state: The next state from the cell, e.g. an instance of</span>
<span class="sd">      AttentionWrapperState if the cell is attentional.</span>
<span class="sd">    beam_state: Current state of the beam search.</span>
<span class="sd">      An instance of `BeamSearchDecoderState`.</span>
<span class="sd">    batch_size: The batch size for this input.</span>
<span class="sd">    beam_width: Python int.  The size of the beams.</span>
<span class="sd">    end_token: The int32 end token.</span>
<span class="sd">    length_penalty_weight: Float weight to penalize length. Disabled with 0.0.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A new beam state.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">static_batch_size</span> <span class="o">=</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

  <span class="c1"># Calculate the current lengths of the predictions</span>
  <span class="n">prediction_lengths</span> <span class="o">=</span> <span class="n">beam_state</span><span class="o">.</span><span class="n">lengths</span>
  <span class="n">previously_finished</span> <span class="o">=</span> <span class="n">beam_state</span><span class="o">.</span><span class="n">finished</span>

  <span class="c1"># Calculate the total log probs for the new hypotheses</span>
  <span class="c1"># Final Shape: [batch_size, beam_width, vocab_size]</span>
  <span class="n">step_log_probs</span> <span class="o">=</span> <span class="n">nn_ops</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
  <span class="n">step_log_probs</span> <span class="o">=</span> <span class="n">_mask_probs</span><span class="p">(</span><span class="n">step_log_probs</span><span class="p">,</span> <span class="n">end_token</span><span class="p">,</span> <span class="n">previously_finished</span><span class="p">)</span>
  <span class="n">total_probs</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">beam_state</span><span class="o">.</span><span class="n">log_probs</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">step_log_probs</span>

  <span class="c1"># Calculate the continuation lengths by adding to all continuing beams.</span>
  <span class="n">vocab_size</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span> <span class="ow">or</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">logits</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">lengths_to_add</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span>
      <span class="n">indices</span><span class="o">=</span><span class="n">array_ops</span><span class="o">.</span><span class="n">fill</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">beam_width</span><span class="p">],</span> <span class="n">end_token</span><span class="p">),</span>
      <span class="n">depth</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
      <span class="n">on_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
      <span class="n">off_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
      <span class="n">dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
  <span class="n">add_mask</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">to_int64</span><span class="p">(</span><span class="n">math_ops</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">previously_finished</span><span class="p">))</span>
  <span class="n">lengths_to_add</span> <span class="o">*=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">add_mask</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  <span class="n">new_prediction_lengths</span> <span class="o">=</span> <span class="p">(</span>
      <span class="n">lengths_to_add</span> <span class="o">+</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">prediction_lengths</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

  <span class="c1"># Calculate the scores for each beam</span>
  <span class="n">scores</span> <span class="o">=</span> <span class="n">_get_scores</span><span class="p">(</span>
      <span class="n">log_probs</span><span class="o">=</span><span class="n">total_probs</span><span class="p">,</span>
      <span class="n">sequence_lengths</span><span class="o">=</span><span class="n">new_prediction_lengths</span><span class="p">,</span>
      <span class="n">length_penalty_weight</span><span class="o">=</span><span class="n">length_penalty_weight</span><span class="p">,</span>
      <span class="n">dtype</span><span class="o">=</span><span class="n">logits</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

  <span class="n">time</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;time&quot;</span><span class="p">)</span>
  <span class="c1"># During the first time step we only consider the initial beam</span>
  <span class="n">scores_shape</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
  <span class="n">scores_flat</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>

  <span class="c1"># Pick the next beams according to the specified successors function</span>
  <span class="n">next_beam_size</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span>
      <span class="n">beam_width</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;beam_width&quot;</span><span class="p">)</span>
  <span class="n">next_beam_scores</span><span class="p">,</span> <span class="n">word_indices</span> <span class="o">=</span> <span class="n">nn_ops</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span><span class="n">scores_flat</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">next_beam_size</span><span class="p">)</span>

  <span class="n">next_beam_scores</span><span class="o">.</span><span class="n">set_shape</span><span class="p">([</span><span class="n">static_batch_size</span><span class="p">,</span> <span class="n">beam_width</span><span class="p">])</span>
  <span class="n">word_indices</span><span class="o">.</span><span class="n">set_shape</span><span class="p">([</span><span class="n">static_batch_size</span><span class="p">,</span> <span class="n">beam_width</span><span class="p">])</span>

  <span class="c1"># Pick out the probs, beam_ids, and states according to the chosen predictions</span>
  <span class="n">next_beam_probs</span> <span class="o">=</span> <span class="n">_tensor_gather_helper</span><span class="p">(</span>
      <span class="n">gather_indices</span><span class="o">=</span><span class="n">word_indices</span><span class="p">,</span>
      <span class="n">gather_from</span><span class="o">=</span><span class="n">total_probs</span><span class="p">,</span>
      <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
      <span class="n">range_size</span><span class="o">=</span><span class="n">beam_width</span> <span class="o">*</span> <span class="n">vocab_size</span><span class="p">,</span>
      <span class="n">gather_shape</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
      <span class="n">name</span><span class="o">=</span><span class="s2">&quot;next_beam_probs&quot;</span><span class="p">)</span>
  <span class="c1"># Note: just doing the following</span>
  <span class="c1">#   math_ops.to_int32(word_indices % vocab_size,</span>
  <span class="c1">#       name=&quot;next_beam_word_ids&quot;)</span>
  <span class="c1"># would be a lot cleaner but for reasons unclear, that hides the results of</span>
  <span class="c1"># the op which prevents capturing it with tfdbg debug ops.</span>
  <span class="n">raw_next_word_ids</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span>
      <span class="n">word_indices</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;next_beam_word_ids&quot;</span><span class="p">)</span>
  <span class="n">next_word_ids</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">to_int32</span><span class="p">(</span><span class="n">raw_next_word_ids</span><span class="p">)</span>
  <span class="n">next_beam_ids</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">to_int32</span><span class="p">(</span>
      <span class="n">word_indices</span> <span class="o">/</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;next_beam_parent_ids&quot;</span><span class="p">)</span>

  <span class="c1"># Append new ids to current predictions</span>
  <span class="n">previously_finished</span> <span class="o">=</span> <span class="n">_tensor_gather_helper</span><span class="p">(</span>
      <span class="n">gather_indices</span><span class="o">=</span><span class="n">next_beam_ids</span><span class="p">,</span>
      <span class="n">gather_from</span><span class="o">=</span><span class="n">previously_finished</span><span class="p">,</span>
      <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
      <span class="n">range_size</span><span class="o">=</span><span class="n">beam_width</span><span class="p">,</span>
      <span class="n">gather_shape</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
  <span class="n">next_finished</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span>
      <span class="n">previously_finished</span><span class="p">,</span>
      <span class="n">math_ops</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">next_word_ids</span><span class="p">,</span> <span class="n">end_token</span><span class="p">),</span>
      <span class="n">name</span><span class="o">=</span><span class="s2">&quot;next_beam_finished&quot;</span><span class="p">)</span>

  <span class="c1"># Calculate the length of the next predictions.</span>
  <span class="c1"># 1. Finished beams remain unchanged.</span>
  <span class="c1"># 2. Beams that are now finished (EOS predicted) have their length</span>
  <span class="c1">#    increased by 1.</span>
  <span class="c1"># 3. Beams that are not yet finished have their length increased by 1.</span>
  <span class="n">lengths_to_add</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">to_int64</span><span class="p">(</span><span class="n">math_ops</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">previously_finished</span><span class="p">))</span>
  <span class="n">next_prediction_len</span> <span class="o">=</span> <span class="n">_tensor_gather_helper</span><span class="p">(</span>
      <span class="n">gather_indices</span><span class="o">=</span><span class="n">next_beam_ids</span><span class="p">,</span>
      <span class="n">gather_from</span><span class="o">=</span><span class="n">beam_state</span><span class="o">.</span><span class="n">lengths</span><span class="p">,</span>
      <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
      <span class="n">range_size</span><span class="o">=</span><span class="n">beam_width</span><span class="p">,</span>
      <span class="n">gather_shape</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
  <span class="n">next_prediction_len</span> <span class="o">+=</span> <span class="n">lengths_to_add</span>

  <span class="c1"># Pick out the cell_states according to the next_beam_ids. We use a</span>
  <span class="c1"># different gather_shape here because the cell_state tensors, i.e.</span>
  <span class="c1"># the tensors that would be gathered from, all have dimension</span>
  <span class="c1"># greater than two and we need to preserve those dimensions.</span>
  <span class="c1"># pylint: disable=g-long-lambda</span>
  <span class="n">next_cell_state</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span>
      <span class="k">lambda</span> <span class="n">gather_from</span><span class="p">:</span> <span class="n">_maybe_tensor_gather_helper</span><span class="p">(</span>
          <span class="n">gather_indices</span><span class="o">=</span><span class="n">next_beam_ids</span><span class="p">,</span>
          <span class="n">gather_from</span><span class="o">=</span><span class="n">gather_from</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
          <span class="n">range_size</span><span class="o">=</span><span class="n">beam_width</span><span class="p">,</span>
          <span class="n">gather_shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">beam_width</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
      <span class="n">next_cell_state</span><span class="p">)</span>
  <span class="c1"># pylint: enable=g-long-lambda</span>

  <span class="n">next_state</span> <span class="o">=</span> <span class="n">BeamSearchDecoderState</span><span class="p">(</span>
      <span class="n">cell_state</span><span class="o">=</span><span class="n">next_cell_state</span><span class="p">,</span>
      <span class="n">log_probs</span><span class="o">=</span><span class="n">next_beam_probs</span><span class="p">,</span>
      <span class="n">lengths</span><span class="o">=</span><span class="n">next_prediction_len</span><span class="p">,</span>
      <span class="n">finished</span><span class="o">=</span><span class="n">next_finished</span><span class="p">)</span>

  <span class="n">output</span> <span class="o">=</span> <span class="n">BeamSearchDecoderOutput</span><span class="p">(</span>
      <span class="n">scores</span><span class="o">=</span><span class="n">next_beam_scores</span><span class="p">,</span>
      <span class="n">predicted_ids</span><span class="o">=</span><span class="n">next_word_ids</span><span class="p">,</span>
      <span class="n">parent_ids</span><span class="o">=</span><span class="n">next_beam_ids</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">next_state</span>


<span class="k">def</span> <span class="nf">_get_scores</span><span class="p">(</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">sequence_lengths</span><span class="p">,</span> <span class="n">length_penalty_weight</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Calculates scores for beam search hypotheses.</span>

<span class="sd">  Args:</span>
<span class="sd">    log_probs: The log probabilities with shape</span>
<span class="sd">      `[batch_size, beam_width, vocab_size]`.</span>
<span class="sd">    sequence_lengths: The array of sequence lengths.</span>
<span class="sd">    length_penalty_weight: Float weight to penalize length. Disabled with 0.0.</span>

<span class="sd">  Returns:</span>
<span class="sd">    The scores normalized by the length_penalty.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">length_penality_</span> <span class="o">=</span> <span class="n">_length_penalty</span><span class="p">(</span>
      <span class="n">sequence_lengths</span><span class="o">=</span><span class="n">sequence_lengths</span><span class="p">,</span> <span class="n">penalty_factor</span><span class="o">=</span><span class="n">length_penalty_weight</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">log_probs</span> <span class="o">/</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">length_penality_</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_length_penalty</span><span class="p">(</span><span class="n">sequence_lengths</span><span class="p">,</span> <span class="n">penalty_factor</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Calculates the length penalty. See https://arxiv.org/abs/1609.08144.</span>

<span class="sd">  Returns the length penalty tensor:</span>
<span class="sd">  ```</span>
<span class="sd">  [(5+sequence_lengths)/6]**penalty_factor</span>
<span class="sd">  ```</span>
<span class="sd">  where all operations are performed element-wise.</span>

<span class="sd">  Args:</span>
<span class="sd">    sequence_lengths: `Tensor`, the sequence lengths of each hypotheses.</span>
<span class="sd">    penalty_factor: A scalar that weights the length penalty.</span>

<span class="sd">  Returns:</span>
<span class="sd">    If the penalty is `0`, returns the scalar `1.0`.  Otherwise returns</span>
<span class="sd">    the length penalty factor, a tensor with the same shape as</span>
<span class="sd">    `sequence_lengths`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">penalty_factor</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">penalty_factor</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;penalty_factor&quot;</span><span class="p">)</span>
  <span class="n">penalty_factor</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(())</span>  <span class="c1"># penalty should be a scalar.</span>
  <span class="n">static_penalty</span> <span class="o">=</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="n">penalty_factor</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">static_penalty</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">static_penalty</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">return</span> <span class="mf">1.0</span>
  <span class="k">return</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">div</span><span class="p">((</span><span class="mf">5.</span> <span class="o">+</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">sequence_lengths</span><span class="p">))</span>
                      <span class="o">**</span><span class="n">penalty_factor</span><span class="p">,</span> <span class="p">(</span><span class="mf">5.</span> <span class="o">+</span> <span class="mf">1.</span><span class="p">)</span><span class="o">**</span><span class="n">penalty_factor</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_mask_probs</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">eos_token</span><span class="p">,</span> <span class="n">finished</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Masks log probabilities.</span>

<span class="sd">  The result is that finished beams allocate all probability mass to eos and</span>
<span class="sd">  unfinished beams remain unchanged.</span>

<span class="sd">  Args:</span>
<span class="sd">    probs: Log probabiltiies of shape `[batch_size, beam_width, vocab_size]`</span>
<span class="sd">    eos_token: An int32 id corresponding to the EOS token to allocate</span>
<span class="sd">      probability to.</span>
<span class="sd">    finished: A boolean tensor of shape `[batch_size, beam_width]` that</span>
<span class="sd">      specifies which elements in the beam are finished already.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tensor of shape `[batch_size, beam_width, vocab_size]`, where unfinished</span>
<span class="sd">    beams stay unchanged and finished beams are replaced with a tensor with all</span>
<span class="sd">    probability on the EOS token.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">vocab_size</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">probs</span><span class="p">)[</span><span class="mi">2</span><span class="p">]</span>
  <span class="c1"># All finished examples are replaced with a vector that has all</span>
  <span class="c1"># probability on EOS</span>
  <span class="n">finished_row</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span>
      <span class="n">eos_token</span><span class="p">,</span>
      <span class="n">vocab_size</span><span class="p">,</span>
      <span class="n">dtype</span><span class="o">=</span><span class="n">probs</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
      <span class="n">on_value</span><span class="o">=</span><span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">probs</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
      <span class="n">off_value</span><span class="o">=</span><span class="n">probs</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">min</span><span class="p">)</span>
  <span class="n">finished_probs</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
      <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">finished_row</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
      <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">finished</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="mi">0</span><span class="p">))</span>
  <span class="n">finished_mask</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
      <span class="n">array_ops</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">finished</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">])</span>

  <span class="k">return</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">finished_mask</span><span class="p">,</span> <span class="n">finished_probs</span><span class="p">,</span> <span class="n">probs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_maybe_tensor_gather_helper</span><span class="p">(</span><span class="n">gather_indices</span><span class="p">,</span> <span class="n">gather_from</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                                <span class="n">range_size</span><span class="p">,</span> <span class="n">gather_shape</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Maybe applies _tensor_gather_helper.</span>

<span class="sd">  This applies _tensor_gather_helper when the gather_from dims is at least as</span>
<span class="sd">  big as the length of gather_shape. This is used in conjunction with nest so</span>
<span class="sd">  that we don&#39;t apply _tensor_gather_helper to inapplicable values like scalars.</span>

<span class="sd">  Args:</span>
<span class="sd">    gather_indices: The tensor indices that we use to gather.</span>
<span class="sd">    gather_from: The tensor that we are gathering from.</span>
<span class="sd">    batch_size: The batch size.</span>
<span class="sd">    range_size: The number of values in each range. Likely equal to beam_width.</span>
<span class="sd">    gather_shape: What we should reshape gather_from to in order to preserve the</span>
<span class="sd">      correct values. An example is when gather_from is the attention from an</span>
<span class="sd">      AttentionWrapperState with shape [batch_size, beam_width, attention_size].</span>
<span class="sd">      There, we want to preserve the attention_size elements, so gather_shape is</span>
<span class="sd">      [batch_size * beam_width, -1]. Then, upon reshape, we still have the</span>
<span class="sd">      attention_size as desired.</span>

<span class="sd">  Returns:</span>
<span class="sd">    output: Gathered tensor of shape tf.shape(gather_from)[:1+len(gather_shape)]</span>
<span class="sd">      or the original tensor if its dimensions are too small.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_check_maybe</span><span class="p">(</span><span class="n">gather_from</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">gather_from</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">gather_shape</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_tensor_gather_helper</span><span class="p">(</span>
        <span class="n">gather_indices</span><span class="o">=</span><span class="n">gather_indices</span><span class="p">,</span>
        <span class="n">gather_from</span><span class="o">=</span><span class="n">gather_from</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">range_size</span><span class="o">=</span><span class="n">range_size</span><span class="p">,</span>
        <span class="n">gather_shape</span><span class="o">=</span><span class="n">gather_shape</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">gather_from</span>


<span class="k">def</span> <span class="nf">_tensor_gather_helper</span><span class="p">(</span><span class="n">gather_indices</span><span class="p">,</span>
                          <span class="n">gather_from</span><span class="p">,</span>
                          <span class="n">batch_size</span><span class="p">,</span>
                          <span class="n">range_size</span><span class="p">,</span>
                          <span class="n">gather_shape</span><span class="p">,</span>
                          <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Helper for gathering the right indices from the tensor.</span>

<span class="sd">  This works by reshaping gather_from to gather_shape (e.g. [-1]) and then</span>
<span class="sd">  gathering from that according to the gather_indices, which are offset by</span>
<span class="sd">  the right amounts in order to preserve the batch order.</span>

<span class="sd">  Args:</span>
<span class="sd">    gather_indices: The tensor indices that we use to gather.</span>
<span class="sd">    gather_from: The tensor that we are gathering from.</span>
<span class="sd">    batch_size: The input batch size.</span>
<span class="sd">    range_size: The number of values in each range. Likely equal to beam_width.</span>
<span class="sd">    gather_shape: What we should reshape gather_from to in order to preserve the</span>
<span class="sd">      correct values. An example is when gather_from is the attention from an</span>
<span class="sd">      AttentionWrapperState with shape [batch_size, beam_width, attention_size].</span>
<span class="sd">      There, we want to preserve the attention_size elements, so gather_shape is</span>
<span class="sd">      [batch_size * beam_width, -1]. Then, upon reshape, we still have the</span>
<span class="sd">      attention_size as desired.</span>
<span class="sd">    name: The tensor name for set of operations. By default this is</span>
<span class="sd">      &#39;tensor_gather_helper&#39;. The final output is named &#39;output&#39;.</span>

<span class="sd">  Returns:</span>
<span class="sd">    output: Gathered tensor of shape tf.shape(gather_from)[:1+len(gather_shape)]</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;tensor_gather_helper&quot;</span><span class="p">):</span>
    <span class="n">range_</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">math_ops</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> <span class="o">*</span> <span class="n">range_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">gather_indices</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">gather_indices</span> <span class="o">+</span> <span class="n">range_</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span>
        <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">gather_from</span><span class="p">,</span> <span class="n">gather_shape</span><span class="p">),</span> <span class="n">gather_indices</span><span class="p">)</span>
    <span class="n">final_shape</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">gather_from</span><span class="p">)[:</span><span class="mi">1</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">gather_shape</span><span class="p">)]</span>
    <span class="n">static_batch_size</span> <span class="o">=</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">final_static_shape</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="n">static_batch_size</span><span class="p">])</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
            <span class="n">gather_from</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">1</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">gather_shape</span><span class="p">)]))</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">final_shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;output&quot;</span><span class="p">)</span>
    <span class="n">output</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">final_static_shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, NVIDIA.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'0.2',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>
  

  <script type="text/javascript">
      jQuery(function () {
          
          SphinxRtdTheme.Navigation.enableSticky();
          
      });
  </script>  
  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #64d81c;
    }
    .wy-side-nav-search > div.version {
      color: #ffffff;
    }
    .wy-side-nav-search > img {
      max-width: 150px;
    }
    .wy-side-nav-search > a {
      font-size: 23px;
    }
  </style>


</body>
</html>